{
    "version": "https://jsonfeed.org/version/1",
    "title": "枯萎的花将在另一彼岸悄然绽放",
    "subtitle": null,
    "icon": "https://yunhdan.github.io/images/favicon.ico",
    "description": "计算机视觉 & 图像恢复",
    "home_page_url": "https://yunhdan.github.io",
    "items": [
        {
            "id": "https://yunhdan.github.io/other/%E8%B0%88%E5%88%A4%E6%8A%80%E5%B7%A7/",
            "url": "https://yunhdan.github.io/other/%E8%B0%88%E5%88%A4%E6%8A%80%E5%B7%A7/",
            "title": "实用谈判技巧",
            "date_published": "2025-07-16T06:42:42.535Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"\\assets\\css\\APlayer.min.css\"><script src=\"\\assets\\js\\APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><div class=\"note info\">\n<p>学习自白斌老师的谈判实用技巧。</p>\n</div>\n<ul>\n<li>移花接木：若对方的要求十分难以接受，当面拒绝不合适时，可以首先进行同意，然后再提出一个让对方难以接受的条件进行拒绝。“送我宝马”“可以，但有个条件，我要让你送我一栋别墅”。</li>\n<li>降低对方期待值：如果对方想要让你接受一个比较坏的结果，你可以告知他接受该结果后的一个更坏的局面。反之亦然，让对方接受一个东西，若对方不接受，则告知将会面临一个更大的后果。</li>\n</ul>\n",
            "tags": [
                "琐碎"
            ]
        },
        {
            "id": "https://yunhdan.github.io/research/%E6%9C%9F%E5%88%8A%E3%80%81%E4%BC%9A%E8%AE%AE%E6%8A%95%E7%A8%BF%E7%BB%8F%E9%AA%8C/",
            "url": "https://yunhdan.github.io/research/%E6%9C%9F%E5%88%8A%E3%80%81%E4%BC%9A%E8%AE%AE%E6%8A%95%E7%A8%BF%E7%BB%8F%E9%AA%8C/",
            "title": "期刊、会议投稿经验",
            "date_published": "2025-07-07T07:44:16.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"\\assets\\css\\APlayer.min.css\"><script src=\"\\assets\\js\\APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h1 id=\"简单介绍会议的peer-review和rebuttal重点提供了rebuttal经验\"><a class=\"anchor\" href=\"#简单介绍会议的peer-review和rebuttal重点提供了rebuttal经验\">#</a> 简单介绍会议的 Peer Review 和 Rebuttal，重点提供了 Rebuttal 经验</h1>\n<ul>\n<li><span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cuemhpaHUuY29tL3RhcmRpcy96bS9hcnQvMTA0Mjk4OTIzP3NvdXJjZV9pZD0xMDA1\">https://www.zhihu.com/tardis/zm/art/104298923?source_id=1005</span></li>\n</ul>\n<h1 id=\"一些会议的rebuttal经历供参考\"><a class=\"anchor\" href=\"#一些会议的rebuttal经历供参考\">#</a> 一些会议的 Rebuttal 经历供参考</h1>\n<ul>\n<li>原文名为记录一次神奇的 Rebuttal 经历：<span class=\"exturl\" data-url=\"aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8zNTM3NjE5MjA=\">https://zhuanlan.zhihu.com/p/353761920</span></li>\n</ul>\n",
            "tags": [
                "学术"
            ]
        },
        {
            "id": "https://yunhdan.github.io/other/%E6%80%9D%E6%83%B3%E5%BB%BA%E8%AE%BE/",
            "url": "https://yunhdan.github.io/other/%E6%80%9D%E6%83%B3%E5%BB%BA%E8%AE%BE/",
            "title": "思想建设",
            "date_published": "2025-07-07T07:43:52.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"\\assets\\css\\APlayer.min.css\"><script src=\"\\assets\\js\\APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><div class=\"note info\">\n<p>自有记载以来，所有宝贵的思想。</p>\n</div>\n<h1 id=\"2025-07\"><a class=\"anchor\" href=\"#2025-07\">#</a> 2025-07</h1>\n<ul>\n<li>与其认定自己已经注定败局，不如相信自己将来能赢。</li>\n<li>一切事物都有两面性，正如一条发布到网上的评论，无论有多少人喷，一定会有站在你的立场，理解你支持你的人。风险与机遇并存，巨大的挑战背景下，一定伴有着令人垂涎的宝物。</li>\n<li>想让一个人成长、变强很简单，就是让他主动承担，担任领头人，主负责人。</li>\n</ul>\n",
            "tags": [
                "琐碎"
            ]
        },
        {
            "id": "https://yunhdan.github.io/research/2025-CVPR-Workshop-Mobile-AI-SRGB-Photo-Enhancement-Challenge-Report%E7%A0%94%E7%A9%B6%E6%80%9D%E8%80%83/",
            "url": "https://yunhdan.github.io/research/2025-CVPR-Workshop-Mobile-AI-SRGB-Photo-Enhancement-Challenge-Report%E7%A0%94%E7%A9%B6%E6%80%9D%E8%80%83/",
            "title": "2025 CVPR Workshop - Mobile AI SRGB Photo Enhancement Challenge Report研究思考",
            "date_published": "2025-07-02T14:38:47.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"\\assets\\css\\APlayer.min.css\"><script src=\"\\assets\\js\\APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h1 id=\"dahua-iig-team\"><a class=\"anchor\" href=\"#dahua-iig-team\">#</a> DaHua-IIG Team</h1>\n<p><img data-src=\"../../assets/cvprw1.png\" alt=\"image\" /></p>\n<p><strong>思考</strong>：</p>\n",
            "tags": [
                "学术"
            ]
        },
        {
            "id": "https://yunhdan.github.io/cs/Linux/",
            "url": "https://yunhdan.github.io/cs/Linux/",
            "title": "Linux",
            "date_published": "2025-07-01T15:39:51.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"\\assets\\css\\APlayer.min.css\"><script src=\"\\assets\\js\\APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h1 id=\"关于移动命令mv\"><a class=\"anchor\" href=\"#关于移动命令mv\">#</a> 关于移动命令 <code>mv</code></h1>\n<p>移动某个文件夹中所有内容到另一个文件夹内：</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token function\">mv</span> /path/to/source/folder/* /path/to/destination/folder/</pre></td></tr></table></figure><p>但是，如果源文件夹的文件量过大，就会报这样的错误：</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>bash: /usr/bin/mv: 参数列表过长</pre></td></tr></table></figure><p>当使用通配符  <code>*</code>  扩展的文件数量超过了系统允许的最大命令行参数限制时就会报这个错误。这是 Linux 系统的一个保护机制，防止用户意外执行可能破坏系统的命令。</p>\n<p>用这个命令替代以解决：</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token function\">find</span> /path/to/source/folder/* <span class=\"token parameter variable\">-mindepth</span> <span class=\"token number\">1</span> <span class=\"token parameter variable\">-maxdepth</span> <span class=\"token number\">1</span> <span class=\"token parameter variable\">-print0</span> <span class=\"token operator\">|</span> <span class=\"token function\">xargs</span> <span class=\"token parameter variable\">-0</span> <span class=\"token function\">mv</span> <span class=\"token parameter variable\">-t</span> /path/to/destination/folder/</pre></td></tr></table></figure><h1 id=\"查看某个文件夹下有多少个文件\"><a class=\"anchor\" href=\"#查看某个文件夹下有多少个文件\">#</a> 查看某个文件夹下有多少个文件</h1>\n<p>配合 <code>ls</code>  和 <code>wc</code>  使用：</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token function\">ls</span> /path/to/source/folder <span class=\"token operator\">|</span> <span class=\"token function\">wc</span> <span class=\"token parameter variable\">-l</span></pre></td></tr></table></figure><h1 id=\"export-pythonpathpwdpythonpath\"><a class=\"anchor\" href=\"#export-pythonpathpwdpythonpath\">#</a>  <code>export PYTHONPATH=&quot;$PWD:$PYTHONPATH&quot;</code></h1>\n<p>这是一个通过 <code>PYTHONPATH</code>  手动指定项目根目录的命令。</p>\n<p>以深度学习项目 <code>Retinexformer</code>  为例，这个项目文件夹内包含了训练的代码 <code>train.py</code> ，以及模型架构文件等。</p>\n<p>有时候直接在终端通过 <code>python train.py</code>  的绝对路径会报一些代码文件中的库引用错误，但是你反复检查了路径，觉得代码里导包的方式没问题。</p>\n<p>这时候你就可以先通过 <code>cd</code>  命令进入项目文件夹中，然后再执行这个 <code>export</code>  命令手动指定项目根目录：</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token operator\">></span> <span class=\"token builtin class-name\">cd</span> Retinexformer</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token operator\">></span> <span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">PYTHONPATH</span><span class=\"token operator\">=</span><span class=\"token string\">\"<span class=\"token environment constant\">$PWD</span>:<span class=\"token variable\">$PYTHONPATH</span>\"</span></pre></td></tr></table></figure><h1 id=\"当linux内存不足时扩大交换空间\"><a class=\"anchor\" href=\"#当linux内存不足时扩大交换空间\">#</a> 当 <code>Linux</code>  内存不足时，扩大交换空间</h1>\n<p>首先要处理一下现有的交换文件：</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 查看当前启用的交换空间</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token function\">sudo</span> <span class=\"token function\">swapon</span> <span class=\"token parameter variable\">--show</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token comment\"># 如果存在 /swapfile，先关闭交换文件</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token function\">sudo</span> swapoff /swapfile</pre></td></tr><tr><td data-num=\"6\"></td><td><pre></pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token comment\"># 删除旧的交换文件</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token function\">sudo</span> <span class=\"token function\">rm</span> /swapfile</pre></td></tr></table></figure><p>然后创建一个更大内存的交换文件：</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 创建 8GB 交换文件</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token function\">sudo</span> fallocate <span class=\"token parameter variable\">-l</span> 8G /swapfile</pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token function\">sudo</span> <span class=\"token function\">chmod</span> <span class=\"token number\">600</span> /swapfile</pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token function\">sudo</span> <span class=\"token function\">mkswap</span> /swapfile</pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token function\">sudo</span> <span class=\"token function\">swapon</span> /swapfile</pre></td></tr></table></figure>",
            "tags": [
                "计算机"
            ]
        },
        {
            "id": "https://yunhdan.github.io/other/%E7%BE%BD%E6%AF%9B%E7%90%832/",
            "url": "https://yunhdan.github.io/other/%E7%BE%BD%E6%AF%9B%E7%90%832/",
            "title": "羽毛球2",
            "date_published": "2025-06-23T15:15:22.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"\\assets\\css\\APlayer.min.css\"><script src=\"\\assets\\js\\APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><div class=\"note info\">\n<p>25 年 6 月 23 日，今日单挑一名对手，明明感觉并不强，差不多，但是就是打不过。经过反思，在全方面的技术上要落后一筹，故决定今后系统地学习羽毛球。</p>\n</div>\n<h1 id=\"正手龙卷风搓球\"><a class=\"anchor\" href=\"#正手龙卷风搓球\">#</a> 正手龙卷风搓球</h1>\n<p>\n<div style=\"position: relative; width: 100%; height: 0; padding-bottom: 75%;\">\n<iframe src=\"//player.bilibili.com/player.html?isOutside=true&aid=113409198789085&bvid=BV1Z9SZYdEBn&cid=26571309405&p=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\"\nstyle=\"position:absolute; height: 100%; width: 100%;\"></iframe>\n</div>\n</p>\n<p>总结要点：</p>\n<ul>\n<li>跑到位，抢到高点。</li>\n<li>横着搓，搓球点在胸口。如果球低，就是压腿降低重心，搓球点保持在胸口，肩以上。</li>\n<li>龙卷风式搓球转的关键是，引完拍，球就差不多快接触到拍面，这样一刚要发力就会搓到，这样就会很转。</li>\n<li>龙卷风式搓球一般在身体正前面搓。</li>\n</ul>\n<h1 id=\"展搓\"><a class=\"anchor\" href=\"#展搓\">#</a> 展搓</h1>\n<p>\n<div style=\"position: relative; width: 100%; height: 0; padding-bottom: 75%;\">\n<iframe src=\"//player.bilibili.com/player.html?isOutside=true&aid=1606338008&bvid=BV1Tm42137xB&cid=1623571024&p=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\"\nstyle=\"position:absolute; height: 100%; width: 100%;\"></iframe>\n</div>\n</p>\n",
            "tags": [
                "琐碎"
            ]
        },
        {
            "id": "https://yunhdan.github.io/cs/Springboot%E3%80%81Mybatis/",
            "url": "https://yunhdan.github.io/cs/Springboot%E3%80%81Mybatis/",
            "title": "Springboot、Mybatis",
            "date_published": "2025-06-19T05:57:13.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"\\assets\\css\\APlayer.min.css\"><script src=\"\\assets\\js\\APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h1 id=\"mybatis是怎么防止sql注入的\"><a class=\"anchor\" href=\"#mybatis是怎么防止sql注入的\">#</a> Mybatis 是怎么防止 SQL 注入的？</h1>\n<ul>\n<li>这篇文章介绍了什么是 SQL 注入，以及 Mybatis 是怎么防止注入的，算是填补一下当时做项目不求甚解带来的漏洞：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzQ4MTIzNC9hcnRpY2xlL2RldGFpbHMvMTIwOTUwMDAz\">https://blog.csdn.net/weixin_43481234/article/details/120950003</span></li>\n</ul>\n",
            "tags": [
                "计算机"
            ]
        },
        {
            "id": "https://yunhdan.github.io/cs/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97/",
            "url": "https://yunhdan.github.io/cs/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97/",
            "title": "边缘计算",
            "date_published": "2025-06-18T13:10:03.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"\\assets\\css\\APlayer.min.css\"><script src=\"\\assets\\js\\APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h1 id=\"tflite-gpu-delegate\"><a class=\"anchor\" href=\"#tflite-gpu-delegate\">#</a> TFlite GPU Delegate</h1>\n<ul>\n<li>这篇算是比较通俗易懂地简要概览一下 TFlite GPU Delegate 的文章了：<span class=\"exturl\" data-url=\"aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8xNDM1NjEwNDA=\">https://zhuanlan.zhihu.com/p/143561040</span></li>\n</ul>\n",
            "tags": [
                "计算机"
            ]
        },
        {
            "id": "https://yunhdan.github.io/cs/Conda%E3%80%81Pip%E3%80%81Cuda/",
            "url": "https://yunhdan.github.io/cs/Conda%E3%80%81Pip%E3%80%81Cuda/",
            "title": "Conda、Pip、Cuda",
            "date_published": "2025-06-17T16:00:00.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"\\assets\\css\\APlayer.min.css\"><script src=\"\\assets\\js\\APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h1 id=\"安装mamba_ssm和causal_conv1d\"><a class=\"anchor\" href=\"#安装mamba_ssm和causal_conv1d\">#</a> 安装 mamba_ssm 和 causal_conv1d</h1>\n<ul>\n<li>Windows 居然也支持 mamba_ssim 和 causal_conv1d 了：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1MTAwMjAwL2FydGljbGUvZGV0YWlscy8xMzk3NTQyMzE=\">https://blog.csdn.net/qq_45100200/article/details/139754231</span></li>\n</ul>\n<h1 id=\"cuda系列\"><a class=\"anchor\" href=\"#cuda系列\">#</a> cuda 系列</h1>\n<ul>\n<li>简要介绍 cudatoolkit 和 CUDA Toolkit 的区别：<span class=\"exturl\" data-url=\"aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8yNzQzNDA5MTEzNQ==\">https://zhuanlan.zhihu.com/p/27434091135</span></li>\n<li>进一步详解 CUDA 和 cudatoolkit，拓展至 cudnn 和 nvcc：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMDk0MDU4L2FydGljbGUvZGV0YWlscy8xMTYyMDczMzM=\">https://blog.csdn.net/qq_41094058/article/details/116207333</span></li>\n</ul>\n",
            "tags": [
                "计算机"
            ]
        },
        {
            "id": "https://yunhdan.github.io/ai/%E7%8E%B0%E4%BB%A3%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/",
            "url": "https://yunhdan.github.io/ai/%E7%8E%B0%E4%BB%A3%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/",
            "title": "现代深度学习",
            "date_published": "2025-06-17T07:25:31.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"\\assets\\css\\APlayer.min.css\"><script src=\"\\assets\\js\\APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h1 id=\"知识蒸馏方法\"><a class=\"anchor\" href=\"#知识蒸馏方法\">#</a> 知识蒸馏方法</h1>\n<ul>\n<li>一文了解知识蒸馏，通俗易懂：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzY5NDA5Ni9hcnRpY2xlL2RldGFpbHMvMTI3NTA1OTQ2\">https://blog.csdn.net/weixin_43694096/article/details/127505946</span></li>\n</ul>\n<h1 id=\"重参数化技术\"><a class=\"anchor\" href=\"#重参数化技术\">#</a> 重参数化技术</h1>\n<ul>\n<li>重参数化的 2 篇根基论文 <code>RepVGG</code>  和 <code>RepMLP</code> ：<span class=\"exturl\" data-url=\"aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8zNzA0Mzg5OTk=\">https://zhuanlan.zhihu.com/p/370438999</span></li>\n</ul>\n<h1 id=\"ntire图像恢复赛事\"><a class=\"anchor\" href=\"#ntire图像恢复赛事\">#</a>  <code>NTIRE</code>  图像恢复赛事</h1>\n<ul>\n<li>23 年超分辨率赛道技术报告解读，文末有赛事原报告：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzgwMDU3Ny9hcnRpY2xlL2RldGFpbHMvMTMxNjY4Nzgy\">https://blog.csdn.net/weixin_43800577/article/details/131668782</span></li>\n</ul>\n<h1 id=\"显存占用\"><a class=\"anchor\" href=\"#显存占用\">#</a> 显存占用</h1>\n<ul>\n<li>分析显存占用的内在机理：<span class=\"exturl\" data-url=\"aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC82NDE4OTQwMTQ=\">https://zhuanlan.zhihu.com/p/641894014</span></li>\n</ul>\n",
            "tags": [
                "人工智能"
            ]
        },
        {
            "id": "https://yunhdan.github.io/cs/Pytorch/",
            "url": "https://yunhdan.github.io/cs/Pytorch/",
            "title": "Pytorch",
            "date_published": "2025-06-13T05:14:06.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"\\assets\\css\\APlayer.min.css\"><script src=\"\\assets\\js\\APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h1 id=\"pytorch算子\"><a class=\"anchor\" href=\"#pytorch算子\">#</a> Pytorch 算子</h1>\n<ul>\n<li>简要介绍算子：<span class=\"exturl\" data-url=\"aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC81NzQxNjY5MjA=\">https://zhuanlan.zhihu.com/p/574166920</span></li>\n</ul>\n<h1 id=\"矩阵乘法-矩阵点乘\"><a class=\"anchor\" href=\"#矩阵乘法-矩阵点乘\">#</a> 矩阵乘法、矩阵点乘</h1>\n<ul>\n<li>这篇分别为矩阵乘法和矩阵点乘介绍了两种广义算子：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNzI4NjY3L2FydGljbGUvZGV0YWlscy8xMzQwMTM4OTk=\">https://blog.csdn.net/qq_40728667/article/details/134013899</span></li>\n</ul>\n<h1 id=\"关于num_worker\"><a class=\"anchor\" href=\"#关于num_worker\">#</a> 关于 num_worker</h1>\n<ul>\n<li>简明扼要地介绍 pytorch 中 dataloader 的 num_worker：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI4MDU3Mzc5L2FydGljbGUvZGV0YWlscy8xMTU0MjcwNTI=\">https://blog.csdn.net/qq_28057379/article/details/115427052</span></li>\n<li>一些关于 num_worker 的独特思考：<span class=\"exturl\" data-url=\"aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC82NDUzNjQwODk=\">https://zhuanlan.zhihu.com/p/645364089</span></li>\n</ul>\n",
            "tags": [
                "计算机"
            ]
        },
        {
            "id": "https://yunhdan.github.io/cs/Flask/",
            "url": "https://yunhdan.github.io/cs/Flask/",
            "title": "Flask",
            "date_published": "2025-06-13T05:10:41.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"\\assets\\css\\APlayer.min.css\"><script src=\"\\assets\\js\\APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h1 id=\"安装\"><a class=\"anchor\" href=\"#安装\">#</a> 安装</h1>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>pip <span class=\"token function\">install</span> Flask</pre></td></tr></table></figure><h1 id=\"overview-铺垫资料\"><a class=\"anchor\" href=\"#overview-铺垫资料\">#</a> Overview、铺垫资料</h1>\n<p>参考资料：</p>\n<ul>\n<li><span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cucnVub29iLmNvbS9mbGFzay9mbGFzay10dXRvcmlhbC5odG1s\">Flask 教程 | 菜鸟教程</span></li>\n<li><span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cucnVub29iLmNvbS9mbGFzay9mbGFzay1iYXNpYy1jb25jZXB0Lmh0bWw=\">Flask 基本概念 | 菜鸟教程</span></li>\n<li><span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cucnVub29iLmNvbS9mbGFzay9mbGFzay1sYXlvdXQuaHRtbA==\">Flask 项目结构 | 菜鸟教程</span></li>\n</ul>\n<p>这部分主要是了解 Flask 的背景。同时了解路由、视图函数、请求对象和响应对象、模板文件、应用工厂、蓝图、配置对象、静态文件是什么。了解 Flask 的项目结构如何。</p>\n",
            "tags": [
                "计算机"
            ]
        },
        {
            "id": "https://yunhdan.github.io/cs/Vue/",
            "url": "https://yunhdan.github.io/cs/Vue/",
            "title": "Vue",
            "date_published": "2025-06-13T05:07:55.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"\\assets\\css\\APlayer.min.css\"><script src=\"\\assets\\js\\APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h1 id=\"循环语句\"><a class=\"anchor\" href=\"#循环语句\">#</a> 循环语句</h1>\n<p>参考资料：</p>\n<ul>\n<li><span class=\"exturl\" data-url=\"aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hTTF9IUi9hcnRpY2xlL2RldGFpbHMvMTI3MzEyNjMyP29wc19yZXF1ZXN0X21pc2M9JTdCJTIycmVxdWVzdCU1RmlkJTIyJTNBJTIyY2JhNzE1ZjNiNzcwOTk1MDVlNzRhOGNlMmUzYzE3MmMlMjIlMkMlMjJzY20lMjIlM0ElMjIyMDE0MDcxMy4xMzAxMDIzMzQuLiUyMiU3RCZhbXA7cmVxdWVzdF9pZD1jYmE3MTVmM2I3NzA5OTUwNWU3NGE4Y2UyZTNjMTcyYyZhbXA7Yml6X2lkPTAmYW1wO3V0bV9tZWRpdW09ZGlzdHJpYnV0ZS5wY19zZWFyY2hfcmVzdWx0Lm5vbmUtdGFzay1ibG9nLTJ+YWxsfnRvcF9wb3NpdGl2ZX5kZWZhdWx0LTEtMTI3MzEyNjMyLW51bGwtbnVsbC4xNDIlNUV2MTAyJTVFcGNfc2VhcmNoX3Jlc3VsdF9iYXNlMyZhbXA7dXRtX3Rlcm09di1mb3ImYW1wO3NwbT0xMDE4LjIyMjYuMzAwMS40MTg3\">vue3【列表渲染】v-for 详细介绍（vue 中的 “循环”）_vue3 v-for-CSDN 博客</span></li>\n<li><span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cucnVub29iLmNvbS92dWUzL3Z1ZTMtdi1mb3IuaHRtbA==\">Vue3 循环语句 | 菜鸟教程</span></li>\n</ul>\n<p>主要围绕如何使用 v-for 遍历数组、对象。v-for 的几种基本用法要掌握。</p>\n<h1 id=\"安装vue项目\"><a class=\"anchor\" href=\"#安装vue项目\">#</a> 安装 Vue 项目</h1>\n<p>参考资料：</p>\n<ul>\n<li><span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cucnVub29iLmNvbS92dWUzL3Z1ZTMtaW5zdGFsbC5odG1s\">Vue3 安装 | 菜鸟教程</span></li>\n<li><span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cucnVub29iLmNvbS92dWUzL3Z1ZTMtY3JlYXRlLXByb2plY3QuaHRtbA==\">Vue3 创建项目 | 菜鸟教程</span></li>\n</ul>\n<h1 id=\"vue项目结构说明\"><a class=\"anchor\" href=\"#vue项目结构说明\">#</a> Vue 项目结构说明</h1>\n<p>参考资料：</p>\n<ul>\n<li><span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cucnVub29iLmNvbS92dWUzL3Z1ZTMtcHJvamVjdC1pbnRyby5odG1s\">Vue3 项目说明 | 菜鸟教程</span></li>\n</ul>\n",
            "tags": [
                "计算机"
            ]
        },
        {
            "id": "https://yunhdan.github.io/research/%E5%A4%9A%E6%A8%A1%E6%80%81%E8%AE%BA%E6%96%87%E7%B2%BE%E7%82%BC/",
            "url": "https://yunhdan.github.io/research/%E5%A4%9A%E6%A8%A1%E6%80%81%E8%AE%BA%E6%96%87%E7%B2%BE%E7%82%BC/",
            "title": "多模态论文精炼",
            "date_published": "2025-06-04T03:04:06.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"\\assets\\css\\APlayer.min.css\"><script src=\"\\assets\\js\\APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h1 id=\"clip工作\"><a class=\"anchor\" href=\"#clip工作\">#</a>  <code>CLIP</code>  工作</h1>\n<h2 id=\"2021-learning-transferable-visual-models-from-natural-language-supervisionclip\"><a class=\"anchor\" href=\"#2021-learning-transferable-visual-models-from-natural-language-supervisionclip\">#</a>  <code>2021 Learning Transferable Visual Models From Natural Language Supervision(CLIP)</code></h2>\n<p><img data-src=\"../../assets/clip.png\" alt=\"image\" /></p>\n<blockquote>\n<p>学习自朱毅老师的 <code>CLIP</code>  逐段精读。</p>\n</blockquote>\n<p><strong>贡献</strong>：</p>\n<ul>\n<li>（1）通过文本和图像的对比学习，模型学习到文本 - 图像对的匹配关系。</li>\n<li>（2）能够实现通过给定一张图像，在多个文本标签中选择出与图像最相关的文本。也可以实现给定一个文本，选择最符合相关的图像。</li>\n</ul>\n<p><strong>创新</strong>：</p>\n<ul>\n<li>实现文本与图像的多模态学习。</li>\n<li>实现实现无标签限制的图像分类，也可以实现无图像限制的文本 - 图像配对。前者可以用于图像中的物体识别，后者可以用于文本检索图像。</li>\n</ul>\n<p><strong> <code>CLIP</code>  对比学习训练代码</strong>：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># image_encoder - ResNet 或者 Vision Transformer</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token comment\"># text_encoder - CBOW 或者 Text Transformer</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token comment\"># I [n, h, w, c] - 图像形状</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token comment\"># T [n, l] - 文本形状，l 是序列长度</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token comment\"># W_i [d_i, d_e] - 图像的线性投射矩阵</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token comment\"># W_t [d_t, d_e] - 文本的线性投射矩阵</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token comment\"># t - learned temperature parameter</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre></pre></td></tr><tr><td data-num=\"9\"></td><td><pre><span class=\"token comment\"># 分别提取图像特征和文本特征</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>I_f <span class=\"token operator\">=</span> image_encoder<span class=\"token punctuation\">(</span>I<span class=\"token punctuation\">)</span> <span class=\"token comment\">#[n, d_i]</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>T_f <span class=\"token operator\">=</span> text_encoder<span class=\"token punctuation\">(</span>T<span class=\"token punctuation\">)</span> <span class=\"token comment\">#[n, d_t]</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre></pre></td></tr><tr><td data-num=\"13\"></td><td><pre><span class=\"token comment\"># 对两个特征进行线性投射，得到相同维度的特征，并进行 l2 归一化</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>I_e <span class=\"token operator\">=</span> l2_normalize<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>dot<span class=\"token punctuation\">(</span>I_f<span class=\"token punctuation\">,</span> W_i<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>T_e <span class=\"token operator\">=</span> l2_normalize<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>dot<span class=\"token punctuation\">(</span>T_f<span class=\"token punctuation\">,</span> W_t<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre></pre></td></tr><tr><td data-num=\"17\"></td><td><pre><span class=\"token comment\"># 计算缩放的余弦相似度：[n, n]</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>logits <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>dot<span class=\"token punctuation\">(</span>I_e<span class=\"token punctuation\">,</span> T_e<span class=\"token punctuation\">.</span>T<span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> np<span class=\"token punctuation\">.</span>exp<span class=\"token punctuation\">(</span>t<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre></pre></td></tr><tr><td data-num=\"20\"></td><td><pre><span class=\"token comment\"># 对称的对比学习损失：等价于 N 个类别的 cross_entropy_loss</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>labels <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>arange<span class=\"token punctuation\">(</span>n<span class=\"token punctuation\">)</span> <span class=\"token comment\"># 对角线元素的 labels</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre>loss_i <span class=\"token operator\">=</span> cross_entropy_loss<span class=\"token punctuation\">(</span>logits<span class=\"token punctuation\">,</span> labels<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>loss_t <span class=\"token operator\">=</span> cross_entropy_loss<span class=\"token punctuation\">(</span>logits<span class=\"token punctuation\">,</span> labels<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre>loss <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>loss_i <span class=\"token operator\">+</span> loss_t<span class=\"token punctuation\">)</span><span class=\"token operator\">/</span><span class=\"token number\">2</span></pre></td></tr></table></figure><h1 id=\"多模态在分割的应用\"><a class=\"anchor\" href=\"#多模态在分割的应用\">#</a> 多模态在分割的应用</h1>\n<h2 id=\"2022-iclr-language-driven-semantic-segmentationlseg\"><a class=\"anchor\" href=\"#2022-iclr-language-driven-semantic-segmentationlseg\">#</a>  <code>2022 ICLR Language-driven semantic segmentation(LSeg)</code></h2>\n<p><img data-src=\"../../assets/lseg1.jpg\" alt=\"image\" /></p>\n<blockquote>\n<p>学习自朱毅老师的逐段精读。</p>\n</blockquote>\n<p><strong>贡献</strong>：</p>\n<ul>\n<li>将 <code>CLIP</code>  的原始文本编码器作为需分割的物体标签的文本编码器，以充分提取文本特征。</li>\n<li>将文本特征与图像特征通过矩阵相乘融合得到多模态特征，上采样后与 <code>Ground-truth</code>  在像素级使用 <code>cross entropy loss</code>  进行训练。</li>\n<li>测试时可以实现，根据需要分割的对象的文本标签，分割特定图像的内容。</li>\n</ul>\n<p><strong>创新</strong>：</p>\n<ul>\n<li>一篇把 <code>CLIP</code>  模型运用到分割任务且有效果的工作。</li>\n<li>采用监督学习的方式训练，而不是对比学习去训练，也是为了更好地与特定分割任务适应。</li>\n</ul>\n<p><strong>不足</strong>：</p>\n<ul>\n<li>依然是有监督学习，目标函数不是对比学习的目标函数。</li>\n<li>文本特征只是用于融合多模态特征，并没有提供监督信号。</li>\n<li>依然依赖于手工标注 <code>segmentation mask</code> 。</li>\n</ul>\n<p>（可以做识别物体位置的实践）</p>\n<h2 id=\"2022-cvpr-groupvitsemantic-segmentation-emerges-from-text-supervisiongroupvit\"><a class=\"anchor\" href=\"#2022-cvpr-groupvitsemantic-segmentation-emerges-from-text-supervisiongroupvit\">#</a>  <code>2022 CVPR GroupViT:Semantic Segmentation Emerges from Text Supervision(GroupViT)</code></h2>\n<p><img data-src=\"../../assets/groupvit1.jpg\" alt=\"image\" /></p>\n<blockquote>\n<p>学习自朱毅老师的逐段精读。</p>\n<p>这篇是分割采用无监督学习的思路。主要使用的是分割中的 <code>Grouping</code>  思想。展开来讲， <code>Grouping</code>  将图像分割做为一种聚类任务，首先在图像确定聚类中心点，然后在模型训练的过程中，不断学习聚类中心周围像素点与聚类中心的相互关系，将与聚类中心相关的像素点并入该聚类中心的 <code>Group</code>  中。</p>\n</blockquote>\n<p><strong>贡献</strong>：</p>\n<ul>\n<li>使用了文本作为监督信号训练分割任务，不再依赖人工标注的图像 <code>Ground-Truth</code> 。</li>\n<li>使用 <code>Vision Transformer</code>  作为图像编码器。在每个 <code>Transformer</code>  层的输入 <code>tokens</code>  中加入若干个 <code>group tokens</code> ，这些 <code>group tokens</code>  实际上就是预先设想的聚类中心数，也就是猜测的图像有哪些物体类别。经过多个 <code>Transformer Layer</code> ， <code>Image tokens</code>  和这几个 <code>group tokens</code>  之间的关系被自注意力不断建模与学习。与特定聚类中心接近的 <code>image tokens</code> ，其特征也越接近该 <code>group token</code>  的特征。</li>\n<li>多个 <code>Transformer</code>  层后跟一个 <code>Grouping Block</code>  层。 <code>Grouping Block</code>  的本质是一个交叉注意力机制，将 <code>Image tokens</code>  并入所属的 <code>Group tokens</code> 。每个 <code>Grouping Block</code>  都将总 <code>tokens</code>  数降低，因此也减小了计算成本。</li>\n<li>使用对比学习的方式进行训练，带监督信号的文本被编码后的特征与最后的图像 <code>tokens</code>  特征两者交叉熵损失。</li>\n</ul>\n<p><strong>创新</strong>：</p>\n<ul>\n<li>首先使用了文本标注分割的 <code>Ground-Truth</code> ，不再依赖繁琐的手工标注。</li>\n</ul>\n<p><strong>不足</strong>：</p>\n<ul>\n<li>只能分割特定数量的类别，无法分割任意数量的物体。测试时，必须指定分割物体的数目，最后得到模型输出的 <code>tokens</code>  与文本标签进行余弦相似度的计算，确定分割物体的文本标签。</li>\n<li>训练中没有侧重语义信息，仅训练出了较好的分割能力。</li>\n</ul>\n<p><img data-src=\"../../assets/groupvit2.jpg\" alt=\"image\" /></p>\n<p>（测试时，模型输出了两个 <code>token</code> ，我们指定分割物体的文本标签有 <code>table、dog...potted plant</code> ，于是可以使用余弦相似度计算得到一个相似度矩阵。对每行取最大的值，对应的文本标签即为该 <code>token</code>  的类别）</p>\n<h1 id=\"多模态在检测的应用\"><a class=\"anchor\" href=\"#多模态在检测的应用\">#</a> 多模态在检测的应用</h1>\n<h2 id=\"2022-cvpr-grounded-language-image-pre-trainingglip\"><a class=\"anchor\" href=\"#2022-cvpr-grounded-language-image-pre-trainingglip\">#</a>  <code>2022 CVPR Grounded Language-Image Pre-training(Glip)</code></h2>\n<p><img data-src=\"../../assets/glip1.jpg\" alt=\"image\" /></p>\n<blockquote>\n<p>学习自朱毅老师的逐段精读。</p>\n<p>与常规目标检测任务相关的一个任务是 <code>Vision Grounding</code> 。具体是根据提供的文本，在图片中找到文本中出现的物体的位置。</p>\n</blockquote>\n<p><strong>贡献</strong>：</p>\n<ul>\n<li>参考 <code>CLIP</code>  范式，将图像的 <code>Bounding box</code>  的 <code>region</code>  输入图像编码器，将提供的文本输入文本编码器，最后得到每个 <code>Bounding box</code>  与单词的相似度矩阵。在相似度矩阵上与 <code>Ground-Truth</code>  的相似度矩阵求定位损失 <code>Localization Loss</code>  和分类损失 <code>Alignment Loss</code>  即可完成训练。</li>\n<li>为了更加充分地学习 <code>Bounding box</code>  和文本的 <code>Joint Feature</code> ，也就是多模态特征。在最后的特征相似度计算前，使用交叉注意力对图像特征和文本特征进行多层交互学习，即 <code>Deep Fusion</code> 。</li>\n</ul>\n<p><strong>创新</strong>：</p>\n<ul>\n<li>使用 <code>Deep Fusion</code>  技术以辅助学习多模态特征。</li>\n<li>将 <code>Gounding</code>  任务与目标检测任务很好地结合，并借鉴 <code>CLIP</code>  的思想做大规模数据的预训练，成功取得了很好的 <code>Zero-shot</code>  效果。</li>\n</ul>\n",
            "tags": [
                "学术"
            ]
        },
        {
            "id": "https://yunhdan.github.io/baoyan/Low-level-Vision-Group/",
            "url": "https://yunhdan.github.io/baoyan/Low-level-Vision-Group/",
            "title": "Low-level-Vision-Group",
            "date_published": "2025-06-03T03:08:17.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"\\assets\\css\\APlayer.min.css\"><script src=\"\\assets\\js\\APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><div class=\"note info\">\n<p>做底层视觉的团队，供保研用。</p>\n</div>\n<details class=\"danger\"><summary>注意</summary><div>\n<p>请做好心理准备，这些导师都很强，申请做他们的学生，在面试考核中一定是会被拷打的。对方的学术水平，能力水平本身就在你之上，你的任何漏洞、问题、毛病都会被看得一清二楚。所以想要做到让对方完全满意是不太可能的，要做好这个心理建设。</p>\n</div></details>\n<h1 id=\"中山大学-网络空间安全学院\"><a class=\"anchor\" href=\"#中山大学-网络空间安全学院\">#</a> 中山大学 - 网络空间安全学院</h1>\n<ul>\n<li>任文琦：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9zaXRlcy5nb29nbGUuY29tL3ZpZXcvd2VucWlyZW4vaG9tZXBhZ2U=\">https://sites.google.com/view/wenqiren/homepage</span></li>\n</ul>\n<p>这个老师特别强，我发过 email2 次都是已阅没回，没看上我。</p>\n<h1 id=\"厦门大学-信息学院\"><a class=\"anchor\" href=\"#厦门大学-信息学院\">#</a> 厦门大学 - 信息学院</h1>\n<ul>\n<li>丁兴号：<span class=\"exturl\" data-url=\"aHR0cHM6Ly94bXUtc21hcnRkc3AuZ2l0aHViLmlvLw==\">https://xmu-smartdsp.github.io/</span></li>\n</ul>\n<p>没有联系过，没有实验室主页，情况未知。</p>\n<h1 id=\"南开大学-密码与网络空间安全学院\"><a class=\"anchor\" href=\"#南开大学-密码与网络空间安全学院\">#</a> 南开大学 - 密码与网络空间安全学院</h1>\n<ul>\n<li>程明明实验室李重仪，郭春乐：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9tbWNoZW5nLm5ldC9yZWNydWl0L2NvbW1lbnQtcGFnZS0yNS8=\">https://mmcheng.net/recruit/comment-page-25/</span></li>\n</ul>\n<p>底层视觉顶级组，考核贼强，六级要 480+。考核差不多相当于用 c++ 复现一篇传统论文，感觉非常困难故未考虑。</p>\n<h1 id=\"东南大学-计算机科学与工程学院\"><a class=\"anchor\" href=\"#东南大学-计算机科学与工程学院\">#</a> 东南大学 - 计算机科学与工程学院</h1>\n<ul>\n<li>薛晖：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9wYWxtLnNldS5lZHUuY24vaHh1ZS8=\">https://palm.seu.edu.cn/hxue/</span></li>\n</ul>\n<p>这个是有名的 palm 实验室，不放实习，不建议去。</p>\n<h1 id=\"中山大学-计算机学院\"><a class=\"anchor\" href=\"#中山大学-计算机学院\">#</a> 中山大学 - 计算机学院</h1>\n<ul>\n<li>李冠彬：<span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cuc3lzdS1oY3AubmV0L2ZhY3VsdHkvbGlndWFuYmluLmh0bWw=\">https://www.sysu-hcp.net/faculty/liguanbin.html</span></li>\n<li>张冬雨：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9jc2Uuc3lzdS5lZHUuY24vdGVhY2hlci9aaGFuZ0Rvbmd5dQ==\">https://cse.sysu.edu.cn/teacher/ZhangDongyu</span></li>\n</ul>\n<p>联系过李老师 2 次，但是都没有看上我，没回信。</p>\n<h1 id=\"南京理工大学-计算机科学与工程学院\"><a class=\"anchor\" href=\"#南京理工大学-计算机科学与工程学院\">#</a> 南京理工大学 - 计算机科学与工程学院</h1>\n<ul>\n<li>潘金山：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9qc3Bhbi5naXRodWIuaW8v\">https://jspan.github.io/</span></li>\n</ul>\n<p>这个老师做 low level 特别强。</p>\n<h1 id=\"北京大学-信息工程学院深圳\"><a class=\"anchor\" href=\"#北京大学-信息工程学院深圳\">#</a> 北京大学 - 信息工程学院（深圳）</h1>\n<ul>\n<li>张健：<span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cuZWNlLnBrdS5lZHUuY24vaW5mby8xMDQ2LzI1MDYuaHRt\">https://www.ece.pku.edu.cn/info/1046/2506.htm</span></li>\n</ul>\n<p>老师很强，听说对学生也很温和友好。我联系过 2 次，均未搭理，没回信。看了一下他实验室的学生的来向，基本全是 9 和 2，双非和四非根本不可能。</p>\n<h1 id=\"哈尔滨工业大学-计算机学院\"><a class=\"anchor\" href=\"#哈尔滨工业大学-计算机学院\">#</a> 哈尔滨工业大学 - 计算机学院</h1>\n<ul>\n<li>左旺孟：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9ob21lcGFnZS5oaXQuZWR1LmNuL3dhbmdtZW5nenVv\">https://homepage.hit.edu.cn/wangmengzuo</span></li>\n</ul>\n<p>这个老师懂得都懂，low level 泰斗。听说对学生也相当好，人品也不错。但因为在本部太远，未考虑。</p>\n<h1 id=\"南京大学-智能科学与技术学院苏州\"><a class=\"anchor\" href=\"#南京大学-智能科学与技术学院苏州\">#</a> 南京大学 - 智能科学与技术学院（苏州）</h1>\n<ul>\n<li>张凯：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9jc3puLmdpdGh1Yi5pby8=\">https://cszn.github.io/</span></li>\n<li>邰颖：<span class=\"exturl\" data-url=\"aHR0cHM6Ly90eXNoaXdvLmdpdGh1Yi5pby9pbmRleC5odG1s\">https://tyshiwo.github.io/index.html</span></li>\n</ul>\n<p>联系过张凯老师，张凯老师人很好。第一次信没有回复，第二次在 follow 信发过去后很快就回信了，这个是第一个回信的老师，表示欢迎我来。虽然有点类似官回，但给我很大的鼓励。</p>\n<h1 id=\"北京师范大学-人工智能学院\"><a class=\"anchor\" href=\"#北京师范大学-人工智能学院\">#</a> 北京师范大学 - 人工智能学院</h1>\n<ul>\n<li>黄华：<span class=\"exturl\" data-url=\"aHR0cHM6Ly92bWNsLmJudS5lZHUuY24vZ3JvdXAvdGVhY2hlci9kY2RhZWE3OWI1ZTU0Yjc1YjUzMjc5NTEwOWE4NWEzNC5odG0=\">https://vmcl.bnu.edu.cn/group/teacher/dcdaea79b5e54b75b532795109a85a34.htm</span></li>\n</ul>\n<p>有点偏 low level 中的底层，与相机有关，感觉干不来。</p>\n<h1 id=\"南京大学-计算机学院\"><a class=\"anchor\" href=\"#南京大学-计算机学院\">#</a> 南京大学 - 计算机学院</h1>\n<ul>\n<li>路通：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9jcy5uanUuZWR1LmNuL2x1dG9uZy9pbmRleC5odG0=\">https://cs.nju.edu.cn/lutong/index.htm</span></li>\n</ul>\n<p>联系过但没有回复。</p>\n<h1 id=\"大连理工大学-国际信息科学与工程学院\"><a class=\"anchor\" href=\"#大连理工大学-国际信息科学与工程学院\">#</a> 大连理工大学 - 国际信息科学与工程学院</h1>\n<ul>\n<li>刘日升：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9yc2xpdS50ZWNoLw==\">https://rsliu.tech/</span></li>\n</ul>\n<p>这个老师同时也做机器人，很强。因为位置偏远，没有考虑。</p>\n<h1 id=\"四川大学-计算机学院\"><a class=\"anchor\" href=\"#四川大学-计算机学院\">#</a> 四川大学 - 计算机学院</h1>\n<ul>\n<li>彭玺：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9wZW5neGkubWUv\">https://pengxi.me/</span></li>\n</ul>\n<h1 id=\"电子科技大学-计算机科学与工程学院\"><a class=\"anchor\" href=\"#电子科技大学-计算机科学与工程学院\">#</a> 电子科技大学 - 计算机科学与工程学院</h1>\n<ul>\n<li>顾舒航：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9zaHVoYW5nZ3UuZ2l0aHViLmlvLw==\">https://shuhanggu.github.io/</span></li>\n</ul>\n<h1 id=\"天津大学-智能与计算学部\"><a class=\"anchor\" href=\"#天津大学-智能与计算学部\">#</a> 天津大学 - 智能与计算学部</h1>\n<ul>\n<li>郭晓杰：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9zaXRlcy5nb29nbGUuY29tL3ZpZXcveGpndW8=\">https://sites.google.com/view/xjguo</span></li>\n</ul>\n<p>很强，LIME 论文的团队。听说对学生也很好，联系过一次，没有回信，再次未被看上。</p>\n<h1 id=\"电子科技大学-信息与通信工程学院\"><a class=\"anchor\" href=\"#电子科技大学-信息与通信工程学院\">#</a> 电子科技大学 - 信息与通信工程学院</h1>\n<ul>\n<li>刘帅成：<span class=\"exturl\" data-url=\"aHR0cDovL3d3dy5saXVzaHVhaWNoZW5nLm9yZy8=\">http://www.liushuaicheng.org/</span></li>\n</ul>\n<p>很强，GLARE 论文的团队，依然是联系过后未被看上，没有回信。</p>\n<h1 id=\"中国科学技术大学\"><a class=\"anchor\" href=\"#中国科学技术大学\">#</a> 中国科学技术大学</h1>\n<ul>\n<li>李厚强：<span class=\"exturl\" data-url=\"aHR0cDovL3N0YWZmLnVzdGMuZWR1LmNuL35saWhxL2VuLw==\">http://staff.ustc.edu.cn/~lihq/en/</span></li>\n<li>熊志伟：<span class=\"exturl\" data-url=\"aHR0cDovL3N0YWZmLnVzdGMuZWR1LmNuL356d3hpb25nLw==\">http://staff.ustc.edu.cn/~zwxiong/</span></li>\n<li>刘东：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9mYWN1bHR5LnVzdGMuZWR1LmNuL2RvbmdlbGl1Lw==\">https://faculty.ustc.edu.cn/dongeliu/</span></li>\n<li>陈志波：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9mYWN1bHR5LnVzdGMuZWR1LmNuL2NoZW56aGliby8=\">https://faculty.ustc.edu.cn/chenzhibo/</span></li>\n</ul>\n<h1 id=\"武汉大学\"><a class=\"anchor\" href=\"#武汉大学\">#</a> 武汉大学</h1>\n<ul>\n<li>马佳义：<span class=\"exturl\" data-url=\"aHR0cDovL212cC53aHUuZWR1LmNuL2ppYXlpbWEv\">http://mvp.whu.edu.cn/jiayima/</span></li>\n</ul>\n<h1 id=\"西安电子科技大学\"><a class=\"anchor\" href=\"#西安电子科技大学\">#</a> 西安电子科技大学</h1>\n<ul>\n<li>董伟生：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9zZWUueGlkaWFuLmVkdS5jbi9mYWN1bHR5L3dzZG9uZy8=\">https://see.xidian.edu.cn/faculty/wsdong/</span></li>\n</ul>\n<p>联系过董老师 2 次，但都是没有打开看我的信。</p>\n<h1 id=\"西安交通大学\"><a class=\"anchor\" href=\"#西安交通大学\">#</a> 西安交通大学</h1>\n<ul>\n<li>孟德宇：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9nci54anR1LmVkdS5jbi93ZWIvZHltZW5n\">https://gr.xjtu.edu.cn/web/dymeng</span></li>\n</ul>\n<p>西交夏令营要本科学校计算机 a 评估。</p>\n<h1 id=\"华东师范大学\"><a class=\"anchor\" href=\"#华东师范大学\">#</a> 华东师范大学</h1>\n<ul>\n<li>谢源：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9mYWN1bHR5LmVjbnUuZWR1LmNuL19zMTYveHkyXzExMzQyL21haW4ucHNw\">https://faculty.ecnu.edu.cn/_s16/xy2_11342/main.psp</span></li>\n</ul>\n<p>风评未知，也没有团队主页，暂不考虑。</p>\n<h1 id=\"中科院深先所\"><a class=\"anchor\" href=\"#中科院深先所\">#</a> 中科院深先所</h1>\n<ul>\n<li>MMLab：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9tbWxhYi5zaWF0LmFjLmNuLw==\">https://mmlab.siat.ac.cn/</span></li>\n<li>董超：<span class=\"exturl\" data-url=\"aHR0cDovL3hwaXhlbC5ncm91cC8=\">http://xpixel.group/</span></li>\n</ul>\n<p>联系过董超老师 2 次，依然没有打开信看。</p>\n<h1 id=\"同济大学-计算机科学与技术学院软件学院\"><a class=\"anchor\" href=\"#同济大学-计算机科学与技术学院软件学院\">#</a> 同济大学 - 计算机科学与技术学院（软件学院）</h1>\n<ul>\n<li>张林：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9zc2UudG9uZ2ppLmVkdS5jbi9pbmZvLzEyMTIvNTA1Mi5odG0=\">https://sse.tongji.edu.cn/info/1212/5052.htm</span></li>\n</ul>\n<p>同济大学 bar 过高。</p>\n<h1 id=\"北京邮电大学-计算机学院\"><a class=\"anchor\" href=\"#北京邮电大学-计算机学院\">#</a> 北京邮电大学 - 计算机学院</h1>\n<ul>\n<li>明安龙：<span class=\"exturl\" data-url=\"aHR0cHM6Ly90ZWFjaGVyLmJ1cHQuZWR1LmNuL21hbA==\">https://teacher.bupt.edu.cn/mal</span></li>\n</ul>\n<p>联系过明老师，明老师做计算摄影、美学评估方向为主，方向有点不太 match。</p>\n<h1 id=\"北京邮电大学-人智学院\"><a class=\"anchor\" href=\"#北京邮电大学-人智学院\">#</a> 北京邮电大学 - 人智学院</h1>\n<ul>\n<li>鲁鹏：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9jdi14dWViYS5jbHViL3BhZ2VzL21lbWJlcnMvcGx1Lmh0bWw=\">https://cv-xueba.club/pages/members/plu.html</span></li>\n</ul>\n",
            "tags": [
                "保研"
            ]
        },
        {
            "id": "https://yunhdan.github.io/project/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%B0%8F%E5%AE%9E%E8%B7%B5%E2%80%94%E2%80%94%E6%9E%84%E5%BB%BAEnv%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%96%B9%E6%B3%95/",
            "url": "https://yunhdan.github.io/project/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%B0%8F%E5%AE%9E%E8%B7%B5%E2%80%94%E2%80%94%E6%9E%84%E5%BB%BAEnv%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%96%B9%E6%B3%95/",
            "title": "强化学习小实践——构建Env的基本方法",
            "date_published": "2025-05-22T10:50:06.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"\\assets\\css\\APlayer.min.css\"><script src=\"\\assets\\js\\APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><div class=\"note info\">\n<p>这个小实践以一个示例说明构建 Env 的基本方法。同样能够涉及到 Gymnasium 的基本用法。</p>\n</div>\n<h1 id=\"环境准备\"><a class=\"anchor\" href=\"#环境准备\">#</a> <span class=\"rainbow\">环境准备</span></h1>\n<div class=\"note warning\">\n<p>最好新建一个虚拟环境，在这个环境下进行环境配置。</p>\n</div>\n<p>首先，需要在终端执行如下命令安装这个示例需要的包：</p>\n<figure class=\"highlight shell\"><figcaption data-lang=\"Bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>pip <span class=\"token function\">install</span> copier</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>copier copy https://github.com/Farama-Foundation/gymnasium-env-template.git <span class=\"token string\">\"path/to/directory\"</span></pre></td></tr></table></figure><p>其中，&quot;path/to/directory&quot; 更改为你自定义的放项目的文件夹位置。执行完毕后，项目文件夹下会出现如下内容：</p>\n<figure class=\"highlight raw\"><figcaption data-lang=\"\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>.</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>├── gymnasium_env</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>│   ├── envs</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>│   │   ├── grid_world.py</pre></td></tr><tr><td data-num=\"5\"></td><td><pre>│   │   └── __init__.py</pre></td></tr><tr><td data-num=\"6\"></td><td><pre>│   ├── __init__.py</pre></td></tr><tr><td data-num=\"7\"></td><td><pre>│   └── wrappers</pre></td></tr><tr><td data-num=\"8\"></td><td><pre>│       ├── clip_reward.py</pre></td></tr><tr><td data-num=\"9\"></td><td><pre>│       ├── discrete_actions.py</pre></td></tr><tr><td data-num=\"10\"></td><td><pre>│       ├── __init__.py</pre></td></tr><tr><td data-num=\"11\"></td><td><pre>│       ├── reacher_weighted_reward.py</pre></td></tr><tr><td data-num=\"12\"></td><td><pre>│       └── relative_position.py</pre></td></tr><tr><td data-num=\"13\"></td><td><pre>├── LICENSE</pre></td></tr><tr><td data-num=\"14\"></td><td><pre>├── pyproject.toml</pre></td></tr><tr><td data-num=\"15\"></td><td><pre>└── README.md</pre></td></tr></table></figure><p>然后确保你的电脑安装了 Microsoft Visual C++ Build Tools。<br />\n安装方法：</p>\n<ul>\n<li>在浏览器打开 https://visualstudio.microsoft.com/zh-hans/visual-cpp-build-tools/</li>\n<li>点击 “下载生成工具”，接着会下载 vs_BuildTools.exe。</li>\n<li>下载完毕后执行 vs_BuildTools.exe，在工作负载勾选第一个。</li>\n<li>在右侧勾选以下组件：MSVC v143 - VS 2022 C++ x64/x86 build tools、Windows 11 SDK。</li>\n<li>点击安装即可。</li>\n</ul>\n<p>最后，在终端执行：</p>\n<figure class=\"highlight shell\"><figcaption data-lang=\"Bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token builtin class-name\">cd</span> <span class=\"token string\">\"path/to/directory\"</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>pip <span class=\"token function\">install</span> swig</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>pip <span class=\"token function\">install</span> <span class=\"token string\">\"gymnasium[box2d]\"</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token builtin class-name\">cd</span> gymnasium_env</pre></td></tr><tr><td data-num=\"5\"></td><td><pre>pip <span class=\"token function\">install</span> <span class=\"token parameter variable\">-e</span> <span class=\"token builtin class-name\">.</span></pre></td></tr></table></figure><p>自此相关环境已经配置完毕。</p>\n<h1 id=\"创建环境实例\"><a class=\"anchor\" href=\"#创建环境实例\">#</a> <span class=\"rainbow\">创建环境实例</span></h1>\n<p>在与 gymnasim_env 同级下，编写 run.py 文件：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">import</span> gymnasium </pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">import</span> gymnasium_env</pre></td></tr><tr><td data-num=\"3\"></td><td><pre></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>env <span class=\"token operator\">=</span> gymnasium<span class=\"token punctuation\">.</span>make<span class=\"token punctuation\">(</span><span class=\"token string\">'gymnasium_env/GridWorld-v0'</span><span class=\"token punctuation\">,</span> render_mode<span class=\"token operator\">=</span><span class=\"token string\">'human'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>env<span class=\"token punctuation\">.</span>reset<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>episode_over <span class=\"token operator\">=</span> <span class=\"token boolean\">False</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token keyword\">while</span> <span class=\"token keyword\">not</span> episode_over<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>    action <span class=\"token operator\">=</span> env<span class=\"token punctuation\">.</span>action_space<span class=\"token punctuation\">.</span>sample<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>    observation<span class=\"token punctuation\">,</span> reward<span class=\"token punctuation\">,</span> terminated<span class=\"token punctuation\">,</span> truncated<span class=\"token punctuation\">,</span> info <span class=\"token operator\">=</span> env<span class=\"token punctuation\">.</span>step<span class=\"token punctuation\">(</span>action<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>    </pre></td></tr><tr><td data-num=\"12\"></td><td><pre>    episode_over <span class=\"token operator\">=</span> terminated <span class=\"token keyword\">or</span> truncated</pre></td></tr><tr><td data-num=\"13\"></td><td><pre>    </pre></td></tr><tr><td data-num=\"14\"></td><td><pre>env<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p>点击运行，就可以看到一个网格，Agent 是蓝色的圆圈，Agent 想要到达红色方块处，这就是 Agent 运行的环境 Env。这个 Agent 因为是一个未训练的模型，所以并不能高效地完成这个任务，它经过了一段时间才 “随机” 地到达了红色方块处。本实践主要是展示如何构建一个环境实例。</p>\n<p><img data-src=\"../../assets/rl_env1.png\" alt=\"image\" /></p>\n<h1 id=\"相关说明\"><a class=\"anchor\" href=\"#相关说明\">#</a> <span class=\"rainbow\">相关说明</span></h1>\n<p>下面说明一些重要的方法以帮助进一步理解环境创建的过程。</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>env <span class=\"token operator\">=</span> gymnasium<span class=\"token punctuation\">.</span>make<span class=\"token punctuation\">(</span><span class=\"token string\">'gymnasium_env/GridWorld-v0'</span><span class=\"token punctuation\">,</span> render_mode<span class=\"token operator\">=</span><span class=\"token string\">'human'</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p>这个语句，根据 'gymnasium_env/GridWorld-v0' 路径下自定义的环境类创建一个环境，render_mode 是可视化的模式，‘human’表示用人性化的方式展现出来。</p>\n<p>很明显，你发现并没有这个路径 'gymnasium_env/GridWorld-v0'，我们打开 gymnasium_env 文件夹下的__init__.py，可以看到如下代码：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">from</span> gymnasium<span class=\"token punctuation\">.</span>envs<span class=\"token punctuation\">.</span>registration <span class=\"token keyword\">import</span> register</pre></td></tr><tr><td data-num=\"2\"></td><td><pre></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>register<span class=\"token punctuation\">(</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    <span class=\"token builtin\">id</span><span class=\"token operator\">=</span><span class=\"token string\">\"gymnasium_env/GridWorld-v0\"</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    entry_point<span class=\"token operator\">=</span><span class=\"token string\">\"gymnasium_env.envs:GridWorldEnv\"</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p>因为是自定义的环境类，而非 gymnasium 库内置的环境类，所以通常需要用 register 类进行环境注册。entry_point 指定了类的位置，id 根据其创建一个路径。但如此做还不够，因为 gymnasium 不一定能够通过 &quot;gymnasium_env.envs:GridWorldEnv&quot; 找到自定义的 GridWorldEnv。</p>\n<p>因为这条语句的意思是，向 gymnasium_env.envs 文件夹寻找 GridWorldEnv 这个类，但 envs 文件夹自己能不能知道自己有 GridWorldEnv 这个类？我们还要再做一步，在 envs 文件夹内的__init__.py 文件导入 GridWorldEnv，正如代码所示的那样：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">from</span> gymnasium_env<span class=\"token punctuation\">.</span>envs<span class=\"token punctuation\">.</span>grid_world <span class=\"token keyword\">import</span> GridWorldEnv</pre></td></tr></table></figure><p>这样，&quot;gymnasium_env.envs:GridWorldEnv&quot; 就能生效了，GridWorldEnv 便可以被注册为 &quot;gymnasium_env/GridWorld-v0&quot; 这个路径。</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>env<span class=\"token punctuation\">.</span>reset<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p>环境类通常有内置方法 reset ()，这个方法用于初始化环境。当环境类被实例化后，使用该方法生成第一个观察状态。</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>action <span class=\"token operator\">=</span> env<span class=\"token punctuation\">.</span>action_space<span class=\"token punctuation\">.</span>sample<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p>当前实践的 Agent 的代码没有定义，所以暂时用环境类内置的 action_space 方法去生成 Agent 的动作。一般情况下，Agent 的 action 是 Agent 观察环境后得出的，是 Agent 的方法。</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>observation<span class=\"token punctuation\">,</span> reward<span class=\"token punctuation\">,</span> terminated<span class=\"token punctuation\">,</span> truncated<span class=\"token punctuation\">,</span> info <span class=\"token operator\">=</span> env<span class=\"token punctuation\">.</span>step<span class=\"token punctuation\">(</span>action<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p>环境类需要有 step 方法，根据 Agent 的 action 去生成激励 reward，更新旧观察状态为新观察状态 observation。terminated 是检查是否已经结束游戏，truncated 检查是否应该中途停止游戏，info 是游戏有关的信息。</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>env<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p>没什么说的，关闭环境，释放资源。</p>\n",
            "tags": [
                "项目与实践"
            ]
        },
        {
            "id": "https://yunhdan.github.io/baoyan/%E4%BF%9D%E7%A0%94%E5%8E%86%E7%A8%8B/",
            "url": "https://yunhdan.github.io/baoyan/%E4%BF%9D%E7%A0%94%E5%8E%86%E7%A8%8B/",
            "title": "保研历程",
            "date_published": "2025-05-16T13:31:49.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"\\assets\\css\\APlayer.min.css\"><script src=\"\\assets\\js\\APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h1 id=\"个人基本情况\"><a class=\"anchor\" href=\"#个人基本情况\">#</a> <span class=\"rainbow\">个人基本情况</span></h1>\n<ul>\n<li>本科：江西四非，计算机科学与技术，2022 级。</li>\n<li>排名：173 人，前 5%。</li>\n<li>竞赛：若干国奖，若干省奖。</li>\n<li>科研经历：2 段，low-level vision 相关，一篇会议在投，一篇竞赛产出的 CVPR Workshop。</li>\n<li>英语：四级 558，六级擦边 428。无雅思。</li>\n</ul>\n<h1 id=\"定位与计划\"><a class=\"anchor\" href=\"#定位与计划\">#</a> <span class=\"rainbow\">定位与计划</span></h1>\n<ul>\n<li>院校倾向：在方向相关的基础上。华五优先，9 优先。有一定的地域考虑，深圳优先。就业前景好优先。</li>\n<li>方向选择：做 AI，low-level vision 方向，可 3d，可多模态。</li>\n<li>导师选择：人好肯带我最重要，个人倾向于年轻的导师，我感觉我不是那种给我资源自己找出路就能很好的人，还是希望有年轻的导师多带带我。导师人好，读研生活愉快些很重要！</li>\n<li>其他的一些考虑：title 强一些更好、学硕最佳、暂时没有直博想法。</li>\n</ul>\n<h1 id=\"夏令营经历\"><a class=\"anchor\" href=\"#夏令营经历\">#</a> <span class=\"rainbow\">夏令营经历</span></h1>\n<table>\n<thead>\n<tr>\n<th>院校</th>\n<th>入营情况</th>\n<th style=\"text-align:left\">备注</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>南大计院</td>\n<td>寄</td>\n<td style=\"text-align:left\">自然是报着乐</td>\n</tr>\n<tr>\n<td>中大网安</td>\n<td>寄</td>\n<td style=\"text-align:left\">刚报完名一两天，夏令营就取消了</td>\n</tr>\n<tr>\n<td>北大信工</td>\n<td>寄</td>\n<td style=\"text-align:left\">bar 挺高的</td>\n</tr>\n<tr>\n<td>上科大信院 <code>VDI</code></td>\n<td>寄</td>\n<td style=\"text-align:left\">信院 VDI 很强，但需要联系到导师，门槛较高。自然，导师没回我信</td>\n</tr>\n<tr>\n<td>中科院深先院</td>\n<td>寄</td>\n<td style=\"text-align:left\">其实是弱 com，联系导师没回复，自然寄</td>\n</tr>\n<tr>\n<td>南京航空航天计软</td>\n<td>寄</td>\n<td style=\"text-align:left\">今年夏令营 bar 很高，卡 211，双非 <code>rk1</code>  也进不去</td>\n</tr>\n<tr>\n<td>深大计软</td>\n<td>寄</td>\n<td style=\"text-align:left\">很奇怪很奇怪，我的 bg 居然没入四非的营</td>\n</tr>\n<tr>\n<td>中科大</td>\n<td>寄</td>\n<td style=\"text-align:left\">不收双非四非今年居然要申请表上有意向导师签字，第一次见到这种</td>\n</tr>\n<tr>\n<td>北京师大人智</td>\n<td>寄</td>\n<td style=\"text-align:left\">今年居然要申请表上有意向导师签字，第一次见到这种</td>\n</tr>\n<tr>\n<td>南大智科</td>\n<td>已报</td>\n<td style=\"text-align:left\">老师要我，但学校一般不收双非四非</td>\n</tr>\n</tbody>\n</table>\n<p>虽然不太敢相信，但还是不得不接受可能夏 0 营的事实。</p>\n<h1 id=\"预推免\"><a class=\"anchor\" href=\"#预推免\">#</a> 预推免</h1>\n<p>已考虑：中大≈南大智科 &gt; 中科大≈人大 &gt; 电子科大≈南科大≈北邮≈中科院深先院 &gt; 华东师大 &gt; 北师大 &gt; 深大 &gt; 上科大信院 &gt; 南航</p>\n<h1 id=\"最后总结\"><a class=\"anchor\" href=\"#最后总结\">#</a> 最后总结</h1>\n<ul>\n<li>保研是导师和学生之间的双选过程，学生没必要抱着舔的心态去申请。牛导不会因为你的跪舔文案而看上你，对方看不上你，你也没办法，你只能选择水平相较之更低的导。你选择被你 over qualified 的导，即使你因为有更好的去处拒绝了这个导，只要你尽早告知，也没必要为自己的行为愧疚。毕竟还是那句话，双方是互选的过程，这个导也没有理由生你的气，你是出于升学考虑才同时联系多个导师。</li>\n<li>还是那句话，只要你积极不轻言放弃，该要你的一定会要你，不想要你的一定不会要，尽人事听天命。</li>\n</ul>\n",
            "tags": [
                "保研"
            ]
        },
        {
            "id": "https://yunhdan.github.io/ai/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/",
            "url": "https://yunhdan.github.io/ai/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/",
            "title": "深度学习理论",
            "date_published": "2025-05-09T15:49:32.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"\\assets\\css\\APlayer.min.css\"><script src=\"\\assets\\js\\APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><div class=\"note info\">\n<p>复习深度学习必要的理论，可参考该复习线路。该文内容学自李沐动手学深度学习，更基础详尽的理论可以学习吴恩达深度学习。</p>\n</div>\n<h1 id=\"线性神经网络\"><a class=\"anchor\" href=\"#线性神经网络\">#</a> <span class=\"rainbow\">线性神经网络</span></h1>\n<h2 id=\"线性回归\"><a class=\"anchor\" href=\"#线性回归\">#</a> <ins class=\"dot\">线性回归</ins></h2>\n<div class=\"note info Summary\">\n<p>学习视频链接：<span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMVBYNHkxZzdLQy8/c3BtX2lkX2Zyb209MzMzLjEzODcuY29sbGVjdGlvbi52aWRlb19jYXJkLmNsaWNrJmFtcDt2ZF9zb3VyY2U9M2QxNDU2MGMyOGY5MGVmZGQxZjNlNmNhZjdiZjQyNzc=\">https://www.bilibili.com/video/BV1PX4y1g7KC/?spm_id_from=333.1387.collection.video_card.click&amp;vd_source=3d14560c28f90efdd1f3e6caf7bf4277</span></p>\n</div>\n<ul>\n<li>线性回归是对 n 维输入的加权，外加偏差，通常用于预测，方程形式：</li>\n</ul>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>y</mi><mo>=</mo><msub><mi>w</mi><mn>1</mn></msub><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><msub><mi>w</mi><mn>2</mn></msub><msub><mi>x</mi><mn>2</mn></msub><mo>+</mo><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mo>+</mo><mi>b</mi></mrow><annotation encoding=\"application/x-tex\">y = w_1x_1 + w_2x_2 + ... + b\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.73333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.73333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.66666em;vertical-align:-0.08333em;\"></span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">b</span></span></span></span></span></p>\n<ul>\n<li>通常使用 <code>MSE</code>  损失去衡量预测的精确性，即预测值<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\hat{y}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.19444em;\"><span class=\"mord\">^</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span></span></span></span> 和真实值 y 的均方差：</li>\n</ul>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mi>L</mi><mrow><mi>M</mi><mi>S</mi><mi>E</mi></mrow></msub><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo>−</mo><mi>y</mi><mi mathvariant=\"normal\">∣</mi><msup><mi mathvariant=\"normal\">∣</mi><mn>2</mn></msup></mrow><annotation encoding=\"application/x-tex\">L_{MSE} = \\frac{1}{2}||\\hat{y} - y||^2\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">L</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">M</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05764em;\">S</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05764em;\">E</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.00744em;vertical-align:-0.686em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.32144em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">2</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mord\">∣</span><span class=\"mord\">∣</span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.19444em;\"><span class=\"mord\">^</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.1141079999999999em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord\">∣</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span></span></span></span></p>\n<ul>\n<li>线性回归一般有显式解，显式解是损失导数为 0 的点。</li>\n<li>线性回归可以看做是单层神经网络，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>w</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">w_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 实际上是唯一的一层神经元的权重。</li>\n</ul>\n<p>pytorch 实现线性回归很简单。线性回归可以被看成是一层神经网络，因此可以用全连接层实现：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>net <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p><code>Linear</code>  第一个参数是输入数据形状的最后一个维度，比如输入数据 features.shape 是 [4,2]，那么 <code>Linear</code>  第一个参数就是 2。通常输入数据的最后一个维度是数据的特征，2 代表输入数据有两个维度的特征，如买房数据有房价和占地面积两个维度的特征。第二个参数就是输出数据形状的最后一个维度。</p>\n<h2 id=\"基础优化算法概览\"><a class=\"anchor\" href=\"#基础优化算法概览\">#</a> <ins class=\"dot\">基础优化算法概览</ins></h2>\n<div class=\"note info Summary\">\n<p>学习视频链接：<span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMVBYNHkxZzdLQz9zcG1faWRfZnJvbT0zMzMuNzg4LnZpZGVvcG9kLmVwaXNvZGVzJmFtcDt2ZF9zb3VyY2U9M2QxNDU2MGMyOGY5MGVmZGQxZjNlNmNhZjdiZjQyNzcmYW1wO3A9Mg==\">https://www.bilibili.com/video/BV1PX4y1g7KC?spm_id_from=333.788.videopod.episodes&amp;vd_source=3d14560c28f90efdd1f3e6caf7bf4277&amp;p=2</span></p>\n</div>\n<h3 id=\"梯度下降\"><a class=\"anchor\" href=\"#梯度下降\">#</a> 梯度下降</h3>\n<p>基本思想是，对一组初始化的参数，反复迭代训练，按照下面的公式进行参数更新，使得最小化损失函数：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mi>w</mi><mi>t</mi></msub><mo>=</mo><msub><mi>w</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>−</mo><mi>α</mi><mfrac><mrow><mi mathvariant=\"normal\">∂</mi><mi>L</mi><mi>o</mi><mi>s</mi><mi>s</mi></mrow><mrow><mi mathvariant=\"normal\">∂</mi><msub><mi>w</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">w_t = w_{t-1} - \\alpha \\frac{\\partial Loss}{\\partial w_{t-1}}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.791661em;vertical-align:-0.208331em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.265771em;vertical-align:-0.894331em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.37144em;\"><span style=\"top:-2.3139999999999996em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord mathnormal\">L</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">s</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.894331em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>α</mi></mrow><annotation encoding=\"application/x-tex\">\\alpha</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span></span></span></span> 是学习率。学习率是一个很重要的超参，设置太大会导致模型无法收敛，设置太小会导致收敛过慢。</p>\n<h3 id=\"小批量梯度下降\"><a class=\"anchor\" href=\"#小批量梯度下降\">#</a> 小批量梯度下降</h3>\n<p>在整个训练集上进行求梯度、求导会很慢。我们可以随机采样 b 个样本，计算损失来近似整个训练集上的损失。这个 b 就是 <code>batch_size</code> （批量大小），不能设置太大，太大导致内存占用过高，设置太小又无法充分发挥硬件潜力。</p>\n<h2 id=\"基本深度学习训练流程\"><a class=\"anchor\" href=\"#基本深度学习训练流程\">#</a> <ins class=\"dot\">基本深度学习训练流程</ins></h2>\n<p>以线性回归为例，假设我们要建立一个这样的模型：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>y</mi><mo>=</mo><mn>2</mn><msub><mi>x</mi><mn>1</mn></msub><mo>−</mo><mn>3.4</mn><msub><mi>x</mi><mn>2</mn></msub><mo>+</mo><mn>4.2</mn></mrow><annotation encoding=\"application/x-tex\">y = 2x_1 -3.4x_2 + 4.2\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.79444em;vertical-align:-0.15em;\"></span><span class=\"mord\">2</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.79444em;vertical-align:-0.15em;\"></span><span class=\"mord\">3</span><span class=\"mord\">.</span><span class=\"mord\">4</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">4</span><span class=\"mord\">.</span><span class=\"mord\">2</span></span></span></span></span></p>\n<p>事先导入需要用的包：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">import</span> torch</pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token keyword\">from</span> torch<span class=\"token punctuation\">.</span>utils <span class=\"token keyword\">import</span> data</pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token keyword\">from</span> d2l <span class=\"token keyword\">import</span> torch <span class=\"token keyword\">as</span> d2l</pre></td></tr></table></figure><p>人工生成数据：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">synthetic_data</span><span class=\"token punctuation\">(</span>w<span class=\"token punctuation\">,</span> b<span class=\"token punctuation\">,</span> num_examples<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    <span class=\"token triple-quoted-string string\">\"\"\"生成y=Xw+b+噪声\"\"\"</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    X <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>normal<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>num_examples<span class=\"token punctuation\">,</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>w<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    y <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>matmul<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> w<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> b</pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    y <span class=\"token operator\">+=</span> torch<span class=\"token punctuation\">.</span>normal<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.01</span><span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    <span class=\"token keyword\">return</span> X<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    </pre></td></tr><tr><td data-num=\"8\"></td><td><pre>true_w <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>tensor<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">3.4</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>true_b <span class=\"token operator\">=</span> <span class=\"token number\">4.2</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>features<span class=\"token punctuation\">,</span> labels <span class=\"token operator\">=</span> synthetic_data<span class=\"token punctuation\">(</span>true_w<span class=\"token punctuation\">,</span> true_b<span class=\"token punctuation\">,</span> <span class=\"token number\">1000</span><span class=\"token punctuation\">)</span>\t<span class=\"token comment\"># 生成 1k 个样本。</span></pre></td></tr></table></figure><p>数据案例：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'features:'</span><span class=\"token punctuation\">,</span> features<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span><span class=\"token string\">'\\nlabel:'</span><span class=\"token punctuation\">,</span> labels<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token comment\"># 返回</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token comment\"># features: tensor([-0.3679, -1.8471]) </span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token comment\"># label: tensor([9.7361])</span></pre></td></tr></table></figure><p><code>features</code>  是样本的特征，本质是一个二维数组，长度为 1000，而 <code>label</code>  是样本的预测真实值。这里每个样本有两个特征，对每个特征单独分析，都会发现其与 <code>label</code>  存在线性关系：</p>\n<p><img data-src=\"../../assets/d2l1.png\" alt=\"image\" /></p>\n<p>读取数据集的函数，返回一个 dataloader：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">load_array</span><span class=\"token punctuation\">(</span>data_arrays<span class=\"token punctuation\">,</span> batch_size<span class=\"token punctuation\">,</span> is_train<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    <span class=\"token triple-quoted-string string\">\"\"\"构造一个PyTorch数据迭代器\"\"\"</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    dataset <span class=\"token operator\">=</span> data<span class=\"token punctuation\">.</span>TensorDataset<span class=\"token punctuation\">(</span><span class=\"token operator\">*</span>data_arrays<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    <span class=\"token keyword\">return</span> data<span class=\"token punctuation\">.</span>DataLoader<span class=\"token punctuation\">(</span>dataset<span class=\"token punctuation\">,</span> batch_size<span class=\"token punctuation\">,</span> shuffle<span class=\"token operator\">=</span>is_train<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p>数据情况示例：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>batch_size <span class=\"token operator\">=</span> <span class=\"token number\">10</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>data_iter <span class=\"token operator\">=</span> load_array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>features<span class=\"token punctuation\">,</span> labels<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> batch_size<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token builtin\">next</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">iter</span><span class=\"token punctuation\">(</span>data_iter<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    </pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token comment\"># 结果分别是 features 和 labels：</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token comment\"># [tensor([[ 0.1554, -0.2034],</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token comment\">#          [-0.2140,  1.0352],</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre><span class=\"token comment\">#          [-0.4209,  0.0428],</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre><span class=\"token comment\">#          [ 0.1887,  0.6141],</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre><span class=\"token comment\">#          [ 0.4987, -0.2314],</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre><span class=\"token comment\">#          [ 0.0653,  1.6406],</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre><span class=\"token comment\">#          [-1.1881,  0.2900],</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre><span class=\"token comment\">#          [-0.2824,  0.5910],</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre><span class=\"token comment\">#          [ 0.9963, -0.1816],</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre><span class=\"token comment\">#          [-1.6830, -1.3963]]),</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre><span class=\"token comment\">#  tensor([[ 5.2116],</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre><span class=\"token comment\">#          [ 0.2479],</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre><span class=\"token comment\">#          [ 3.2188],</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre><span class=\"token comment\">#          [ 2.4845],</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre><span class=\"token comment\">#          [ 5.9884],</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre><span class=\"token comment\">#          [-1.2453],</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre><span class=\"token comment\">#          [ 0.8441],</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre><span class=\"token comment\">#          [ 1.6217],</span></pre></td></tr><tr><td data-num=\"25\"></td><td><pre><span class=\"token comment\">#          [ 6.8072],</span></pre></td></tr><tr><td data-num=\"26\"></td><td><pre><span class=\"token comment\">#         [ 5.5692]])]</span></pre></td></tr></table></figure><p>我们的目的就是使用这 1000 个样本，训练出一个线性回归模型，也就是求出 w 和 b，以最大化预测的精度，即给定一个样本特征，能够尽可能估计出其对应 <code>label</code>  的值。</p>\n<p>初始化线性回归模型的参数，然后在训练过程中，这些参数会被学习、调整。定义模型和损失函数，并初始化模型参数：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># nn 是神经网络的缩写</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">from</span> torch <span class=\"token keyword\">import</span> nn</pre></td></tr><tr><td data-num=\"3\"></td><td><pre></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>net <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>loss <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>MSELoss<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>net<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>weight<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">.</span>normal_<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.01</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>net<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>bias<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">.</span>fill_<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p>正如前面所说的，对整个数据集进行梯度求导会相当费时，所以通常采用小批量梯度下降 ——SGD。</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>trainer <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>optim<span class=\"token punctuation\">.</span>SGD<span class=\"token punctuation\">(</span>net<span class=\"token punctuation\">.</span>parameters<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> lr<span class=\"token operator\">=</span><span class=\"token number\">0.03</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p>这样就可以开始训练了：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>num_epochs <span class=\"token operator\">=</span> <span class=\"token number\">3</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">for</span> epoch <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>num_epochs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    <span class=\"token keyword\">for</span> X<span class=\"token punctuation\">,</span> y <span class=\"token keyword\">in</span> data_iter<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>        l <span class=\"token operator\">=</span> loss<span class=\"token punctuation\">(</span>net<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">,</span>y<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>        trainer<span class=\"token punctuation\">.</span>zero_grad<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>        l<span class=\"token punctuation\">.</span>backward<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>        trainer<span class=\"token punctuation\">.</span>step<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>    l <span class=\"token operator\">=</span> loss<span class=\"token punctuation\">(</span>net<span class=\"token punctuation\">(</span>features<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> labels<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f'epoch </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>epoch <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">, loss </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>l<span class=\"token punctuation\">:</span><span class=\"token format-spec\">f</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">'</span></span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>        </pre></td></tr><tr><td data-num=\"11\"></td><td><pre><span class=\"token comment\"># 训练过程举例：</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre><span class=\"token comment\"># epoch 1, loss 0.043705</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre><span class=\"token comment\"># epoch 2, loss 0.000172</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre><span class=\"token comment\"># epoch 3, loss 0.000047</span></pre></td></tr></table></figure><h2 id=\"回归-分类与独热编码\"><a class=\"anchor\" href=\"#回归-分类与独热编码\">#</a> <ins class=\"dot\">回归、分类与独热编码</ins></h2>\n<div class=\"note info\">\n<p>学习视频：<span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMUs2NHkxUTd3dT9zcG1faWRfZnJvbT0zMzMuNzg4LnZpZGVvcG9kLmVwaXNvZGVzJmFtcDt2ZF9zb3VyY2U9M2QxNDU2MGMyOGY5MGVmZGQxZjNlNmNhZjdiZjQyNzc=\">https://www.bilibili.com/video/BV1K64y1Q7wu?spm_id_from=333.788.videopod.episodes&amp;vd_source=3d14560c28f90efdd1f3e6caf7bf4277</span></p>\n</div>\n<p>回归可以用于预测的问题，比如预测房屋被售出价格，或者棒球队可能获得的胜场数，又或者患者住院的天数，回归的输出是一个连续的数值。</p>\n<p><img data-src=\"../../assets/d2l2.png\" alt=\"image\" /></p>\n<p>分类则更倾向于问 “哪一个”。比如，某个电子邮件是否属于垃圾邮件，某张图像是驴、狗、猫还是鸡。分类问题通常是多个输出，输出 i 是模型预测输入为第 i 类的置信度。</p>\n<p><img data-src=\"../../assets/d2l3.png\" alt=\"image\" /></p>\n<p>独热编码能够很好地应用到分类问题上，比如有三个类别：{狗，猫，鸡}。在计算机中，可以用 (1,0,0) 代表狗，用 (0,1,0) 代表猫，用 (0,0,1) 代表鸡。也就是说，用向量表示标签，分量和类别一样多，都是 3。类别对应的分量设置为 1，其他所有分量不是这个类别的设置为 0，这就是独热编码。</p>\n<h2 id=\"softmax运算与全连接层\"><a class=\"anchor\" href=\"#softmax运算与全连接层\">#</a> <ins class=\"dot\">Softmax 运算与全连接层</ins></h2>\n<div class=\"note info\">\n<p>学习视频：<span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMUs2NHkxUTd3dT9zcG1faWRfZnJvbT0zMzMuNzg4LnZpZGVvcG9kLmVwaXNvZGVzJmFtcDt2ZF9zb3VyY2U9M2QxNDU2MGMyOGY5MGVmZGQxZjNlNmNhZjdiZjQyNzc=\">https://www.bilibili.com/video/BV1K64y1Q7wu?spm_id_from=333.788.videopod.episodes&amp;vd_source=3d14560c28f90efdd1f3e6caf7bf4277</span></p>\n</div>\n<p>softmax 运算将数据转换为 [0,1] 区间的数值，可以理解为一种标准化，数值可以认为是概率。比如，一个长度为 3 的向量经过 softmax 操作后，3 个数值都会被转换为 0 到 1 的区间值，并且相加和为 1。</p>\n<p>softmax 公式如下：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mfrac><mrow><mi>e</mi><mi>x</mi><mi>p</mi><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><mrow><munderover><mo>∑</mo><mi>k</mi><mrow><mi>l</mi><mi>e</mi><mi>n</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></munderover><mi>e</mi><mi>x</mi><mi>p</mi><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy=\"false\">)</mo></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">softmax(x) = \\frac{exp(x_i)}{\\sum_{k}^{len(x)}exp(x_k)}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">m</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\">x</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.6631080000000003em;vertical-align:-1.236108em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.427em;\"><span style=\"top:-2.11em;\"><span class=\"pstrut\" style=\"height:3.0448em;\"></span><span class=\"mord\"><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.0448em;\"><span style=\"top:-2.398692em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span style=\"top:-3.2197999999999998em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\">n</span><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">x</span><span class=\"mclose mtight\">)</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30130799999999996em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">x</span><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span><span style=\"top:-3.2748em;\"><span class=\"pstrut\" style=\"height:3.0448em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.7218em;\"><span class=\"pstrut\" style=\"height:3.0448em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">x</span><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.236108em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<p>全连接层无处不在，前面提到全连接层可以很方便地通过 nn.Linear 实现。但是全连接层也不是没有缺点，参数量冗余是问题。对于任何具有 d 个输入和 q 个输出的全连接层（对应在最后一个维度上，输入和输出的特征数分别为 d 和 q），参数量开销为 O (dq)。</p>\n<p>后续会提到用 Dropout 方法处理这个问题。</p>\n<h2 id=\"经典损失函数\"><a class=\"anchor\" href=\"#经典损失函数\">#</a> <ins class=\"dot\">经典损失函数</ins></h2>\n<h3 id=\"l1损失\"><a class=\"anchor\" href=\"#l1损失\">#</a> L1 损失</h3>\n<h3 id=\"l2损失\"><a class=\"anchor\" href=\"#l2损失\">#</a> L2 损失</h3>\n<h3 id=\"huber鲁棒损失\"><a class=\"anchor\" href=\"#huber鲁棒损失\">#</a> Huber 鲁棒损失</h3>\n<h3 id=\"交叉熵损失\"><a class=\"anchor\" href=\"#交叉熵损失\">#</a> 交叉熵损失</h3>\n<h2 id=\"信息论基础\"><a class=\"anchor\" href=\"#信息论基础\">#</a> <ins class=\"dot\">信息论基础</ins></h2>\n<h1 id=\"多层感知机\"><a class=\"anchor\" href=\"#多层感知机\">#</a> <span class=\"rainbow\">多层感知机</span></h1>\n<h3 id=\"多层感知机理论\"><a class=\"anchor\" href=\"#多层感知机理论\">#</a> <ins class=\"dot\">多层感知机理论</ins></h3>\n<p>前面提到的线性回归是一种线性神经网络，这样的网络存在一种假设：输入和输出是线性相关的。这种假设下，任何输入的特征增大都会导致模型的输出增大或减小。但很多时候，输入和输出并非是线性相关的。比如一张图像，增加某个位置的像素的强度值能否总是增大其分类为狗的概率？</p>\n<p>我们可以在网络中加入一个或多个隐藏层来突破线性模型的限制，使其能处理更普遍的函数关系类型。这种架构称为多层感知机（ <code>multilayer perceptron, MLP</code> ），这是堆叠许多全连接层的神经网络。</p>\n<p><img data-src=\"../../assets/d2l4.png\" alt=\"image\" /></p>\n<p>每两个层都是全连接的，每个输入都会影响隐藏层中的每个神经元，而隐藏层中的每个神经元又会影响输出层中的每个神经元。</p>\n<p>如果输入<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>X</mi><mo>∈</mo><msup><mi mathvariant=\"double-struck\">R</mi><mrow><mi>n</mi><mo>×</mo><mi>d</mi></mrow></msup></mrow><annotation encoding=\"application/x-tex\">X \\in \\mathbb{R}^{n \\times d}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.72243em;vertical-align:-0.0391em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8491079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbb\">R</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8491079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span><span class=\"mbin mtight\">×</span><span class=\"mord mathnormal mtight\">d</span></span></span></span></span></span></span></span></span></span></span></span>，n 是小样本数，d 是输入特征。对于隐藏层有权重<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>W</mi><mn>1</mn></msub><mo>∈</mo><msup><mi mathvariant=\"double-struck\">R</mi><mrow><mi>d</mi><mo>×</mo><mi>h</mi></mrow></msup></mrow><annotation encoding=\"application/x-tex\">W_1 \\in \\mathbb{R}^{d \\times h}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8491079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbb\">R</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8491079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">d</span><span class=\"mbin mtight\">×</span><span class=\"mord mathnormal mtight\">h</span></span></span></span></span></span></span></span></span></span></span></span>、偏置<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>b</mi><mn>1</mn></msub><mo>∈</mo><msup><mi mathvariant=\"double-struck\">R</mi><mrow><mn>1</mn><mo>×</mo><mi>h</mi></mrow></msup></mrow><annotation encoding=\"application/x-tex\">b_1 \\in \\mathbb{R}^{1 \\times h}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8491079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbb\">R</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8491079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mbin mtight\">×</span><span class=\"mord mathnormal mtight\">h</span></span></span></span></span></span></span></span></span></span></span></span>，输出层也有权重<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>W</mi><mn>2</mn></msub><mo>∈</mo><msup><mi mathvariant=\"double-struck\">R</mi><mrow><mi>h</mi><mo>×</mo><mi>q</mi></mrow></msup></mrow><annotation encoding=\"application/x-tex\">W_2 \\in \\mathbb{R}^{h \\times q}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8491079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbb\">R</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8491079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">h</span><span class=\"mbin mtight\">×</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">q</span></span></span></span></span></span></span></span></span></span></span></span> 和偏置<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>b</mi><mn>2</mn></msub><mo>∈</mo><msup><mi mathvariant=\"double-struck\">R</mi><mrow><mn>1</mn><mo>×</mo><mi>q</mi></mrow></msup></mrow><annotation encoding=\"application/x-tex\">b_2 \\in \\mathbb{R}^{1 \\times q}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8141079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbb\">R</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mbin mtight\">×</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">q</span></span></span></span></span></span></span></span></span></span></span></span>。其中，h 通常是这个隐藏层的隐藏单元数，q 是输出的输出特征，如果要分类为 10 类，q 就是 10。因此多层感知机（单个隐藏层）的数学表达式可以表示为，O 是输出，H 称为隐藏表征（ <code>hidden representation</code> ）：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>H</mi><mo>=</mo><mi>X</mi><msub><mi>W</mi><mn>1</mn></msub><mo>+</mo><msub><mi>b</mi><mn>1</mn></msub><mspace linebreak=\"newline\"></mspace><mi>O</mi><mo>=</mo><mi>H</mi><msub><mi>W</mi><mn>2</mn></msub><mo>+</mo><msub><mi>b</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">H = XW_1 + b_1\t\\\\\nO = HW_2 + b_2\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.08125em;\">H</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span><span class=\"mspace newline\"></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">O</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.08125em;\">H</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span></p>\n<h3 id=\"激活函数\"><a class=\"anchor\" href=\"#激活函数\">#</a> <ins class=\"dot\">激活函数</ins></h3>\n<p>没有激活函数的多层感知机相当于线性神经网络。观察上面的表达式，隐藏单元由输入的仿射变换给出，而输出也只是隐藏单元的仿射函数。仿射函数的仿射函数还是仿射函数，可以如下证明上面的多层感知机等价于单层模型：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>O</mi><mo>=</mo><mo stretchy=\"false\">(</mo><mi>X</mi><msub><mi>W</mi><mn>1</mn></msub><mo>+</mo><msub><mi>b</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo><msub><mi>W</mi><mn>2</mn></msub><mo>+</mo><msub><mi>b</mi><mn>2</mn></msub><mo>=</mo><mi>X</mi><msub><mi>W</mi><mn>1</mn></msub><msub><mi>W</mi><mn>2</mn></msub><mo>+</mo><msub><mi>b</mi><mn>1</mn></msub><msub><mi>W</mi><mn>2</mn></msub><mo>+</mo><msub><mi>b</mi><mn>2</mn></msub><mo>=</mo><mi>X</mi><mi>W</mi><mo>+</mo><mi>b</mi></mrow><annotation encoding=\"application/x-tex\">O = (XW_1 + b_1)W_2 + b_2 = XW_1W_2 + b_1W_2 + b_2 = XW + b\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">O</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.76666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">b</span></span></span></span></span></p>\n<p>这是因为，之前说到的线性回归模型已经可以表示任何仿射函数。通过合并，多层感知机退化为单层的线性回归模型。为了发挥多层架构的潜力，可以在仿射变换后应用非线性的激活函数（ <code>activation function</code> ），即：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>H</mi><mo>=</mo><mi>σ</mi><mo stretchy=\"false\">(</mo><mi>X</mi><msub><mi>W</mi><mn>1</mn></msub><mo>+</mo><msub><mi>b</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo><mspace linebreak=\"newline\"></mspace><mi>O</mi><mo>=</mo><mi>σ</mi><mo stretchy=\"false\">(</mo><mi>H</mi><msub><mi>W</mi><mn>2</mn></msub><mo>+</mo><msub><mi>b</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">H = \\sigma(XW_1 + b_1)\t\\\\\nO = \\sigma(HW_2 + b_2)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.08125em;\">H</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span><span class=\"mspace newline\"></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">O</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.08125em;\">H</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p>这样，多层感知机避免了线性计算退化为单层的线性模型的风险。通过隐藏层中的神经元，多层感知机可以捕获输入之间复杂的相互作用，这些神经元依赖每个输入的值。如果给定足够的神经元和正确的权重，我们就可以对任意函数进行建模，尽管实际应用中学习该函数是很困难的。</p>\n<h4 id=\"relu函数\"><a class=\"anchor\" href=\"#relu函数\">#</a>  <code>ReLU</code>  函数</h4>\n<p>最受欢迎的激活函数：修正线性单元（ <code>rectified linear unit, ReLU</code> ）。数学表达式为：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>R</mi><mi>e</mi><mi>L</mi><mi>U</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo separator=\"true\">,</mo><mn>0</mn><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">ReLU(x) = max(x, 0)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">L</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">U</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">m</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\">x</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">0</span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p><code>ReLU</code>  函数通过将相应的激活值设为 0，仅保留正元素并丢弃所有负元素。当输入值精确为 0 试， <code>ReLU</code>  函数不可导。 <code>ReLU</code>  函数求导很方便，优化表现好，并一定程度上缓解了以往神经网络的梯度消失问题。代码实现和函数曲线图如下：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>y <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>relu<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p><img data-src=\"../../assets/d2l5.png\" alt=\"image\" /></p>\n<h4 id=\"sigmoid函数\"><a class=\"anchor\" href=\"#sigmoid函数\">#</a> sigmoid 函数</h4>\n<p>对于一个定义在<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"double-struck\">R</mi></mrow><annotation encoding=\"application/x-tex\">\\mathbb{R}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68889em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathbb\">R</span></span></span></span></span> 的输入， <code>sigmoid</code>  激活函数将输入变换到 (0,1) 区间。数学表达式为：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>s</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>o</mi><mi>i</mi><mi>d</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><mi>e</mi><mi>x</mi><mi>p</mi><mo stretchy=\"false\">(</mo><mo>−</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">sigmoid(x) = \\frac{1}{1+exp(-x)}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"mord mathnormal\">m</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">d</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.25744em;vertical-align:-0.936em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.32144em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">x</span><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord\">−</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.936em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<p>这是一个平滑的、可微的阈值单元的近似函数。sigmoid 常被用做输出层的激活函数，这个时候，它输出二元分类的概率，因此 sigmoid 可以看作是 softmax 的一个特例。但是，隐藏层中的激活函数还是不选择 sigmoid，因为 <code>ReLU</code>  更合适。当输入接近 0 时，sigmoid 函数接近线性变换。代码实现和函数曲线图如下：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>y <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>sigmoid<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p><img data-src=\"../../assets/d2l6.png\" alt=\"image\" /></p>\n<h4 id=\"tanh函数\"><a class=\"anchor\" href=\"#tanh函数\">#</a>  <code>Tanh</code>  函数</h4>\n<p><code>Tanh</code> （双曲正切）函数也是将输入压缩转换到区间 (-1,1) 上。函数公式如下：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>t</mi><mi>a</mi><mi>n</mi><mi>h</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mfrac><mrow><mn>1</mn><mo>−</mo><mi>e</mi><mi>x</mi><mi>p</mi><mo stretchy=\"false\">(</mo><mo>−</mo><mn>2</mn><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><mrow><mn>1</mn><mo>+</mo><mi>e</mi><mi>x</mi><mi>p</mi><mo stretchy=\"false\">(</mo><mo>−</mo><mn>2</mn><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">tanh(x) = \\frac{1 - exp(-2x)}{1+exp(-2x)}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">h</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.363em;vertical-align:-0.936em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.427em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">x</span><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord\">−</span><span class=\"mord\">2</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">x</span><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord\">−</span><span class=\"mord\">2</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.936em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<p>输入在 0 附近时，它和 sigmoid 函数一样，接近线性变换。代码实现和函数曲线图如下：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>y <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>tanh<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p><img data-src=\"../../assets/d2l7.png\" alt=\"image\" /></p>\n",
            "tags": [
                "人工智能"
            ]
        },
        {
            "id": "https://yunhdan.github.io/other/%E5%8D%9A%E5%AE%A2%E6%96%87%E6%A1%A3%E7%BE%8E%E5%8C%96%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E/",
            "url": "https://yunhdan.github.io/other/%E5%8D%9A%E5%AE%A2%E6%96%87%E6%A1%A3%E7%BE%8E%E5%8C%96%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E/",
            "title": "博客文档美化使用说明",
            "date_published": "2025-03-06T13:04:00.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"\\assets\\css\\APlayer.min.css\"><script src=\"\\assets\\js\\APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><div class=\"note info\">\n<p>摘自 <code>Hexo-Shoka</code>  主题拥有者的使用说明：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9zaG9rYS5sb3N0eXUubWUvY29tcHV0ZXItc2NpZW5jZS9ub3RlL3RoZW1lLXNob2thLWRvYy9zcGVjaWFsLw==\">Step.4 主题特殊功能 - Theme Shoka Documentation - 二进制杂谈 - 计算机科学 | Yume Shoka = 有夢書架 = 吾乃天，壶中之天 (lostyu.me)</span></p>\n</div>\n<h1 id=\"文字特效\"><a class=\"anchor\" href=\"#文字特效\">#</a> 文字特效</h1>\n<figure class=\"highlight raw\"><figcaption data-lang=\"\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>++ 下划线 ++</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>++ 波浪线 ++&#123;.wavy&#125;</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>++ 着重点 ++&#123;.dot&#125;</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>++ 紫色下划线 ++&#123;.primary&#125;</pre></td></tr><tr><td data-num=\"5\"></td><td><pre>++ 绿色波浪线 ++&#123;.wavy .success&#125;</pre></td></tr><tr><td data-num=\"6\"></td><td><pre>++ 黄色着重点 ++&#123;.dot .warning&#125;</pre></td></tr><tr><td data-num=\"7\"></td><td><pre>~~ 删除线～～</pre></td></tr><tr><td data-num=\"8\"></td><td><pre>~~ 红色删除线～～&#123;.danger&#125;</pre></td></tr><tr><td data-num=\"9\"></td><td><pre>&#x3D;&#x3D; 荧光高亮 &#x3D;&#x3D;</pre></td></tr><tr><td data-num=\"10\"></td><td><pre>[赤橙黄绿青蓝紫]&#123;.rainbow&#125;</pre></td></tr><tr><td data-num=\"11\"></td><td><pre>[红色]&#123;.red&#125;</pre></td></tr><tr><td data-num=\"12\"></td><td><pre>[粉色]&#123;.pink&#125;</pre></td></tr><tr><td data-num=\"13\"></td><td><pre>[橙色]&#123;.orange&#125;</pre></td></tr><tr><td data-num=\"14\"></td><td><pre>[黄色]&#123;.yellow&#125;</pre></td></tr><tr><td data-num=\"15\"></td><td><pre>[绿色]&#123;.green&#125;</pre></td></tr><tr><td data-num=\"16\"></td><td><pre>[靛青]&#123;.aqua&#125;</pre></td></tr><tr><td data-num=\"17\"></td><td><pre>[蓝色]&#123;.blue&#125;</pre></td></tr><tr><td data-num=\"18\"></td><td><pre>[紫色]&#123;.purple&#125;</pre></td></tr><tr><td data-num=\"19\"></td><td><pre>[灰色]&#123;.grey&#125;</pre></td></tr><tr><td data-num=\"20\"></td><td><pre>快捷键 [Ctrl]&#123;.kbd&#125; + [C]&#123;.kbd .red&#125;</pre></td></tr><tr><td data-num=\"21\"></td><td><pre>H~2~0</pre></td></tr><tr><td data-num=\"22\"></td><td><pre>29^th^</pre></td></tr></table></figure><p><ins>下划线</ins><br />\n<ins class=\"wavy\">波浪线</ins><br />\n<ins class=\"dot\">着重点</ins><br />\n<ins class=\"primary\">紫色下划线</ins><br />\n<ins class=\"wavy success\">绿色波浪线</ins><br />\n<ins class=\"dot warning\">黄色着重点</ins><br />\n～～删除线～～<br />\n~~ 红色删除线～～{.danger}<br />\n<mark> 荧光高亮</mark><br />\n<span class=\"rainbow\">赤橙黄绿青蓝紫</span><br />\n<span class=\"red\">红色</span><br />\n<span class=\"pink\">粉色</span><br />\n<span class=\"orange\">橙色</span><br />\n<span class=\"yellow\">黄色</span><br />\n<span class=\"green\">绿色</span><br />\n<span class=\"aqua\">靛青</span><br />\n<span class=\"blue\">蓝色</span><br />\n<span class=\"purple\">紫色</span><br />\n<span class=\"grey\">灰色</span><br />\n快捷键 <span class=\"kbd\">Ctrl</span> + <span class=\"kbd red\">C</span><br />\nH<sub>2</sub>0<br />\n29<sup>th</sup></p>\n<h1 id=\"隐藏文字\"><a class=\"anchor\" href=\"#隐藏文字\">#</a> 隐藏文字</h1>\n<figure class=\"highlight raw\"><figcaption data-lang=\"\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>!! 黑幕黑幕黑幕黑幕黑幕黑幕！！： 鼠标滑过显示内容</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>!! 模糊模糊模糊模糊模糊模糊！！&#123;.bulr&#125; ： 选中文字显示内容</pre></td></tr></table></figure><p>!! 黑幕黑幕黑幕黑幕黑幕黑幕！！： 鼠标滑过显示内容<br />\n！！模糊模糊模糊模糊模糊模糊！！{.bulr} ： 选中文字显示内容</p>\n<h1 id=\"标签块\"><a class=\"anchor\" href=\"#标签块\">#</a> 标签块</h1>\n<figure class=\"highlight raw\"><figcaption data-lang=\"\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>[default]&#123;.label&#125;</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>[primary]&#123;.label .primary&#125;</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>[info]&#123;.label .info&#125;</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>[:heavy_check_mark:success]&#123;.label .success&#125;</pre></td></tr><tr><td data-num=\"5\"></td><td><pre>[warning]&#123;.label .warning&#125;</pre></td></tr><tr><td data-num=\"6\"></td><td><pre>[:broken_heart:danger]&#123;.label .danger&#125;</pre></td></tr></table></figure><p><span class=\"label\">default</span><br />\n<span class=\"label primary\">primary</span><br />\n<span class=\"label info\">info</span><br />\n<span class=\"label success\">✔️success</span><br />\n<span class=\"label warning\">warning</span><br />\n<span class=\"label danger\">💔danger</span></p>\n<h1 id=\"提醒块\"><a class=\"anchor\" href=\"#提醒块\">#</a> 提醒块</h1>\n<figure class=\"highlight raw\"><figcaption data-lang=\"\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>:::default</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>默认默认</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>:::</pre></td></tr><tr><td data-num=\"4\"></td><td><pre></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>:::primary</pre></td></tr><tr><td data-num=\"6\"></td><td><pre>基本基本</pre></td></tr><tr><td data-num=\"7\"></td><td><pre>:::</pre></td></tr><tr><td data-num=\"8\"></td><td><pre></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>:::info</pre></td></tr><tr><td data-num=\"10\"></td><td><pre>提示提示</pre></td></tr><tr><td data-num=\"11\"></td><td><pre>:::</pre></td></tr><tr><td data-num=\"12\"></td><td><pre></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>:::success</pre></td></tr><tr><td data-num=\"14\"></td><td><pre>成功成功</pre></td></tr><tr><td data-num=\"15\"></td><td><pre>:::</pre></td></tr><tr><td data-num=\"16\"></td><td><pre></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>:::warning</pre></td></tr><tr><td data-num=\"18\"></td><td><pre>警告警告</pre></td></tr><tr><td data-num=\"19\"></td><td><pre>:::</pre></td></tr><tr><td data-num=\"20\"></td><td><pre></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>:::danger</pre></td></tr><tr><td data-num=\"22\"></td><td><pre>危险危险</pre></td></tr><tr><td data-num=\"23\"></td><td><pre>:::</pre></td></tr></table></figure><div class=\"note default\">\n<p>默认默认</p>\n</div>\n<div class=\"note primary\">\n<p>基本基本</p>\n</div>\n<div class=\"note info\">\n<p>提示提示</p>\n</div>\n<div class=\"note success\">\n<p>成功成功</p>\n</div>\n<div class=\"note warning\">\n<p>警告警告</p>\n</div>\n<div class=\"note danger\">\n<p>危险危险</p>\n</div>\n<h1 id=\"折叠块\"><a class=\"anchor\" href=\"#折叠块\">#</a> 折叠块</h1>\n<figure class=\"highlight raw\"><figcaption data-lang=\"\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>+++ 默认默认 这里是一段文字</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>++ 下划线 ++</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>+++</pre></td></tr><tr><td data-num=\"4\"></td><td><pre></pre></td></tr><tr><td data-num=\"5\"></td><td><pre></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>+++primary 紫色</pre></td></tr><tr><td data-num=\"7\"></td><td><pre>:::info</pre></td></tr><tr><td data-num=\"8\"></td><td><pre>参考信息</pre></td></tr><tr><td data-num=\"9\"></td><td><pre>:::</pre></td></tr><tr><td data-num=\"10\"></td><td><pre></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>- 第一行</pre></td></tr><tr><td data-num=\"12\"></td><td><pre>- 第二行</pre></td></tr><tr><td data-num=\"13\"></td><td><pre>+++</pre></td></tr><tr><td data-num=\"14\"></td><td><pre></pre></td></tr><tr><td data-num=\"15\"></td><td><pre></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>+++info  蓝色</pre></td></tr><tr><td data-num=\"17\"></td><td><pre>;;;id3 卡片 1</pre></td></tr><tr><td data-num=\"18\"></td><td><pre>这里是卡片 1 的内容</pre></td></tr><tr><td data-num=\"19\"></td><td><pre>;;;</pre></td></tr><tr><td data-num=\"20\"></td><td><pre></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>;;;id3 卡片 2</pre></td></tr><tr><td data-num=\"22\"></td><td><pre>这里是卡片 2 的内容</pre></td></tr><tr><td data-num=\"23\"></td><td><pre>;;;</pre></td></tr><tr><td data-num=\"24\"></td><td><pre>+++</pre></td></tr><tr><td data-num=\"25\"></td><td><pre></pre></td></tr><tr><td data-num=\"26\"></td><td><pre>+++success 绿色</pre></td></tr><tr><td data-num=\"27\"></td><td><pre><div class=\"links\"><div class=\"item\" title=\"優萌初華\" style=\"--block-color:#e9546b;\"><span class=\"exturl image\" data-url=\"aHR0cHM6Ly9zaG9rYS5sb3N0eXUubWU=\" data-background-image=\"/images/404.png\"></span>\n          <div class=\"info\">\n          <span class=\"exturl title\" data-url=\"aHR0cHM6Ly9zaG9rYS5sb3N0eXUubWU=\">優萌初華</span>\n          <p class=\"desc\">https://shoka.lostyu.me</p>\n          </div></div></div></pre></td></tr><tr><td data-num=\"28\"></td><td><pre>+++</pre></td></tr><tr><td data-num=\"29\"></td><td><pre></pre></td></tr><tr><td data-num=\"30\"></td><td><pre>+++warning 黄色</pre></td></tr><tr><td data-num=\"31\"></td><td><pre>!! 警告警告警告警告警告！！&#123;.bulr&#125;</pre></td></tr><tr><td data-num=\"32\"></td><td><pre>[label]&#123;.label .success&#125;</pre></td></tr><tr><td data-num=\"33\"></td><td><pre>+++</pre></td></tr><tr><td data-num=\"34\"></td><td><pre></pre></td></tr><tr><td data-num=\"35\"></td><td><pre>+++danger 红色</pre></td></tr><tr><td data-num=\"36\"></td><td><pre>[danger]&#123;.label .danger&#125;</pre></td></tr><tr><td data-num=\"37\"></td><td><pre>+++</pre></td></tr></table></figure><details><summary>默认默认 这里是一段文字</summary><div>\n<p>++ 下划线 ++</p>\n</div></details>\n<details class=\"primary\"><summary>紫色</summary><div>\n<div class=\"note info\">\n<p>参考信息</p>\n</div>\n<ul>\n<li>第一行</li>\n<li>第二行</li>\n</ul>\n</div></details>\n<details class=\"info\"><summary>蓝色</summary><div>\n<div class=\"tab\" data-id=\"id3\" data-title=\"卡片 1\">\n<p>这里是卡片 1 的内容</p>\n</div>\n<div class=\"tab\" data-id=\"id3\" data-title=\"卡片 2\">\n<p>这里是卡片 2 的内容</p>\n</div>\n</div></details>\n<details class=\"success\"><summary>绿色</summary><div>\n<p><div class=\"links\"><div class=\"item\" title=\"優萌初華\" style=\"--block-color:#e9546b;\"><span class=\"exturl image\" data-url=\"aHR0cHM6Ly9zaG9rYS5sb3N0eXUubWU=\" data-background-image=\"/images/404.png\"></span>\n          <div class=\"info\">\n          <span class=\"exturl title\" data-url=\"aHR0cHM6Ly9zaG9rYS5sb3N0eXUubWU=\">優萌初華</span>\n          <p class=\"desc\">https://shoka.lostyu.me</p>\n          </div></div></div></p>\n</div></details>\n<details class=\"warning\"><summary>黄色</summary><div>\n<p>!! 警告警告警告警告警告！！{.bulr}<br />\n<span class=\"label success\">label</span></p>\n</div></details>\n<details class=\"danger\"><summary>红色</summary><div>\n<p><span class=\"label danger\">danger</span></p>\n</div></details>\n",
            "tags": [
                "琐碎"
            ]
        },
        {
            "id": "https://yunhdan.github.io/ai/Deep-Learning-Experiment-Tricks/",
            "url": "https://yunhdan.github.io/ai/Deep-Learning-Experiment-Tricks/",
            "title": "Deep Learning Experiment Tricks",
            "date_published": "2025-03-02T15:58:57.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"\\assets\\css\\APlayer.min.css\"><script src=\"\\assets\\js\\APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><div class=\"note info\">\n<p>一般在一个新的 <code>trick</code>  和 <code>experience</code>  开坑时，都会先暂时粗略地搬运一些其他地方的内容，或者简略描述。偶尔精进与专门研究时，会特别地丰富和细致化该内容。</p>\n</div>\n<h1 id=\"pytorch_mssimssim的使用\"><a class=\"anchor\" href=\"#pytorch_mssimssim的使用\">#</a>  <code>pytorch_mssim.ssim</code>  的使用</h1>\n<p>以下面计算 <code>ssim</code>  的代码为例：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>ssim_value <span class=\"token operator\">=</span> ssim<span class=\"token punctuation\">(</span>final<span class=\"token punctuation\">,</span> gt_batch<span class=\"token punctuation\">,</span> data_range<span class=\"token operator\">=</span><span class=\"token number\">2.0</span><span class=\"token punctuation\">,</span> size_average<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p><code>data_range</code>  表示图像像素值的动态范围（最大值与最小值的差）。如果输入图像经过归一化处理（如  <code>transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])</code> ），则像素值范围会被映射到 <code>[-1, 1]</code> 。此时  <code>data_range</code>  应设为  <code>2.0</code> （因为  <code>1 - (-1) = 2</code> ），而不是  <code>1.0</code> 。</p>\n<p><code>SSIM</code>  默认假设输入范围是 <code>[0, 1]</code> （当  <code>data_range=1</code> ）或  <code>[0, 255]</code> （当  <code>data_range=255</code> ）。</p>\n<p><code>size_average=True</code>  会将  <code>SSIM</code>  值在所有图像和通道上取平均。 <code>pytorch_msssim</code>  的新版本使用 reduction 取代这个参数，重写为： <code>reduction='mean'</code> 。</p>\n<p>有时候，应该确保输入给 <code>ssim</code>  做计算时的数据范围在 <code>[-1, 1]</code>  之间，不然，则要裁剪处理：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>final_clamped <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>clamp<span class=\"token punctuation\">(</span>final<span class=\"token punctuation\">,</span> <span class=\"token number\">0.0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1.0</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>ssim_value <span class=\"token operator\">=</span> ssim<span class=\"token punctuation\">(</span>final_clamped<span class=\"token punctuation\">,</span> gt_batch<span class=\"token punctuation\">,</span> data_range<span class=\"token operator\">=</span><span class=\"token number\">1.0</span><span class=\"token punctuation\">,</span> size_average<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><h1 id=\"损失函数下降-震荡-上升的原因\"><a class=\"anchor\" href=\"#损失函数下降-震荡-上升的原因\">#</a> 损失函数下降、震荡、上升的原因</h1>\n<blockquote>\n<p>在训练包含多个损失函数的模型时，各子损失函数的变化趋势能够反映模型的学习动态和优化方向。以下是不同趋势的详细分析及应对策略：</p>\n<hr />\n<h4 id=\"一-损失函数整体持续下降\"><a class=\"anchor\" href=\"#一-损失函数整体持续下降\">#</a> <strong>一、损失函数整体持续下降</strong></h4>\n<h4 id=\"含义解析\"><a class=\"anchor\" href=\"#含义解析\">#</a> <strong>含义解析</strong></h4>\n<ul>\n<li><strong>良性学习信号</strong>：模型正在有效优化该任务目标，权重分配合理，数据质量良好。</li>\n<li><strong>潜在风险</strong>：\n<ul>\n<li><strong>过拟合倾向</strong>：若验证集对应指标未同步下降，可能过拟合训练数据。</li>\n<li><strong>任务主导性</strong>：其他损失未充分优化，模型可能偏向该任务。</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"典型案例\"><a class=\"anchor\" href=\"#典型案例\">#</a> <strong>典型案例</strong></h4>\n<ul>\n<li>重建损失（如 L1/L2）持续下降，但对抗损失震荡 → 模型过度拟合像素级精度，忽视生成真实性。</li>\n</ul>\n<h4 id=\"应对策略\"><a class=\"anchor\" href=\"#应对策略\">#</a> <strong>应对策略</strong></h4>\n<ol>\n<li><strong>验证泛化性</strong>：检查验证集对应指标是否同步改善</li>\n<li><strong>调整权重</strong>：若其他损失停滞，适当降低该损失权重（如从 1.0→0.7）</li>\n<li><strong>早停机制</strong>：当验证损失不再下降时停止训练</li>\n</ol>\n<hr />\n<h4 id=\"二-损失函数震荡波动\"><a class=\"anchor\" href=\"#二-损失函数震荡波动\">#</a> <strong>二、损失函数震荡波动</strong></h4>\n<h4 id=\"含义解析-2\"><a class=\"anchor\" href=\"#含义解析-2\">#</a> <strong>含义解析</strong></h4>\n<ul>\n<li><strong>优化不稳定</strong>：学习率过高、批次过小或损失间存在冲突。</li>\n<li><strong>数据问题</strong>：噪声数据或类别不均衡导致梯度方向不一致。</li>\n<li><strong>对抗性博弈</strong>：典型于 GAN 的判别器与生成器损失交替上升。</li>\n</ul>\n<h4 id=\"数值特征\"><a class=\"anchor\" href=\"#数值特征\">#</a> <strong>数值特征</strong></h4>\n<ul>\n<li><strong>高频震荡</strong>（如 ±5%）：常由学习率过大引起</li>\n<li><strong>低频震荡</strong>（如每 5 个 epoch 变化）：多任务目标冲突</li>\n</ul>\n<h4 id=\"典型案例-2\"><a class=\"anchor\" href=\"#典型案例-2\">#</a> <strong>典型案例</strong></h4>\n<ul>\n<li>分类损失下降但正则化损失震荡 → L2 正则化强度过高导致参数更新不稳定</li>\n</ul>\n<h4 id=\"应对策略-2\"><a class=\"anchor\" href=\"#应对策略-2\">#</a> <strong>应对策略</strong></h4>\n<ol>\n<li><strong>降低学习率</strong>：将初始学习率减少 3-5 倍（如 2e-4→5e-5）</li>\n<li><strong>增大批次大小</strong>：从 32 提升至 128，稳定梯度估计</li>\n<li><strong>梯度裁剪</strong>：设置 <code>max_grad_norm=1.0</code></li>\n<li><strong>冲突分析</strong>：计算损失梯度余弦相似度，对负相关损失解耦训练</li>\n</ol>\n<hr />\n<h4 id=\"三-损失函数持续上升\"><a class=\"anchor\" href=\"#三-损失函数持续上升\">#</a> <strong>三、损失函数持续上升</strong></h4>\n<h4 id=\"含义解析-3\"><a class=\"anchor\" href=\"#含义解析-3\">#</a> <strong>含义解析</strong></h4>\n<ul>\n<li><strong>严重警告信号</strong>：模型在该任务上性能退化，优化方向错误。</li>\n<li><strong>常见诱因</strong>：\n<ul>\n<li><strong>损失权重倒置</strong>：如误将权重设为负数</li>\n<li><strong>任务本质冲突</strong>：如超分辨率任务中，L1 损失下降但感知损失上升</li>\n<li><strong>数值不稳定</strong>：梯度爆炸导致损失进入病态区域</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"典型案例-3\"><a class=\"anchor\" href=\"#典型案例-3\">#</a> <strong>典型案例</strong></h4>\n<ul>\n<li>对抗损失上升而重建损失下降 → 判别器过强导致生成器无法有效学习</li>\n</ul>\n<h4 id=\"应对策略-3\"><a class=\"anchor\" href=\"#应对策略-3\">#</a> <strong>应对策略</strong></h4>\n<ol>\n<li><strong>立即暂停训练</strong>：检查损失计算代码和权重符号</li>\n<li><strong>损失权重热力图</strong>：可视化各损失对总损失的贡献比例</li>\n<li><strong>渐进式训练</strong>：分阶段引入上升的损失项（如先用 L1 预训练，第 50epoch 加入对抗损失）</li>\n<li><strong>架构改进</strong>：对于根本性冲突，修改网络结构（如增加多尺度特征融合模块）</li>\n</ol>\n<hr />\n<h4 id=\"四-综合优化建议\"><a class=\"anchor\" href=\"#四-综合优化建议\">#</a> <strong>四、综合优化建议</strong></h4>\n<ol>\n<li><strong>动态权重调整</strong>：采用不确定性加权法（如《Multi-Task Learning Using Uncertainty to Weigh Losses》）<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 各损失自动加权示例</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>log_var <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Parameter<span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 3 个损失</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>loss <span class=\"token operator\">=</span> <span class=\"token number\">0.5</span><span class=\"token operator\">*</span><span class=\"token punctuation\">(</span>loss1<span class=\"token operator\">/</span>torch<span class=\"token punctuation\">.</span>exp<span class=\"token punctuation\">(</span>log_var<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> loss2<span class=\"token operator\">/</span>torch<span class=\"token punctuation\">.</span>exp<span class=\"token punctuation\">(</span>log_var<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> log_var<span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure></li>\n<li><strong>损失相关性监控</strong>：计算各损失间的 Pearson 相关系数矩阵，识别冲突组合</li>\n<li><strong>课程学习策略</strong>：早期侧重易优化损失（如 L1），后期加强高阶损失（如 SSIM、VGG 感知损失）</li>\n<li><strong>可视化工具</strong>：使用 TensorBoard 的并行坐标视图对比超参数与损失关系</li>\n</ol>\n<hr />\n<h4 id=\"五-调试检查清单\"><a class=\"anchor\" href=\"#五-调试检查清单\">#</a> <strong>五、调试检查清单</strong></h4>\n<p>当出现异常损失趋势时，按以下顺序排查：</p>\n<ol>\n<li><strong>数值检查</strong>：\n<ul>\n<li>确认损失计算未出现 NaN/Inf</li>\n<li>检查梯度幅值（ <code>torch.nn.utils.clip_grad_norm_</code> ）</li>\n</ul>\n</li>\n<li><strong>数据流验证</strong>：<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 数据检查代码片段</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">for</span> batch <span class=\"token keyword\">in</span> val_loader<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>batch<span class=\"token punctuation\">[</span><span class=\"token string\">'image'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">min</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> batch<span class=\"token punctuation\">[</span><span class=\"token string\">'image'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 应为 [0,1] 或 [-1,1]</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    visualize<span class=\"token punctuation\">(</span>batch<span class=\"token punctuation\">[</span><span class=\"token string\">'image'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 肉眼验证图像质量</span></pre></td></tr></table></figure></li>\n<li><strong>权重合理性</strong>：确保各损失量级匹配（如 L1≈0.1，对抗损失≈2.0 时，需调整权重平衡）</li>\n<li><strong>模型容量测试</strong>：在小数据集（如 100 样本）上过拟合，验证能否达到预期损失</li>\n</ol>\n<p>通过系统分析损失动态，可精准定位模型优化瓶颈，实现多目标协同优化。</p>\n</blockquote>\n<h1 id=\"transformsresize\"><a class=\"anchor\" href=\"#transformsresize\">#</a>  <code>transforms.Resize()</code></h1>\n<p>这个与 <code>RandomCrop()</code>  还不太一样， <code>Resize()</code>  是等比例的缩放原图。所以存在一定的信息损失，一般不使用这种操作。</p>\n<h1 id=\"不确定性损失加权法多任务损失均衡\"><a class=\"anchor\" href=\"#不确定性损失加权法多任务损失均衡\">#</a> 不确定性损失加权法 —— 多任务损失均衡</h1>\n<blockquote>\n<p>以下是使用不确定性加权法改造后的损失函数实现：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">import</span> torch</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">import</span> torch<span class=\"token punctuation\">.</span>nn <span class=\"token keyword\">as</span> nn</pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token keyword\">import</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>functional <span class=\"token keyword\">as</span> F</pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token keyword\">from</span> pytorch_msssim <span class=\"token keyword\">import</span> ssim</pre></td></tr><tr><td data-num=\"5\"></td><td><pre></pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token keyword\">class</span> <span class=\"token class-name\">UncertaintyWeightedLoss</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> trans<span class=\"token punctuation\">,</span> num_tasks<span class=\"token operator\">=</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>        <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"9\"></td><td><pre>        trans: HVI转换器实例</pre></td></tr><tr><td data-num=\"10\"></td><td><pre>        num_tasks: 需要加权的损失项数量（这里包含L1, SSIM, Res, Cons, HVI）</pre></td></tr><tr><td data-num=\"11\"></td><td><pre>        \"\"\"</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>        self<span class=\"token punctuation\">.</span>trans <span class=\"token operator\">=</span> trans</pre></td></tr><tr><td data-num=\"14\"></td><td><pre>        <span class=\"token comment\"># 初始化可学习的不确定性参数（log 方差）</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>        self<span class=\"token punctuation\">.</span>log_vars <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Parameter<span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span>num_tasks<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>        <span class=\"token comment\"># 初始化参数（可选）</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>        nn<span class=\"token punctuation\">.</span>init<span class=\"token punctuation\">.</span>uniform_<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>log_vars<span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 初始方差在 0.05~0.37 之间</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre></pre></td></tr><tr><td data-num=\"19\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">compute_losses</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> final<span class=\"token punctuation\">,</span> gt<span class=\"token punctuation\">,</span> output<span class=\"token punctuation\">,</span> S1<span class=\"token punctuation\">,</span> P1<span class=\"token punctuation\">,</span> S2<span class=\"token punctuation\">,</span> P2<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>        <span class=\"token triple-quoted-string string\">\"\"\"分解计算各个基础损失项\"\"\"</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>        <span class=\"token comment\"># RGB 空间损失</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre>        l1_loss <span class=\"token operator\">=</span> F<span class=\"token punctuation\">.</span>l1_loss<span class=\"token punctuation\">(</span>final<span class=\"token punctuation\">,</span> gt<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>        ssim_loss <span class=\"token operator\">=</span> <span class=\"token number\">1</span> <span class=\"token operator\">-</span> ssim<span class=\"token punctuation\">(</span>final<span class=\"token punctuation\">,</span> gt<span class=\"token punctuation\">,</span> data_range<span class=\"token operator\">=</span><span class=\"token number\">1.0</span><span class=\"token punctuation\">,</span> size_average<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre>        </pre></td></tr><tr><td data-num=\"25\"></td><td><pre>        <span class=\"token comment\"># 残差一致性损失</span></pre></td></tr><tr><td data-num=\"26\"></td><td><pre>        loss_res1 <span class=\"token operator\">=</span> F<span class=\"token punctuation\">.</span>mse_loss<span class=\"token punctuation\">(</span>S1<span class=\"token punctuation\">,</span> P1 <span class=\"token operator\">+</span> S2<span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> <span class=\"token punctuation\">(</span>S1<span class=\"token punctuation\">.</span>detach<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>var<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> <span class=\"token number\">1e-6</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"27\"></td><td><pre>        loss_res2 <span class=\"token operator\">=</span> F<span class=\"token punctuation\">.</span>mse_loss<span class=\"token punctuation\">(</span>S2<span class=\"token punctuation\">,</span> P2 <span class=\"token operator\">+</span> S1<span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> <span class=\"token punctuation\">(</span>S2<span class=\"token punctuation\">.</span>detach<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>var<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> <span class=\"token number\">1e-6</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre>        res_loss <span class=\"token operator\">=</span> loss_res1 <span class=\"token operator\">+</span> loss_res2</pre></td></tr><tr><td data-num=\"29\"></td><td><pre>        </pre></td></tr><tr><td data-num=\"30\"></td><td><pre>        <span class=\"token comment\"># 下采样一致性损失</span></pre></td></tr><tr><td data-num=\"31\"></td><td><pre>        g1<span class=\"token punctuation\">,</span> g2 <span class=\"token operator\">=</span> pair_downsampler<span class=\"token punctuation\">(</span>output<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"32\"></td><td><pre>        cons_loss <span class=\"token operator\">=</span> F<span class=\"token punctuation\">.</span>l1_loss<span class=\"token punctuation\">(</span>S1<span class=\"token punctuation\">,</span> P1 <span class=\"token operator\">+</span> g1<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> F<span class=\"token punctuation\">.</span>l1_loss<span class=\"token punctuation\">(</span>S2<span class=\"token punctuation\">,</span> P2 <span class=\"token operator\">+</span> g2<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"33\"></td><td><pre>        </pre></td></tr><tr><td data-num=\"34\"></td><td><pre>        <span class=\"token comment\"># HVI 空间损失</span></pre></td></tr><tr><td data-num=\"35\"></td><td><pre>        final_hvi <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>trans<span class=\"token punctuation\">.</span>HVIT<span class=\"token punctuation\">(</span>final<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"36\"></td><td><pre>        gt_hvi <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>trans<span class=\"token punctuation\">.</span>HVIT<span class=\"token punctuation\">(</span>gt<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"37\"></td><td><pre>        hvi_l1 <span class=\"token operator\">=</span> F<span class=\"token punctuation\">.</span>l1_loss<span class=\"token punctuation\">(</span>final_hvi<span class=\"token punctuation\">,</span> gt_hvi<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"38\"></td><td><pre>        hvi_edge <span class=\"token operator\">=</span> edge_loss<span class=\"token punctuation\">(</span>final_hvi<span class=\"token punctuation\">,</span> gt_hvi<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"39\"></td><td><pre>        </pre></td></tr><tr><td data-num=\"40\"></td><td><pre>        <span class=\"token keyword\">return</span> <span class=\"token punctuation\">[</span>l1_loss<span class=\"token punctuation\">,</span> ssim_loss<span class=\"token punctuation\">,</span> res_loss<span class=\"token punctuation\">,</span> cons_loss<span class=\"token punctuation\">,</span> hvi_l1<span class=\"token punctuation\">,</span> hvi_edge<span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"41\"></td><td><pre></pre></td></tr><tr><td data-num=\"42\"></td><td><pre>    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> final<span class=\"token punctuation\">,</span> gt<span class=\"token punctuation\">,</span> output<span class=\"token punctuation\">,</span> S1<span class=\"token punctuation\">,</span> P1<span class=\"token punctuation\">,</span> S2<span class=\"token punctuation\">,</span> P2<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"43\"></td><td><pre>        <span class=\"token comment\"># 获取所有基础损失项</span></pre></td></tr><tr><td data-num=\"44\"></td><td><pre>        losses <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>compute_losses<span class=\"token punctuation\">(</span>final<span class=\"token punctuation\">,</span> gt<span class=\"token punctuation\">,</span> output<span class=\"token punctuation\">,</span> S1<span class=\"token punctuation\">,</span> P1<span class=\"token punctuation\">,</span> S2<span class=\"token punctuation\">,</span> P2<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"45\"></td><td><pre>        </pre></td></tr><tr><td data-num=\"46\"></td><td><pre>        <span class=\"token comment\"># 应用不确定性加权</span></pre></td></tr><tr><td data-num=\"47\"></td><td><pre>        total_loss <span class=\"token operator\">=</span> <span class=\"token number\">0.0</span></pre></td></tr><tr><td data-num=\"48\"></td><td><pre>        <span class=\"token keyword\">for</span> i<span class=\"token punctuation\">,</span> loss <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>losses<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"49\"></td><td><pre>            precision <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>exp<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span>self<span class=\"token punctuation\">.</span>log_vars<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"50\"></td><td><pre>            total_loss <span class=\"token operator\">+=</span> precision <span class=\"token operator\">*</span> loss <span class=\"token operator\">+</span> self<span class=\"token punctuation\">.</span>log_vars<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"51\"></td><td><pre>        </pre></td></tr><tr><td data-num=\"52\"></td><td><pre>        <span class=\"token comment\"># 返回总损失和详细损失项（用于监控）</span></pre></td></tr><tr><td data-num=\"53\"></td><td><pre>        loss_details <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"54\"></td><td><pre>            <span class=\"token string\">'total'</span><span class=\"token punctuation\">:</span> total_loss<span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"55\"></td><td><pre>            <span class=\"token string\">'l1'</span><span class=\"token punctuation\">:</span> losses<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"56\"></td><td><pre>            <span class=\"token string\">'ssim'</span><span class=\"token punctuation\">:</span> losses<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"57\"></td><td><pre>            <span class=\"token string\">'res'</span><span class=\"token punctuation\">:</span> losses<span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"58\"></td><td><pre>            <span class=\"token string\">'cons'</span><span class=\"token punctuation\">:</span> losses<span class=\"token punctuation\">[</span><span class=\"token number\">3</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"59\"></td><td><pre>            <span class=\"token string\">'hvi_l1'</span><span class=\"token punctuation\">:</span> losses<span class=\"token punctuation\">[</span><span class=\"token number\">4</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"60\"></td><td><pre>            <span class=\"token string\">'hvi_edge'</span><span class=\"token punctuation\">:</span> losses<span class=\"token punctuation\">[</span><span class=\"token number\">5</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"61\"></td><td><pre>            <span class=\"token string\">'log_vars'</span><span class=\"token punctuation\">:</span> self<span class=\"token punctuation\">.</span>log_vars</pre></td></tr><tr><td data-num=\"62\"></td><td><pre>        <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"63\"></td><td><pre>        <span class=\"token keyword\">return</span> total_loss<span class=\"token punctuation\">,</span> loss_details</pre></td></tr></table></figure><p>主要改进点说明：</p>\n<ol>\n<li><strong>模块化设计</strong>：</li>\n</ol>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 初始化方式变化</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>trans <span class=\"token operator\">=</span> RGB_HVI<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>criterion <span class=\"token operator\">=</span> UncertaintyWeightedLoss<span class=\"token punctuation\">(</span>trans<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token comment\"># 前向计算变化</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>total_loss<span class=\"token punctuation\">,</span> loss_details <span class=\"token operator\">=</span> criterion<span class=\"token punctuation\">(</span>final<span class=\"token punctuation\">,</span> gt<span class=\"token punctuation\">,</span> output<span class=\"token punctuation\">,</span> S1<span class=\"token punctuation\">,</span> P1<span class=\"token punctuation\">,</span> S2<span class=\"token punctuation\">,</span> P2<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><ol start=\"2\">\n<li><strong>动态权重机制</strong>：</li>\n</ol>\n<ul>\n<li>每个损失项自动获得权重：weight = exp (-log_var)</li>\n<li>包含正则项：log_var 防止方差无限增大</li>\n<li>初始权重范围：exp (-3)=0.05 ~ exp (-1)=0.37</li>\n</ul>\n<ol start=\"3\">\n<li><strong>训练监控增强</strong>：</li>\n</ol>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 在训练循环中添加监控</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>writer<span class=\"token punctuation\">.</span>add_scalars<span class=\"token punctuation\">(</span><span class=\"token string\">'Loss/Train'</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    <span class=\"token string\">'total'</span><span class=\"token punctuation\">:</span> loss_details<span class=\"token punctuation\">[</span><span class=\"token string\">'total'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>item<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    <span class=\"token string\">'l1'</span><span class=\"token punctuation\">:</span> loss_details<span class=\"token punctuation\">[</span><span class=\"token string\">'l1'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>item<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    <span class=\"token string\">'ssim'</span><span class=\"token punctuation\">:</span> loss_details<span class=\"token punctuation\">[</span><span class=\"token string\">'ssim'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>item<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    <span class=\"token string\">'res'</span><span class=\"token punctuation\">:</span> loss_details<span class=\"token punctuation\">[</span><span class=\"token string\">'res'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>item<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    <span class=\"token string\">'cons'</span><span class=\"token punctuation\">:</span> loss_details<span class=\"token punctuation\">[</span><span class=\"token string\">'cons'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>item<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>    <span class=\"token string\">'hvi_l1'</span><span class=\"token punctuation\">:</span> loss_details<span class=\"token punctuation\">[</span><span class=\"token string\">'hvi_l1'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>item<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>    <span class=\"token string\">'hvi_edge'</span><span class=\"token punctuation\">:</span> loss_details<span class=\"token punctuation\">[</span><span class=\"token string\">'hvi_edge'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>item<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">,</span> total_iter<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre></pre></td></tr><tr><td data-num=\"12\"></td><td><pre><span class=\"token comment\"># 监控不确定性参数</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre><span class=\"token keyword\">for</span> i<span class=\"token punctuation\">,</span> log_var <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>loss_details<span class=\"token punctuation\">[</span><span class=\"token string\">'log_vars'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>    writer<span class=\"token punctuation\">.</span>add_scalar<span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f'Uncertainty/var_</span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>i<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">'</span></span><span class=\"token punctuation\">,</span> torch<span class=\"token punctuation\">.</span>exp<span class=\"token punctuation\">(</span>log_var<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>item<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> epoch<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><ol start=\"4\">\n<li><strong>优化器调整</strong>：</li>\n</ol>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 需要将损失参数加入优化器</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>optimizer <span class=\"token operator\">=</span> optim<span class=\"token punctuation\">.</span>Adam<span class=\"token punctuation\">(</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">.</span>parameters<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>criterion<span class=\"token punctuation\">.</span>parameters<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    lr<span class=\"token operator\">=</span>args<span class=\"token punctuation\">.</span>lr<span class=\"token punctuation\">,</span> </pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    betas<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">0.9</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.999</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><ol start=\"5\">\n<li><strong>梯度稳定性处理</strong>：</li>\n</ol>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 在训练步骤中添加梯度裁剪</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>utils<span class=\"token punctuation\">.</span>clip_grad_norm_<span class=\"token punctuation\">(</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">.</span>parameters<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>criterion<span class=\"token punctuation\">.</span>parameters<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    max_norm<span class=\"token operator\">=</span><span class=\"token number\">1.0</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p>该实现通过以下方式解决原代码问题：</p>\n<ol>\n<li><strong>自动平衡机制</strong>：</li>\n</ol>\n<ul>\n<li>难任务（高方差项）自动获得低权重</li>\n<li>简单任务（低方差项）获得高权重</li>\n<li>通过反向传播自动调整权重</li>\n</ul>\n<ol start=\"2\">\n<li><strong>数值稳定性改进</strong>：</li>\n</ol>\n<ul>\n<li>使用 log 方差代替直接学习方差，避免除零错误</li>\n<li>初始值限制在合理范围</li>\n<li>梯度裁剪防止参数爆炸</li>\n</ul>\n<ol start=\"3\">\n<li><strong>可解释性增强</strong>：</li>\n</ol>\n<ul>\n<li>通过 TensorBoard 可直接观察每个任务的：\n<ul>\n<li>损失值变化曲线</li>\n<li>自适应权重变化（exp (-log_var)）</li>\n<li>方差参数演化</li>\n</ul>\n</li>\n</ul>\n<p>实际使用时需要注意：</p>\n<ol>\n<li>\n<p><strong>参数初始化</strong>：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 如果某些任务需要强调，可以调整初始值</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>nn<span class=\"token punctuation\">.</span>init<span class=\"token punctuation\">.</span>constant_<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>log_vars<span class=\"token punctuation\">[</span><span class=\"token number\">4</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">2.0</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 强调 HVI_L1 损失</span></pre></td></tr></table></figure></li>\n<li>\n<p><strong>学习率设置</strong>：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 为损失参数设置更小的学习率</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>optimizer <span class=\"token operator\">=</span> optim<span class=\"token punctuation\">.</span>Adam<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    <span class=\"token punctuation\">&#123;</span><span class=\"token string\">'params'</span><span class=\"token punctuation\">:</span> model<span class=\"token punctuation\">.</span>parameters<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'lr'</span><span class=\"token punctuation\">:</span> <span class=\"token number\">1e-4</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    <span class=\"token punctuation\">&#123;</span><span class=\"token string\">'params'</span><span class=\"token punctuation\">:</span> criterion<span class=\"token punctuation\">.</span>parameters<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'lr'</span><span class=\"token punctuation\">:</span> <span class=\"token number\">1e-5</span><span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure></li>\n<li>\n<p><strong>多阶段训练</strong>：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 初始阶段固定部分损失权重</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">if</span> epoch <span class=\"token operator\">&lt;</span> warmup_epochs<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    criterion<span class=\"token punctuation\">.</span>log_vars<span class=\"token punctuation\">.</span>requires_grad_<span class=\"token punctuation\">(</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    criterion<span class=\"token punctuation\">.</span>log_vars<span class=\"token punctuation\">.</span>requires_grad_<span class=\"token punctuation\">(</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure></li>\n</ol>\n<p>这种实现方式比手动调整 lambda 参数更科学，尤其在处理类似 HVI 这类新增损失时，能自动平衡其与原有损失项的关系。</p>\n</blockquote>\n<h1 id=\"余弦退火学习率调度器\"><a class=\"anchor\" href=\"#余弦退火学习率调度器\">#</a> 余弦退火学习率调度器</h1>\n<p>一代经典的学习率调度器。</p>\n<p>模板代码参考如：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># ... 其他导入 ...</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">from</span> torch<span class=\"token punctuation\">.</span>optim<span class=\"token punctuation\">.</span>lr_scheduler <span class=\"token keyword\">import</span> CosineAnnealingLR</pre></td></tr><tr><td data-num=\"3\"></td><td><pre></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    <span class=\"token comment\"># 参数解析</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    parser <span class=\"token operator\">=</span> argparse<span class=\"token punctuation\">.</span>ArgumentParser<span class=\"token punctuation\">(</span><span class=\"token string\">\"MAI_Denoised_Train\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    <span class=\"token comment\"># ... 原有参数 ...</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>    parser<span class=\"token punctuation\">.</span>add_argument<span class=\"token punctuation\">(</span><span class=\"token string\">'--min_lr'</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">type</span><span class=\"token operator\">=</span><span class=\"token builtin\">float</span><span class=\"token punctuation\">,</span> default<span class=\"token operator\">=</span><span class=\"token number\">1e-6</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">help</span><span class=\"token operator\">=</span><span class=\"token string\">'minimum learning rate for cosine annealing'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>    args <span class=\"token operator\">=</span> parser<span class=\"token punctuation\">.</span>parse_args<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>    <span class=\"token comment\"># ... 模型初始化 ...</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>  </pre></td></tr><tr><td data-num=\"13\"></td><td><pre>    <span class=\"token comment\"># 初始化优化器和调度器</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>    optimizer <span class=\"token operator\">=</span> optim<span class=\"token punctuation\">.</span>Adam<span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">.</span>parameters<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> lr<span class=\"token operator\">=</span>args<span class=\"token punctuation\">.</span>lr<span class=\"token punctuation\">,</span> betas<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">0.9</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.999</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> weight_decay<span class=\"token operator\">=</span><span class=\"token number\">1e-6</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>    scheduler <span class=\"token operator\">=</span> CosineAnnealingLR<span class=\"token punctuation\">(</span>optimizer<span class=\"token punctuation\">,</span> T_max<span class=\"token operator\">=</span>args<span class=\"token punctuation\">.</span>epochs<span class=\"token punctuation\">,</span> eta_min<span class=\"token operator\">=</span>args<span class=\"token punctuation\">.</span>min_lr<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>    <span class=\"token comment\"># 训练循环</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>    <span class=\"token keyword\">for</span> epoch <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>args<span class=\"token punctuation\">.</span>epochs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre>        <span class=\"token comment\"># 训练过程...</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>      </pre></td></tr><tr><td data-num=\"21\"></td><td><pre>        <span class=\"token comment\"># 验证过程...</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre>      </pre></td></tr><tr><td data-num=\"23\"></td><td><pre>        <span class=\"token comment\"># 更新学习率</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre>        scheduler<span class=\"token punctuation\">.</span>step<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"25\"></td><td><pre>      </pre></td></tr><tr><td data-num=\"26\"></td><td><pre>        <span class=\"token comment\"># 记录学习率</span></pre></td></tr><tr><td data-num=\"27\"></td><td><pre>        current_lr <span class=\"token operator\">=</span> scheduler<span class=\"token punctuation\">.</span>get_last_lr<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre>        writer<span class=\"token punctuation\">.</span>add_scalar<span class=\"token punctuation\">(</span><span class=\"token string\">'Learning Rate'</span><span class=\"token punctuation\">,</span> current_lr<span class=\"token punctuation\">,</span> epoch<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"29\"></td><td><pre>        logging<span class=\"token punctuation\">.</span>info<span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f'Epoch [</span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>epoch<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">/</span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>args<span class=\"token punctuation\">.</span>epochs<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">] Learning Rate: </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>current_lr<span class=\"token punctuation\">:</span><span class=\"token format-spec\">.7f</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">'</span></span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"30\"></td><td><pre></pre></td></tr><tr><td data-num=\"31\"></td><td><pre>    <span class=\"token comment\"># ... 后续代码 ...</span></pre></td></tr></table></figure><h1 id=\"optuna自动化调参\"><a class=\"anchor\" href=\"#optuna自动化调参\">#</a>  <code>Optuna</code>  自动化调参</h1>\n<blockquote>\n<p>为了使用 Optuna 进行超参数调优，我们需要对代码进行以下主要修改。这里展示关键修改步骤（完整代码见最后）：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">import</span> optuna</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">from</span> optuna<span class=\"token punctuation\">.</span>trial <span class=\"token keyword\">import</span> Trial</pre></td></tr><tr><td data-num=\"3\"></td><td><pre></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">objective</span><span class=\"token punctuation\">(</span>trial<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    <span class=\"token comment\"># 定义可调参数范围</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    args <span class=\"token operator\">=</span> argparse<span class=\"token punctuation\">.</span>Namespace<span class=\"token punctuation\">(</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>        batch_size<span class=\"token operator\">=</span>trial<span class=\"token punctuation\">.</span>suggest_categorical<span class=\"token punctuation\">(</span><span class=\"token string\">'batch_size'</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span> <span class=\"token number\">64</span><span class=\"token punctuation\">,</span> <span class=\"token number\">128</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>        lr<span class=\"token operator\">=</span>trial<span class=\"token punctuation\">.</span>suggest_float<span class=\"token punctuation\">(</span><span class=\"token string\">'lr'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1e-6</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1e-3</span><span class=\"token punctuation\">,</span> log<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>        lambda_hvi1<span class=\"token operator\">=</span>trial<span class=\"token punctuation\">.</span>suggest_float<span class=\"token punctuation\">(</span><span class=\"token string\">'lambda_hvi1'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.001</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>        lambda_hvi2<span class=\"token operator\">=</span>trial<span class=\"token punctuation\">.</span>suggest_float<span class=\"token punctuation\">(</span><span class=\"token string\">'lambda_hvi2'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.001</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>        lambda_rgb1<span class=\"token operator\">=</span>trial<span class=\"token punctuation\">.</span>suggest_float<span class=\"token punctuation\">(</span><span class=\"token string\">'lambda_rgb1'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>        lambda_rgb2<span class=\"token operator\">=</span>trial<span class=\"token punctuation\">.</span>suggest_float<span class=\"token punctuation\">(</span><span class=\"token string\">'lambda_rgb2'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>        <span class=\"token comment\"># 保留其他固定参数...</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>        cuda<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>        gpu<span class=\"token operator\">=</span><span class=\"token string\">'cuda:0'</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>        epochs<span class=\"token operator\">=</span><span class=\"token number\">100</span><span class=\"token punctuation\">,</span>  <span class=\"token comment\"># 调试时可减少 epoch</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>        save<span class=\"token operator\">=</span><span class=\"token string-interpolation\"><span class=\"token string\">f'./EXP/</span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>trial<span class=\"token punctuation\">.</span>number<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">'</span></span>  <span class=\"token comment\"># 为每个 trial 创建独立目录</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>    <span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>    <span class=\"token comment\"># 运行训练并返回验证指标</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>    final_psnr <span class=\"token operator\">=</span> train_model<span class=\"token punctuation\">(</span>args<span class=\"token punctuation\">,</span> trial<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre>    <span class=\"token keyword\">return</span> final_psnr</pre></td></tr><tr><td data-num=\"23\"></td><td><pre></pre></td></tr><tr><td data-num=\"24\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">train_model</span><span class=\"token punctuation\">(</span>args<span class=\"token punctuation\">,</span> trial<span class=\"token operator\">=</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"25\"></td><td><pre>    <span class=\"token comment\"># [原 main () 函数内容在这里重构]</span></pre></td></tr><tr><td data-num=\"26\"></td><td><pre>    <span class=\"token comment\"># 在验证循环中报告中间结果</span></pre></td></tr><tr><td data-num=\"27\"></td><td><pre>    <span class=\"token keyword\">if</span> trial<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre>        trial<span class=\"token punctuation\">.</span>report<span class=\"token punctuation\">(</span>val_psnr<span class=\"token punctuation\">,</span> epoch<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"29\"></td><td><pre>        <span class=\"token keyword\">if</span> trial<span class=\"token punctuation\">.</span>should_prune<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"30\"></td><td><pre>            <span class=\"token keyword\">raise</span> optuna<span class=\"token punctuation\">.</span>exceptions<span class=\"token punctuation\">.</span>TrialPruned<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"31\"></td><td><pre>    </pre></td></tr><tr><td data-num=\"32\"></td><td><pre>    <span class=\"token keyword\">return</span> best_val_psnr  <span class=\"token comment\"># 返回需要优化的指标</span></pre></td></tr><tr><td data-num=\"33\"></td><td><pre></pre></td></tr><tr><td data-num=\"34\"></td><td><pre><span class=\"token keyword\">if</span> __name__ <span class=\"token operator\">==</span> <span class=\"token string\">\"__main__\"</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"35\"></td><td><pre>    <span class=\"token comment\"># 创建 Optuna study</span></pre></td></tr><tr><td data-num=\"36\"></td><td><pre>    study <span class=\"token operator\">=</span> optuna<span class=\"token punctuation\">.</span>create_study<span class=\"token punctuation\">(</span></pre></td></tr><tr><td data-num=\"37\"></td><td><pre>        direction<span class=\"token operator\">=</span><span class=\"token string\">'maximize'</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"38\"></td><td><pre>        sampler<span class=\"token operator\">=</span>optuna<span class=\"token punctuation\">.</span>samplers<span class=\"token punctuation\">.</span>TPESampler<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"39\"></td><td><pre>        pruner<span class=\"token operator\">=</span>optuna<span class=\"token punctuation\">.</span>pruners<span class=\"token punctuation\">.</span>MedianPruner<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"40\"></td><td><pre>    <span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"41\"></td><td><pre>    </pre></td></tr><tr><td data-num=\"42\"></td><td><pre>    <span class=\"token comment\"># 运行优化</span></pre></td></tr><tr><td data-num=\"43\"></td><td><pre>    study<span class=\"token punctuation\">.</span>optimize<span class=\"token punctuation\">(</span>objective<span class=\"token punctuation\">,</span> n_trials<span class=\"token operator\">=</span><span class=\"token number\">50</span><span class=\"token punctuation\">,</span> timeout<span class=\"token operator\">=</span><span class=\"token number\">3600</span><span class=\"token operator\">*</span><span class=\"token number\">24</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"44\"></td><td><pre>    </pre></td></tr><tr><td data-num=\"45\"></td><td><pre>    <span class=\"token comment\"># 输出结果</span></pre></td></tr><tr><td data-num=\"46\"></td><td><pre>    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Best trial:\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"47\"></td><td><pre>    trial <span class=\"token operator\">=</span> study<span class=\"token punctuation\">.</span>best_trial</pre></td></tr><tr><td data-num=\"48\"></td><td><pre>    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"  Value: </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>trial<span class=\"token punctuation\">.</span>value<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"49\"></td><td><pre>    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"  Params: \"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"50\"></td><td><pre>    <span class=\"token keyword\">for</span> key<span class=\"token punctuation\">,</span> value <span class=\"token keyword\">in</span> trial<span class=\"token punctuation\">.</span>params<span class=\"token punctuation\">.</span>items<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"51\"></td><td><pre>        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"    </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>key<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">: </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>value<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p>主要修改点说明：</p>\n<ol>\n<li>\n<p><strong>参数建议</strong>：使用 trial.suggest_* 方法替代原 argparse 参数：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>trial<span class=\"token punctuation\">.</span>suggest_categorical<span class=\"token punctuation\">(</span><span class=\"token string\">'batch_size'</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span> <span class=\"token number\">64</span><span class=\"token punctuation\">,</span> <span class=\"token number\">128</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>trial<span class=\"token punctuation\">.</span>suggest_float<span class=\"token punctuation\">(</span><span class=\"token string\">'lr'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1e-6</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1e-3</span><span class=\"token punctuation\">,</span> log<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure></li>\n<li>\n<p><strong>目标函数</strong>：将训练过程封装到目标函数中，返回验证 PSNR 作为优化指标</p>\n</li>\n<li>\n<p><strong>中间报告</strong>：在训练过程中定期报告验证指标，支持提前终止：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>trial<span class=\"token punctuation\">.</span>report<span class=\"token punctuation\">(</span>val_psnr<span class=\"token punctuation\">,</span> epoch<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">if</span> trial<span class=\"token punctuation\">.</span>should_prune<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    <span class=\"token keyword\">raise</span> optuna<span class=\"token punctuation\">.</span>exceptions<span class=\"token punctuation\">.</span>TrialPruned<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure></li>\n<li>\n<p><strong>独立目录</strong>：为每个 trial 创建独立的保存目录，避免文件冲突：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>args<span class=\"token punctuation\">.</span>save <span class=\"token operator\">=</span> <span class=\"token string-interpolation\"><span class=\"token string\">f'./EXP/</span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>trial<span class=\"token punctuation\">.</span>number<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">'</span></span></pre></td></tr></table></figure></li>\n<li>\n<p><strong>Study 配置</strong>：创建优化 study 时指定优化方向（最大化 PSNR）和采样策略：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>study <span class=\"token operator\">=</span> optuna<span class=\"token punctuation\">.</span>create_study<span class=\"token punctuation\">(</span>direction<span class=\"token operator\">=</span><span class=\"token string\">'maximize'</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure></li>\n</ol>\n<p>完整整合后的代码示例：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">import</span> optuna</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">from</span> optuna<span class=\"token punctuation\">.</span>trial <span class=\"token keyword\">import</span> Trial</pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token keyword\">import</span> argparse</pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token keyword\">import</span> torch</pre></td></tr><tr><td data-num=\"5\"></td><td><pre></pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    <span class=\"token comment\"># 原始训练代码...</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre></pre></td></tr><tr><td data-num=\"9\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">objective</span><span class=\"token punctuation\">(</span>trial<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>    <span class=\"token comment\"># 定义超参数搜索空间</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>    params <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>        <span class=\"token string\">'batch_size'</span><span class=\"token punctuation\">:</span> trial<span class=\"token punctuation\">.</span>suggest_categorical<span class=\"token punctuation\">(</span><span class=\"token string\">'batch_size'</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span> <span class=\"token number\">64</span><span class=\"token punctuation\">,</span> <span class=\"token number\">128</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>        <span class=\"token string\">'lr'</span><span class=\"token punctuation\">:</span> trial<span class=\"token punctuation\">.</span>suggest_float<span class=\"token punctuation\">(</span><span class=\"token string\">'lr'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1e-6</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1e-3</span><span class=\"token punctuation\">,</span> log<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>        <span class=\"token string\">'lambda_hvi1'</span><span class=\"token punctuation\">:</span> trial<span class=\"token punctuation\">.</span>suggest_float<span class=\"token punctuation\">(</span><span class=\"token string\">'lambda_hvi1'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.001</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>        <span class=\"token string\">'lambda_hvi2'</span><span class=\"token punctuation\">:</span> trial<span class=\"token punctuation\">.</span>suggest_float<span class=\"token punctuation\">(</span><span class=\"token string\">'lambda_hvi2'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.001</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>        <span class=\"token string\">'lambda_rgb1'</span><span class=\"token punctuation\">:</span> trial<span class=\"token punctuation\">.</span>suggest_float<span class=\"token punctuation\">(</span><span class=\"token string\">'lambda_rgb1'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2.0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>        <span class=\"token string\">'lambda_rgb2'</span><span class=\"token punctuation\">:</span> trial<span class=\"token punctuation\">.</span>suggest_float<span class=\"token punctuation\">(</span><span class=\"token string\">'lambda_rgb2'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2.0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>        <span class=\"token string\">'lambda_res'</span><span class=\"token punctuation\">:</span> trial<span class=\"token punctuation\">.</span>suggest_float<span class=\"token punctuation\">(</span><span class=\"token string\">'lambda_res'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2.0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre>        <span class=\"token string\">'lambda_cons'</span><span class=\"token punctuation\">:</span> trial<span class=\"token punctuation\">.</span>suggest_float<span class=\"token punctuation\">(</span><span class=\"token string\">'lambda_cons'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2.0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>    </pre></td></tr><tr><td data-num=\"22\"></td><td><pre>    <span class=\"token comment\"># 固定参数</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>    fixed_params <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre>        <span class=\"token string\">'cuda'</span><span class=\"token punctuation\">:</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"25\"></td><td><pre>        <span class=\"token string\">'gpu'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'cuda:0'</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"26\"></td><td><pre>        <span class=\"token string\">'epochs'</span><span class=\"token punctuation\">:</span> <span class=\"token number\">100</span><span class=\"token punctuation\">,</span>  <span class=\"token comment\"># 调优时 epoch 可以适当减少</span></pre></td></tr><tr><td data-num=\"27\"></td><td><pre>        <span class=\"token string\">'data_dir'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'/path/to/data'</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre>        <span class=\"token string\">'save'</span><span class=\"token punctuation\">:</span> <span class=\"token string-interpolation\"><span class=\"token string\">f'./EXP/trial_</span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>trial<span class=\"token punctuation\">.</span>number<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">'</span></span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"29\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"30\"></td><td><pre>    </pre></td></tr><tr><td data-num=\"31\"></td><td><pre>    <span class=\"token comment\"># 合并参数</span></pre></td></tr><tr><td data-num=\"32\"></td><td><pre>    args <span class=\"token operator\">=</span> argparse<span class=\"token punctuation\">.</span>Namespace<span class=\"token punctuation\">(</span><span class=\"token operator\">**</span><span class=\"token punctuation\">&#123;</span><span class=\"token operator\">**</span>params<span class=\"token punctuation\">,</span> <span class=\"token operator\">**</span>fixed_params<span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"33\"></td><td><pre>    </pre></td></tr><tr><td data-num=\"34\"></td><td><pre>    <span class=\"token comment\"># 运行训练</span></pre></td></tr><tr><td data-num=\"35\"></td><td><pre>    best_psnr <span class=\"token operator\">=</span> train_with_args<span class=\"token punctuation\">(</span>args<span class=\"token punctuation\">,</span> trial<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"36\"></td><td><pre>    <span class=\"token keyword\">return</span> best_psnr</pre></td></tr><tr><td data-num=\"37\"></td><td><pre></pre></td></tr><tr><td data-num=\"38\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">train_with_args</span><span class=\"token punctuation\">(</span>args<span class=\"token punctuation\">,</span> trial<span class=\"token operator\">=</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"39\"></td><td><pre>    <span class=\"token comment\"># [原 main () 函数内容重构到这里]</span></pre></td></tr><tr><td data-num=\"40\"></td><td><pre>    <span class=\"token comment\"># 初始化模型、数据加载等...</span></pre></td></tr><tr><td data-num=\"41\"></td><td><pre>    </pre></td></tr><tr><td data-num=\"42\"></td><td><pre>    best_psnr <span class=\"token operator\">=</span> <span class=\"token number\">0</span></pre></td></tr><tr><td data-num=\"43\"></td><td><pre>    <span class=\"token keyword\">for</span> epoch <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>args<span class=\"token punctuation\">.</span>epochs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"44\"></td><td><pre>        <span class=\"token comment\"># 训练循环...</span></pre></td></tr><tr><td data-num=\"45\"></td><td><pre>        </pre></td></tr><tr><td data-num=\"46\"></td><td><pre>        <span class=\"token comment\"># 验证循环</span></pre></td></tr><tr><td data-num=\"47\"></td><td><pre>        <span class=\"token keyword\">with</span> torch<span class=\"token punctuation\">.</span>no_grad<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"48\"></td><td><pre>            val_psnr <span class=\"token operator\">=</span> evaluate<span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">,</span> val_loader<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"49\"></td><td><pre>            </pre></td></tr><tr><td data-num=\"50\"></td><td><pre>            <span class=\"token comment\"># 向 Optuna 报告中间结果</span></pre></td></tr><tr><td data-num=\"51\"></td><td><pre>            <span class=\"token keyword\">if</span> trial<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"52\"></td><td><pre>                trial<span class=\"token punctuation\">.</span>report<span class=\"token punctuation\">(</span>val_psnr<span class=\"token punctuation\">,</span> epoch<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"53\"></td><td><pre>                </pre></td></tr><tr><td data-num=\"54\"></td><td><pre>                <span class=\"token comment\"># 提前终止</span></pre></td></tr><tr><td data-num=\"55\"></td><td><pre>                <span class=\"token keyword\">if</span> trial<span class=\"token punctuation\">.</span>should_prune<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"56\"></td><td><pre>                    <span class=\"token keyword\">raise</span> optuna<span class=\"token punctuation\">.</span>exceptions<span class=\"token punctuation\">.</span>TrialPruned<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"57\"></td><td><pre>                    </pre></td></tr><tr><td data-num=\"58\"></td><td><pre>        <span class=\"token keyword\">if</span> val_psnr <span class=\"token operator\">></span> best_psnr<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"59\"></td><td><pre>            best_psnr <span class=\"token operator\">=</span> val_psnr</pre></td></tr><tr><td data-num=\"60\"></td><td><pre>            torch<span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">.</span>state_dict<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token string-interpolation\"><span class=\"token string\">f\"</span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>args<span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">/best_model.pth\"</span></span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"61\"></td><td><pre>    </pre></td></tr><tr><td data-num=\"62\"></td><td><pre>    <span class=\"token keyword\">return</span> best_psnr</pre></td></tr><tr><td data-num=\"63\"></td><td><pre></pre></td></tr><tr><td data-num=\"64\"></td><td><pre><span class=\"token keyword\">if</span> __name__ <span class=\"token operator\">==</span> <span class=\"token string\">\"__main__\"</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"65\"></td><td><pre>    <span class=\"token comment\"># 创建 Optuna study</span></pre></td></tr><tr><td data-num=\"66\"></td><td><pre>    study <span class=\"token operator\">=</span> optuna<span class=\"token punctuation\">.</span>create_study<span class=\"token punctuation\">(</span></pre></td></tr><tr><td data-num=\"67\"></td><td><pre>        direction<span class=\"token operator\">=</span><span class=\"token string\">'maximize'</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"68\"></td><td><pre>        sampler<span class=\"token operator\">=</span>optuna<span class=\"token punctuation\">.</span>samplers<span class=\"token punctuation\">.</span>TPESampler<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"69\"></td><td><pre>        pruner<span class=\"token operator\">=</span>optuna<span class=\"token punctuation\">.</span>pruners<span class=\"token punctuation\">.</span>MedianPruner<span class=\"token punctuation\">(</span>n_startup_trials<span class=\"token operator\">=</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span> n_warmup_steps<span class=\"token operator\">=</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"70\"></td><td><pre>    <span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"71\"></td><td><pre>    </pre></td></tr><tr><td data-num=\"72\"></td><td><pre>    <span class=\"token comment\"># 运行优化</span></pre></td></tr><tr><td data-num=\"73\"></td><td><pre>    study<span class=\"token punctuation\">.</span>optimize<span class=\"token punctuation\">(</span>objective<span class=\"token punctuation\">,</span> n_trials<span class=\"token operator\">=</span><span class=\"token number\">50</span><span class=\"token punctuation\">,</span> timeout<span class=\"token operator\">=</span><span class=\"token number\">3600</span><span class=\"token operator\">*</span><span class=\"token number\">24</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"74\"></td><td><pre>    </pre></td></tr><tr><td data-num=\"75\"></td><td><pre>    <span class=\"token comment\"># 输出最佳结果</span></pre></td></tr><tr><td data-num=\"76\"></td><td><pre>    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Best trial:\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"77\"></td><td><pre>    trial <span class=\"token operator\">=</span> study<span class=\"token punctuation\">.</span>best_trial</pre></td></tr><tr><td data-num=\"78\"></td><td><pre>    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"  PSNR: </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>trial<span class=\"token punctuation\">.</span>value<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"79\"></td><td><pre>    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"  Params: \"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"80\"></td><td><pre>    <span class=\"token keyword\">for</span> key<span class=\"token punctuation\">,</span> value <span class=\"token keyword\">in</span> trial<span class=\"token punctuation\">.</span>params<span class=\"token punctuation\">.</span>items<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"81\"></td><td><pre>        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"    </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>key<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">: </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>value<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p>关键优化技巧：</p>\n<ol>\n<li>\n<p><strong>参数范围设置</strong>：根据参数性质选择适当的范围：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>trial<span class=\"token punctuation\">.</span>suggest_float<span class=\"token punctuation\">(</span><span class=\"token string\">'lr'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1e-6</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1e-3</span><span class=\"token punctuation\">,</span> log<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 对数尺度更适合学习率</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>trial<span class=\"token punctuation\">.</span>suggest_categorical<span class=\"token punctuation\">(</span><span class=\"token string\">'batch_size'</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span> <span class=\"token number\">64</span><span class=\"token punctuation\">,</span> <span class=\"token number\">128</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure></li>\n<li>\n<p><strong>提前终止</strong>：使用 MedianPruner 避免资源浪费：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>pruner<span class=\"token operator\">=</span>optuna<span class=\"token punctuation\">.</span>pruners<span class=\"token punctuation\">.</span>MedianPruner<span class=\"token punctuation\">(</span>n_startup_trials<span class=\"token operator\">=</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span> n_warmup_steps<span class=\"token operator\">=</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure></li>\n<li>\n<p><strong>并行优化</strong>：通过指定 n_jobs 并行运行：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>study<span class=\"token punctuation\">.</span>optimize<span class=\"token punctuation\">(</span>objective<span class=\"token punctuation\">,</span> n_trials<span class=\"token operator\">=</span><span class=\"token number\">100</span><span class=\"token punctuation\">,</span> n_jobs<span class=\"token operator\">=</span><span class=\"token number\">4</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure></li>\n<li>\n<p><strong>持久化存储</strong>：使用数据库保存进度：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>study <span class=\"token operator\">=</span> optuna<span class=\"token punctuation\">.</span>create_study<span class=\"token punctuation\">(</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    storage<span class=\"token operator\">=</span><span class=\"token string\">'sqlite:///optuna.db'</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    study_name<span class=\"token operator\">=</span><span class=\"token string\">'denoising_study'</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    load_if_exists<span class=\"token operator\">=</span><span class=\"token boolean\">True</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token punctuation\">)</span></pre></td></tr></table></figure></li>\n</ol>\n<p>注意事项：</p>\n<ol>\n<li>\n<p><strong>资源管理</strong>：调优时适当减少 epoch 数量（如 50-100），最终训练时再用完整 epoch</p>\n</li>\n<li>\n<p><strong>参数空间</strong>：初始搜索使用较宽范围，后期可基于初步结果缩小范围</p>\n</li>\n<li>\n<p><strong>指标选择</strong>：建议使用验证集 PSNR 作为优化目标，而非训练损失</p>\n</li>\n<li>\n<p><strong>随机种子</strong>：为保持可比性，可在每个 trial 中固定随机种子：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>torch<span class=\"token punctuation\">.</span>manual_seed<span class=\"token punctuation\">(</span>trial<span class=\"token punctuation\">.</span>suggest_int<span class=\"token punctuation\">(</span><span class=\"token string\">'seed'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1000</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure></li>\n<li>\n<p><strong>GPU 内存</strong>：注意 batch_size 与 GPU 显存的匹配，建议在 suggest_categorical 中包含可行值</p>\n</li>\n</ol>\n<p>这种集成方式可以在不破坏原有训练逻辑的基础上，系统性地探索超参数空间。最终可以通过 study.best_trial.params 获取最佳参数组合，用于最终模型的训练。</p>\n</blockquote>\n<h1 id=\"混合精度训练\"><a class=\"anchor\" href=\"#混合精度训练\">#</a> 混合精度训练</h1>\n<h1 id=\"梯度累积\"><a class=\"anchor\" href=\"#梯度累积\">#</a> 梯度累积</h1>\n<p>通过多次小批量迭代累积梯度，模拟大  <code>Batch Size</code>  的效果，模板代码参考可见下方：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>accumulation_steps <span class=\"token operator\">=</span> <span class=\"token number\">4</span>  <span class=\"token comment\"># 累积 4 个 batch 的梯度</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">for</span> i<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>inputs<span class=\"token punctuation\">,</span> labels<span class=\"token punctuation\">)</span> <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>dataloader<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    outputs <span class=\"token operator\">=</span> model<span class=\"token punctuation\">(</span>inputs<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    loss <span class=\"token operator\">=</span> criterion<span class=\"token punctuation\">(</span>outputs<span class=\"token punctuation\">,</span> labels<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    loss <span class=\"token operator\">=</span> loss <span class=\"token operator\">/</span> accumulation_steps  <span class=\"token comment\"># 损失按累积步数缩放</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    loss<span class=\"token punctuation\">.</span>backward<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    </pre></td></tr><tr><td data-num=\"8\"></td><td><pre>    <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>i <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">%</span> accumulation_steps <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>        optimizer<span class=\"token punctuation\">.</span>step<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>        optimizer<span class=\"token punctuation\">.</span>zero_grad<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><h1 id=\"torchinfo统计模型的显存占用\"><a class=\"anchor\" href=\"#torchinfo统计模型的显存占用\">#</a>  <code>torchinfo</code>  统计模型的显存占用</h1>\n<p>参考如下代码：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">from</span> torchinfo <span class=\"token keyword\">import</span> summary</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>model <span class=\"token operator\">=</span> MyModel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>cuda<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>summary<span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">,</span> input_size<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>batch_size<span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">256</span><span class=\"token punctuation\">,</span> <span class=\"token number\">256</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><h1 id=\"显存分析器memory_profiler\"><a class=\"anchor\" href=\"#显存分析器memory_profiler\">#</a> 显存分析器 <code>memory_profiler</code></h1>\n<p>这个工具可以可以统计每行代码的显存变化</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">from</span> pytorch_memlab <span class=\"token keyword\">import</span> LineProfiler</pre></td></tr><tr><td data-num=\"2\"></td><td><pre></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token decorator annotation punctuation\">@profile</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">train_batch</span><span class=\"token punctuation\">(</span>inputs<span class=\"token punctuation\">,</span> labels<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    outputs <span class=\"token operator\">=</span> model<span class=\"token punctuation\">(</span>inputs<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    loss <span class=\"token operator\">=</span> criterion<span class=\"token punctuation\">(</span>outputs<span class=\"token punctuation\">,</span> labels<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    loss<span class=\"token punctuation\">.</span>backward<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>    optimizer<span class=\"token punctuation\">.</span>step<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre></pre></td></tr><tr><td data-num=\"10\"></td><td><pre><span class=\"token comment\"># 运行后会打印每行代码的显存变化</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>train_batch<span class=\"token punctuation\">(</span>inputs<span class=\"token punctuation\">,</span> labels<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><h1 id=\"dataloader的num_workers设置\"><a class=\"anchor\" href=\"#dataloader的num_workers设置\">#</a>  <code>Dataloader</code>  的 <code>num_workers</code>  设置</h1>\n<p><code>num_workers</code>  通常设置为 0， <code>CPU</code>  线程数的 <code>75%</code> ， <code>CPU</code>  线程数， <code>CPU</code>  线程数的两倍。</p>\n<p><code>CPU</code>  的线程数计算公式为：线程数 = 逻辑核心数 = 物理核心数 * 单核线程数。</p>\n<p><code>num_workers</code>  很大程度上影响 <code>GPU</code>  的占用率。保持长时间的高 <code>GPU</code>  占用率是高效率训练深度学习的基础。</p>\n<h1 id=\"损失为nan的分析\"><a class=\"anchor\" href=\"#损失为nan的分析\">#</a> 损失为 <code>Nan</code>  的分析</h1>\n<blockquote>\n<p>损失值出现 NaN（Not a Number）通常由数值不稳定引起，以下是可能原因及解决方案：</p>\n<h4 id=\"1-输入数据问题\"><a class=\"anchor\" href=\"#1-输入数据问题\">#</a> 1. <strong>输入数据问题</strong></h4>\n<ul>\n<li>\n<p><strong>检查数据中的 NaN 或异常值</strong>：确保输入数据无缺失或无效值。</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"NaN in data:\"</span><span class=\"token punctuation\">,</span> np<span class=\"token punctuation\">.</span>isnan<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">any</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"数据范围:\"</span><span class=\"token punctuation\">,</span> data<span class=\"token punctuation\">.</span><span class=\"token builtin\">min</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> data<span class=\"token punctuation\">.</span><span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure></li>\n<li>\n<p><strong>数据标准化 / 归一化</strong>：过大或过小的输入值可能导致梯度爆炸。</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>data <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>data <span class=\"token operator\">-</span> data<span class=\"token punctuation\">.</span>mean<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> data<span class=\"token punctuation\">.</span>std<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 标准化</span></pre></td></tr></table></figure></li>\n</ul>\n<h4 id=\"2-学习率过高\"><a class=\"anchor\" href=\"#2-学习率过高\">#</a> 2. <strong>学习率过高</strong></h4>\n<ul>\n<li><strong>降低学习率</strong>：过大的学习率会导致参数更新不稳定。<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>optimizer <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>optim<span class=\"token punctuation\">.</span>SGD<span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">.</span>parameters<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> lr<span class=\"token operator\">=</span><span class=\"token number\">0.01</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 初始学习率设为 0.01 或更小</span></pre></td></tr></table></figure></li>\n</ul>\n<h4 id=\"3-损失函数实现问题\"><a class=\"anchor\" href=\"#3-损失函数实现问题\">#</a> 3. <strong>损失函数实现问题</strong></h4>\n<ul>\n<li>\n<p><strong>避免对零取对数</strong>：在交叉熵损失中增加极小值 ε（如 1e-8）。</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>loss <span class=\"token operator\">=</span> <span class=\"token operator\">-</span>tf<span class=\"token punctuation\">.</span>reduce_sum<span class=\"token punctuation\">(</span>y_true <span class=\"token operator\">*</span> tf<span class=\"token punctuation\">.</span>math<span class=\"token punctuation\">.</span>log<span class=\"token punctuation\">(</span>y_pred <span class=\"token operator\">+</span> <span class=\"token number\">1e-8</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure></li>\n<li>\n<p><strong>使用框架内置函数</strong>：如 TensorFlow 的 <code>CategoricalCrossentropy(from_logits=True)</code> ，避免手动实现中的错误。</p>\n</li>\n</ul>\n<h4 id=\"4-梯度爆炸前提是你的其他代码得写对\"><a class=\"anchor\" href=\"#4-梯度爆炸前提是你的其他代码得写对\">#</a> 4. <strong>梯度爆炸（前提是你的其他代码得写对）</strong></h4>\n<ul>\n<li>\n<p><strong>梯度裁剪</strong>：限制梯度最大范数。</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># PyTorch 示例</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>utils<span class=\"token punctuation\">.</span>clip_grad_norm_<span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">.</span>parameters<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> max_norm<span class=\"token operator\">=</span><span class=\"token number\">1.0</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># TensorFlow 示例</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>gradients <span class=\"token operator\">=</span> tape<span class=\"token punctuation\">.</span>gradient<span class=\"token punctuation\">(</span>loss<span class=\"token punctuation\">,</span> model<span class=\"token punctuation\">.</span>trainable_variables<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>gradients<span class=\"token punctuation\">,</span> _ <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>clip_by_global_norm<span class=\"token punctuation\">(</span>gradients<span class=\"token punctuation\">,</span> <span class=\"token number\">1.0</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>optimizer<span class=\"token punctuation\">.</span>apply_gradients<span class=\"token punctuation\">(</span><span class=\"token builtin\">zip</span><span class=\"token punctuation\">(</span>gradients<span class=\"token punctuation\">,</span> model<span class=\"token punctuation\">.</span>trainable_variables<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure></li>\n</ul>\n<h4 id=\"5-模型结构问题\"><a class=\"anchor\" href=\"#5-模型结构问题\">#</a> 5. <strong>模型结构问题</strong></h4>\n<ul>\n<li><strong>激活函数与输出层匹配</strong>：分类任务最后一层需用 Softmax（或配合 <code>from_logits=True</code> ）。</li>\n<li><strong>权重初始化</strong>：使用 He/Xavier 初始化避免初始值过大。<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># PyTorch 示例</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>init<span class=\"token punctuation\">.</span>kaiming_normal_<span class=\"token punctuation\">(</span>layer<span class=\"token punctuation\">.</span>weight<span class=\"token punctuation\">)</span></pre></td></tr></table></figure></li>\n</ul>\n<h4 id=\"6-数值稳定性技巧\"><a class=\"anchor\" href=\"#6-数值稳定性技巧\">#</a> 6. <strong>数值稳定性技巧</strong></h4>\n<ul>\n<li><strong>添加 Batch Normalization</strong>：稳定层间输出分布。<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>model<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>BatchNormalization<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure></li>\n<li><strong>混合精度训练</strong>：使用 FP16 时，开启梯度缩放。<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>optimizer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>mixed_precision<span class=\"token punctuation\">.</span>LossScaleOptimizer<span class=\"token punctuation\">(</span>optimizer<span class=\"token punctuation\">)</span></pre></td></tr></table></figure></li>\n</ul>\n<h4 id=\"7-调试步骤\"><a class=\"anchor\" href=\"#7-调试步骤\">#</a> 7. <strong>调试步骤</strong></h4>\n<ul>\n<li><strong>小数据集测试</strong>：用少量样本过拟合，快速复现问题。</li>\n<li><strong>打印中间结果</strong>：检查前向传播输出和梯度。<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 检查输出层</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"模型输出:\"</span><span class=\"token punctuation\">,</span> outputs<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token comment\"># 检查梯度</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token keyword\">for</span> name<span class=\"token punctuation\">,</span> param <span class=\"token keyword\">in</span> model<span class=\"token punctuation\">.</span>named_parameters<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    <span class=\"token keyword\">if</span> param<span class=\"token punctuation\">.</span>grad <span class=\"token keyword\">is</span> <span class=\"token keyword\">not</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"梯度 </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>name<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">: </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>param<span class=\"token punctuation\">.</span>grad<span class=\"token punctuation\">.</span>norm<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure></li>\n</ul>\n<h4 id=\"8-其他可能原因\"><a class=\"anchor\" href=\"#8-其他可能原因\">#</a> 8. <strong>其他可能原因</strong></h4>\n<ul>\n<li><strong>正则化过强</strong>：降低 L2 正则化系数。</li>\n<li><strong>数据预处理错误</strong>：检查标准化时是否除以零（如方差为零的特征）。</li>\n</ul>\n<h4 id=\"总结流程\"><a class=\"anchor\" href=\"#总结流程\">#</a> 总结流程</h4>\n<ol>\n<li><strong>检查输入数据</strong>：确保无 NaN 且已标准化。</li>\n<li><strong>降低学习率</strong>：尝试 0.001 或更低。</li>\n<li><strong>验证损失函数</strong>：使用内置函数或添加 ε。</li>\n<li><strong>梯度裁剪</strong>：限制梯度大小。</li>\n<li><strong>检查模型结构</strong>：激活函数、初始化、添加 BatchNorm。</li>\n<li><strong>逐步调试</strong>：缩小数据范围，打印中间变量。</li>\n</ol>\n<p>通过以上步骤逐步排查，通常可以定位并解决 NaN 损失问题。</p>\n</blockquote>\n<h1 id=\"torchvisionutilssave_image\"><a class=\"anchor\" href=\"#torchvisionutilssave_image\">#</a>  <code>torchvision.utils.save_image</code></h1>\n<p>有个参数叫做 <code>Normalize</code> ，这个将数值映射到 <code>[0,255]</code>  的区间。相关使用说明如下：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>当设置normalize<span class=\"token operator\">=</span><span class=\"token boolean\">True</span>时：</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token operator\">-</span> 会自动将张量的数值范围从<span class=\"token punctuation\">[</span><span class=\"token builtin\">min</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">max</span><span class=\"token punctuation\">]</span>线性映射到<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">255</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token operator\">-</span> 例如：输入张量范围是<span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span>，会被映射到<span class=\"token number\">0</span><span class=\"token operator\">-</span><span class=\"token number\">255</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token operator\">-</span> 例如：输入张量范围是<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span>，会被映射到<span class=\"token number\">0</span><span class=\"token operator\">-</span><span class=\"token number\">255</span>（相当于直接乘以<span class=\"token number\">255</span>）</pre></td></tr></table></figure><p><code>torchvision.utils.save_image</code>  保存图像要求图像的数值范围必须是指定范围，即在 <code>[0,1]</code>  或 <code>[0,255]</code> 。如果数据范围在其他区间，则需要保证数据范围符合 <code>torchvision.utils.save_image</code>  的要求，可通过设置 <code>normalize</code>  为 <code>True</code>  解决这个问题。</p>\n<h1 id=\"确保python优先加载本地项目的代码而不是anaconda环境中的库\"><a class=\"anchor\" href=\"#确保python优先加载本地项目的代码而不是anaconda环境中的库\">#</a> 确保 <code>Python</code>  优先加载本地项目的代码而不是 <code>Anaconda</code>  环境中的库</h1>\n<p>情景： <code>TinyNeuralNetwork</code>  库代码在项目文件夹 <code>Retinexformer</code>  下面， <code>Anaconda</code>  也有一个 <code>TinyNeuralNetwork</code>  库。现在我们在本地更新了 <code>TinyNeuralNetwork</code>  库代码，想要运行更新后的库代码中的 <code>convert.py</code>  代码。这个时候 Python 有可能会在执行新库代码 <code>convert.py</code>  的时候，调用 <code>Anaconda</code>  环境的旧库代码。</p>\n<p>一种方法是指定优先级，强制优先加载项目中的本地库：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">import</span> sys</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">import</span> os</pre></td></tr><tr><td data-num=\"3\"></td><td><pre></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token comment\"># 获取当前脚本所在目录（TinyNeuralNetwork 文件夹的路径）</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>TINYNN_DIR <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>dirname<span class=\"token punctuation\">(</span>os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>abspath<span class=\"token punctuation\">(</span>__file__<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token comment\"># 获取项目根目录（假设 TinyNeuralNetwork 是 Retinexformer 的子目录）</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>PROJECT_ROOT <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>dirname<span class=\"token punctuation\">(</span>TINYNN_DIR<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre></pre></td></tr><tr><td data-num=\"9\"></td><td><pre><span class=\"token comment\"># 将本地库路径插入到 sys.path 的最前面</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>sys<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>insert<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> TINYNN_DIR<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>sys<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>insert<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> PROJECT_ROOT<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre></pre></td></tr><tr><td data-num=\"13\"></td><td><pre><span class=\"token comment\"># 打印验证路径是否正确添加（可选）</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"当前 Python 路径:\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre><span class=\"token keyword\">for</span> p <span class=\"token keyword\">in</span> sys<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>p<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p>另一种方式就是在终端执行 <code>convert.py</code>  而不是在 <code>IDE</code>  中运行：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token operator\">></span> cd Retinexformer</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token operator\">></span> export PYTHONPATH<span class=\"token operator\">=</span><span class=\"token string\">\"$PWD:$PYTHONPATH\"</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token operator\">></span> python convert<span class=\"token punctuation\">.</span>py</pre></td></tr></table></figure>",
            "tags": [
                "人工智能"
            ]
        }
    ]
}