{
    "version": "https://jsonfeed.org/version/1",
    "title": "枯萎的花将在另一彼岸悄然绽放",
    "subtitle": null,
    "icon": "https://yunhdan.github.io/images/favicon.ico",
    "description": "计算机视觉 & 图像恢复",
    "home_page_url": "https://yunhdan.github.io",
    "items": [
        {
            "id": "https://yunhdan.github.io/other/%E8%B0%88%E5%88%A4%E6%8A%80%E5%B7%A7/",
            "url": "https://yunhdan.github.io/other/%E8%B0%88%E5%88%A4%E6%8A%80%E5%B7%A7/",
            "title": "实用谈判技巧",
            "date_published": "2025-07-16T06:42:42.535Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"\\assets\\css\\APlayer.min.css\"><script src=\"\\assets\\js\\APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>:::info </p>\n<p>学习自白斌老师的谈判实用技巧。</p>\n<p>:::</p>\n<ul>\n<li>移花接木：若对方的要求十分难以接受，当面拒绝不合适时，可以首先进行同意，然后再提出一个让对方难以接受的条件进行拒绝。“送我宝马”“可以，但有个条件，我要让你送我一栋别墅”。</li>\n<li>降低对方期待值：如果对方想要让你接受一个比较坏的结果，你可以告知他接受该结果后的一个更坏的局面。反之亦然，让对方接受一个东西，若对方不接受，则告知将会面临一个更大的后果。</li>\n</ul>\n",
            "tags": [
                "琐碎"
            ]
        },
        {
            "id": "https://yunhdan.github.io/research/%E6%9C%9F%E5%88%8A%E3%80%81%E4%BC%9A%E8%AE%AE%E6%8A%95%E7%A8%BF%E7%BB%8F%E9%AA%8C/",
            "url": "https://yunhdan.github.io/research/%E6%9C%9F%E5%88%8A%E3%80%81%E4%BC%9A%E8%AE%AE%E6%8A%95%E7%A8%BF%E7%BB%8F%E9%AA%8C/",
            "title": "期刊、会议投稿经验",
            "date_published": "2025-07-07T07:44:16.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"\\assets\\css\\APlayer.min.css\"><script src=\"\\assets\\js\\APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h1 id=\"简单介绍会议的Peer-Review和Rebuttal，重点提供了Rebuttal经验\"><a href=\"#简单介绍会议的Peer-Review和Rebuttal，重点提供了Rebuttal经验\" class=\"headerlink\" title=\"简单介绍会议的Peer Review和Rebuttal，重点提供了Rebuttal经验\"></a>简单介绍会议的Peer Review和Rebuttal，重点提供了Rebuttal经验</h1><ul>\n<li><p><span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cuemhpaHUuY29tL3RhcmRpcy96bS9hcnQvMTA0Mjk4OTIzP3NvdXJjZV9pZD0xMDA1\">https://www.zhihu.com/tardis/zm/art/104298923?source_id=1005</span></p>\n<h1 id=\"一些会议的Rebuttal经历供参考\"><a href=\"#一些会议的Rebuttal经历供参考\" class=\"headerlink\" title=\"一些会议的Rebuttal经历供参考\"></a>一些会议的Rebuttal经历供参考</h1></li>\n<li><p>原文名为记录一次神奇的Rebuttal经历：<span class=\"exturl\" data-url=\"aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8zNTM3NjE5MjA=\">https://zhuanlan.zhihu.com/p/353761920</span></p>\n</li>\n</ul>\n",
            "tags": [
                "学术"
            ]
        },
        {
            "id": "https://yunhdan.github.io/other/%E6%80%9D%E6%83%B3%E5%BB%BA%E8%AE%BE/",
            "url": "https://yunhdan.github.io/other/%E6%80%9D%E6%83%B3%E5%BB%BA%E8%AE%BE/",
            "title": "思想建设",
            "date_published": "2025-07-07T07:43:52.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"\\assets\\css\\APlayer.min.css\"><script src=\"\\assets\\js\\APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>:::info</p>\n<p>自有记载以来，所有宝贵的思想。</p>\n<p>:::</p>\n<h1 id=\"2025-07\"><a href=\"#2025-07\" class=\"headerlink\" title=\"2025-07\"></a>2025-07</h1><ul>\n<li>与其认定自己已经注定败局，不如相信自己将来能赢。</li>\n<li>一切事物都有两面性，正如一条发布到网上的评论，无论有多少人喷，一定会有站在你的立场，理解你支持你的人。风险与机遇并存，巨大的挑战背景下，一定伴有着令人垂涎的宝物。</li>\n<li></li>\n</ul>\n",
            "tags": [
                "琐碎"
            ]
        },
        {
            "id": "https://yunhdan.github.io/research/2025-CVPR-Workshop-Mobile-AI-SRGB-Photo-Enhancement-Challenge-Report%E7%A0%94%E7%A9%B6%E6%80%9D%E8%80%83/",
            "url": "https://yunhdan.github.io/research/2025-CVPR-Workshop-Mobile-AI-SRGB-Photo-Enhancement-Challenge-Report%E7%A0%94%E7%A9%B6%E6%80%9D%E8%80%83/",
            "title": "2025 CVPR Workshop - Mobile AI SRGB Photo Enhancement Challenge Report研究思考",
            "date_published": "2025-07-02T14:38:47.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"\\assets\\css\\APlayer.min.css\"><script src=\"\\assets\\js\\APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h1 id=\"DaHua-IIG-Team\"><a href=\"#DaHua-IIG-Team\" class=\"headerlink\" title=\"DaHua-IIG Team\"></a>DaHua-IIG Team</h1><p><img data-src=\"../../assets/cvprw1.png\" alt=\"image\"></p>\n<p><strong>思考</strong>：</p>\n",
            "tags": [
                "学术"
            ]
        },
        {
            "id": "https://yunhdan.github.io/cs/Linux/",
            "url": "https://yunhdan.github.io/cs/Linux/",
            "title": "Linux",
            "date_published": "2025-07-01T15:39:51.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"\\assets\\css\\APlayer.min.css\"><script src=\"\\assets\\js\\APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h1 id=\"关于移动命令mv\"><a href=\"#关于移动命令mv\" class=\"headerlink\" title=\"关于移动命令mv\"></a>关于移动命令<code>mv</code></h1><p>移动某个文件夹中所有内容到另一个文件夹内：</p>\n<pre><code class=\"lang-bash\">mv /path/to/source/folder/* /path/to/destination/folder/\n</code></pre>\n<p>但是，如果源文件夹的文件量过大，就会报这样的错误：</p>\n<pre><code class=\"lang-bash\">bash: /usr/bin/mv: 参数列表过长\n</code></pre>\n<p>当使用通配符 <code>*</code> 扩展的文件数量超过了系统允许的最大命令行参数限制时就会报这个错误。这是 Linux 系统的一个保护机制，防止用户意外执行可能破坏系统的命令。</p>\n<p>用这个命令替代以解决：</p>\n<pre><code class=\"lang-bash\">find /path/to/source/folder/* -mindepth 1 -maxdepth 1 -print0 | xargs -0 mv -t /path/to/destination/folder/\n</code></pre>\n<h1 id=\"查看某个文件夹下有多少个文件\"><a href=\"#查看某个文件夹下有多少个文件\" class=\"headerlink\" title=\"查看某个文件夹下有多少个文件\"></a>查看某个文件夹下有多少个文件</h1><p>配合<code>ls</code>和<code>wc</code>使用：</p>\n<pre><code class=\"lang-bash\">ls /path/to/source/folder | wc -l\n</code></pre>\n<h1 id=\"export-PYTHONPATH-quot-PWD-PYTHONPATH-quot\"><a href=\"#export-PYTHONPATH-quot-PWD-PYTHONPATH-quot\" class=\"headerlink\" title=\"export PYTHONPATH=&quot;$PWD:$PYTHONPATH&quot;\"></a><code>export PYTHONPATH=&quot;$PWD:$PYTHONPATH&quot;</code></h1><p>这是一个通过<code>PYTHONPATH</code>手动指定项目根目录的命令。</p>\n<p>以深度学习项目<code>Retinexformer</code>为例，这个项目文件夹内包含了训练的代码<code>train.py</code>，以及模型架构文件等。</p>\n<p>有时候直接在终端通过<code>python train.py</code>的绝对路径会报一些代码文件中的库引用错误，但是你反复检查了路径，觉得代码里导包的方式没问题。</p>\n<p>这时候你就可以先通过<code>cd</code>命令进入项目文件夹中，然后再执行这个<code>export</code>命令手动指定项目根目录：</p>\n<pre><code class=\"lang-bash\">&gt; cd Retinexformer\n&gt; export PYTHONPATH=&quot;$PWD:$PYTHONPATH&quot;\n</code></pre>\n<h1 id=\"当Linux内存不足时，扩大交换空间\"><a href=\"#当Linux内存不足时，扩大交换空间\" class=\"headerlink\" title=\"当Linux内存不足时，扩大交换空间\"></a>当<code>Linux</code>内存不足时，扩大交换空间</h1><p>首先要处理一下现有的交换文件：</p>\n<pre><code class=\"lang-bash\"># 查看当前启用的交换空间\nsudo swapon --show\n\n# 如果存在 /swapfile，先关闭交换文件\nsudo swapoff /swapfile\n\n# 删除旧的交换文件\nsudo rm /swapfile\n</code></pre>\n<p>然后创建一个更大内存的交换文件：</p>\n<pre><code class=\"lang-bash\"># 创建8GB交换文件\nsudo fallocate -l 8G /swapfile\nsudo chmod 600 /swapfile\nsudo mkswap /swapfile\nsudo swapon /swapfile\n</code></pre>\n",
            "tags": [
                "计算机"
            ]
        },
        {
            "id": "https://yunhdan.github.io/other/%E7%BE%BD%E6%AF%9B%E7%90%832/",
            "url": "https://yunhdan.github.io/other/%E7%BE%BD%E6%AF%9B%E7%90%832/",
            "title": "羽毛球2",
            "date_published": "2025-06-23T15:15:22.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"\\assets\\css\\APlayer.min.css\"><script src=\"\\assets\\js\\APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>:::info </p>\n<p>25年6月23日，今日单挑一名对手，明明感觉并不强，差不多，但是就是打不过。经过反思，在全方面的技术上要落后一筹，故决定今后系统地学习羽毛球。</p>\n<p>:::</p>\n<h1 id=\"正手龙卷风搓球\"><a href=\"#正手龙卷风搓球\" class=\"headerlink\" title=\"正手龙卷风搓球\"></a>正手龙卷风搓球</h1>\n<div style=\"position: relative; width: 100%; height: 0; padding-bottom: 75%;\">\n<iframe src=\"//player.bilibili.com/player.html?isOutside=true&aid=113409198789085&bvid=BV1Z9SZYdEBn&cid=26571309405&p=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\"\nstyle=\"position:absolute; height: 100%; width: 100%;\"></iframe>\n</div>\n\n<p>总结要点：</p>\n<ul>\n<li>跑到位，抢到高点。</li>\n<li>横着搓，搓球点在胸口。如果球低，就是压腿降低重心，搓球点保持在胸口，肩以上。</li>\n<li>龙卷风式搓球转的关键是，引完拍，球就差不多快接触到拍面，这样一刚要发力就会搓到，这样就会很转。</li>\n<li>龙卷风式搓球一般在身体正前面搓。</li>\n</ul>\n<h1 id=\"展搓\"><a href=\"#展搓\" class=\"headerlink\" title=\"展搓\"></a>展搓</h1>\n<div style=\"position: relative; width: 100%; height: 0; padding-bottom: 75%;\">\n<iframe src=\"//player.bilibili.com/player.html?isOutside=true&aid=1606338008&bvid=BV1Tm42137xB&cid=1623571024&p=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\"\nstyle=\"position:absolute; height: 100%; width: 100%;\"></iframe>\n</div>\n\n",
            "tags": [
                "琐碎"
            ]
        },
        {
            "id": "https://yunhdan.github.io/cs/Springboot%E3%80%81Mybatis/",
            "url": "https://yunhdan.github.io/cs/Springboot%E3%80%81Mybatis/",
            "title": "Springboot、Mybatis",
            "date_published": "2025-06-19T05:57:13.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"\\assets\\css\\APlayer.min.css\"><script src=\"\\assets\\js\\APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h1 id=\"Mybatis是怎么防止SQL注入的？\"><a href=\"#Mybatis是怎么防止SQL注入的？\" class=\"headerlink\" title=\"Mybatis是怎么防止SQL注入的？\"></a>Mybatis是怎么防止SQL注入的？</h1><ul>\n<li>这篇文章介绍了什么是SQL注入，以及Mybatis是怎么防止注入的，算是填补一下当时做项目不求甚解带来的漏洞：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzQ4MTIzNC9hcnRpY2xlL2RldGFpbHMvMTIwOTUwMDAz\">https://blog.csdn.net/weixin_43481234/article/details/120950003</span></li>\n</ul>\n",
            "tags": [
                "计算机"
            ]
        },
        {
            "id": "https://yunhdan.github.io/cs/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97/",
            "url": "https://yunhdan.github.io/cs/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97/",
            "title": "边缘计算",
            "date_published": "2025-06-18T13:10:03.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"\\assets\\css\\APlayer.min.css\"><script src=\"\\assets\\js\\APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h1 id=\"TFlite-GPU-Delegate\"><a href=\"#TFlite-GPU-Delegate\" class=\"headerlink\" title=\"TFlite GPU Delegate\"></a>TFlite GPU Delegate</h1><ul>\n<li>这篇算是比较通俗易懂地简要概览一下TFlite GPU Delegate的文章了：<span class=\"exturl\" data-url=\"aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8xNDM1NjEwNDA=\">https://zhuanlan.zhihu.com/p/143561040</span></li>\n</ul>\n",
            "tags": [
                "计算机"
            ]
        },
        {
            "id": "https://yunhdan.github.io/cs/Conda%E3%80%81Pip%E3%80%81Cuda/",
            "url": "https://yunhdan.github.io/cs/Conda%E3%80%81Pip%E3%80%81Cuda/",
            "title": "Conda、Pip、Cuda",
            "date_published": "2025-06-17T16:00:00.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"\\assets\\css\\APlayer.min.css\"><script src=\"\\assets\\js\\APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h1 id=\"安装mamba-ssm和causal-conv1d\"><a href=\"#安装mamba-ssm和causal-conv1d\" class=\"headerlink\" title=\"安装mamba_ssm和causal_conv1d\"></a>安装mamba_ssm和causal_conv1d</h1><ul>\n<li>Windows居然也支持mamba_ssim和causal_conv1d了：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1MTAwMjAwL2FydGljbGUvZGV0YWlscy8xMzk3NTQyMzE=\">https://blog.csdn.net/qq_45100200/article/details/139754231</span></li>\n</ul>\n<h1 id=\"cuda系列\"><a href=\"#cuda系列\" class=\"headerlink\" title=\"cuda系列\"></a>cuda系列</h1><ul>\n<li>简要介绍cudatoolkit和CUDA Toolkit的区别：<span class=\"exturl\" data-url=\"aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8yNzQzNDA5MTEzNQ==\">https://zhuanlan.zhihu.com/p/27434091135</span></li>\n<li>进一步详解CUDA和cudatoolkit，拓展至cudnn和nvcc：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMDk0MDU4L2FydGljbGUvZGV0YWlscy8xMTYyMDczMzM=\">https://blog.csdn.net/qq_41094058/article/details/116207333</span></li>\n</ul>\n",
            "tags": [
                "计算机"
            ]
        },
        {
            "id": "https://yunhdan.github.io/ai/%E7%8E%B0%E4%BB%A3%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/",
            "url": "https://yunhdan.github.io/ai/%E7%8E%B0%E4%BB%A3%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/",
            "title": "现代深度学习",
            "date_published": "2025-06-17T07:25:31.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"\\assets\\css\\APlayer.min.css\"><script src=\"\\assets\\js\\APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h1 id=\"知识蒸馏方法\"><a href=\"#知识蒸馏方法\" class=\"headerlink\" title=\"知识蒸馏方法\"></a>知识蒸馏方法</h1><ul>\n<li>一文了解知识蒸馏，通俗易懂：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzY5NDA5Ni9hcnRpY2xlL2RldGFpbHMvMTI3NTA1OTQ2\">https://blog.csdn.net/weixin_43694096/article/details/127505946</span></li>\n</ul>\n<h1 id=\"重参数化技术\"><a href=\"#重参数化技术\" class=\"headerlink\" title=\"重参数化技术\"></a>重参数化技术</h1><ul>\n<li>重参数化的2篇根基论文<code>RepVGG</code>和<code>RepMLP</code>：<span class=\"exturl\" data-url=\"aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8zNzA0Mzg5OTk=\">https://zhuanlan.zhihu.com/p/370438999</span></li>\n</ul>\n<h1 id=\"NTIRE图像恢复赛事\"><a href=\"#NTIRE图像恢复赛事\" class=\"headerlink\" title=\"NTIRE图像恢复赛事\"></a><code>NTIRE</code>图像恢复赛事</h1><ul>\n<li>23年超分辨率赛道技术报告解读，文末有赛事原报告：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzgwMDU3Ny9hcnRpY2xlL2RldGFpbHMvMTMxNjY4Nzgy\">https://blog.csdn.net/weixin_43800577/article/details/131668782</span></li>\n</ul>\n<h1 id=\"显存占用\"><a href=\"#显存占用\" class=\"headerlink\" title=\"显存占用\"></a>显存占用</h1><ul>\n<li>分析显存占用的内在机理：<span class=\"exturl\" data-url=\"aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC82NDE4OTQwMTQ=\">https://zhuanlan.zhihu.com/p/641894014</span></li>\n</ul>\n",
            "tags": [
                "人工智能"
            ]
        },
        {
            "id": "https://yunhdan.github.io/cs/Pytorch/",
            "url": "https://yunhdan.github.io/cs/Pytorch/",
            "title": "Pytorch",
            "date_published": "2025-06-13T05:14:06.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"\\assets\\css\\APlayer.min.css\"><script src=\"\\assets\\js\\APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h1 id=\"Pytorch算子\"><a href=\"#Pytorch算子\" class=\"headerlink\" title=\"Pytorch算子\"></a>Pytorch算子</h1><ul>\n<li>简要介绍算子：<span class=\"exturl\" data-url=\"aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC81NzQxNjY5MjA=\">https://zhuanlan.zhihu.com/p/574166920</span></li>\n</ul>\n<h1 id=\"矩阵乘法、矩阵点乘\"><a href=\"#矩阵乘法、矩阵点乘\" class=\"headerlink\" title=\"矩阵乘法、矩阵点乘\"></a>矩阵乘法、矩阵点乘</h1><ul>\n<li>这篇分别为矩阵乘法和矩阵点乘介绍了两种广义算子：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNzI4NjY3L2FydGljbGUvZGV0YWlscy8xMzQwMTM4OTk=\">https://blog.csdn.net/qq_40728667/article/details/134013899</span></li>\n</ul>\n<h1 id=\"关于num-worker\"><a href=\"#关于num-worker\" class=\"headerlink\" title=\"关于num_worker\"></a>关于num_worker</h1><ul>\n<li>简明扼要地介绍pytorch中dataloader的num_worker：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI4MDU3Mzc5L2FydGljbGUvZGV0YWlscy8xMTU0MjcwNTI=\">https://blog.csdn.net/qq_28057379/article/details/115427052</span></li>\n<li>一些关于num_worker的独特思考：<span class=\"exturl\" data-url=\"aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC82NDUzNjQwODk=\">https://zhuanlan.zhihu.com/p/645364089</span></li>\n</ul>\n",
            "tags": [
                "计算机"
            ]
        },
        {
            "id": "https://yunhdan.github.io/cs/Flask/",
            "url": "https://yunhdan.github.io/cs/Flask/",
            "title": "Flask",
            "date_published": "2025-06-13T05:10:41.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"\\assets\\css\\APlayer.min.css\"><script src=\"\\assets\\js\\APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h1 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h1><pre><code class=\"lang-bash\">pip install Flask\n</code></pre>\n<h1 id=\"Overview、铺垫资料\"><a href=\"#Overview、铺垫资料\" class=\"headerlink\" title=\"Overview、铺垫资料\"></a>Overview、铺垫资料</h1><p>参考资料：</p>\n<ul>\n<li><span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cucnVub29iLmNvbS9mbGFzay9mbGFzay10dXRvcmlhbC5odG1s\">Flask 教程 | 菜鸟教程</span></li>\n<li><span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cucnVub29iLmNvbS9mbGFzay9mbGFzay1iYXNpYy1jb25jZXB0Lmh0bWw=\">Flask 基本概念 | 菜鸟教程</span></li>\n<li><span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cucnVub29iLmNvbS9mbGFzay9mbGFzay1sYXlvdXQuaHRtbA==\">Flask 项目结构 | 菜鸟教程</span></li>\n</ul>\n<p>这部分主要是了解Flask的背景。同时了解路由、视图函数、请求对象和响应对象、模板文件、应用工厂、蓝图、配置对象、静态文件是什么。了解Flask的项目结构如何。</p>\n",
            "tags": [
                "计算机"
            ]
        },
        {
            "id": "https://yunhdan.github.io/cs/Vue/",
            "url": "https://yunhdan.github.io/cs/Vue/",
            "title": "Vue",
            "date_published": "2025-06-13T05:07:55.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"\\assets\\css\\APlayer.min.css\"><script src=\"\\assets\\js\\APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h1 id=\"循环语句\"><a href=\"#循环语句\" class=\"headerlink\" title=\"循环语句\"></a>循环语句</h1><p>参考资料：</p>\n<ul>\n<li><span class=\"exturl\" data-url=\"aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hTTF9IUi9hcnRpY2xlL2RldGFpbHMvMTI3MzEyNjMyP29wc19yZXF1ZXN0X21pc2M9JTdCJTIycmVxdWVzdCU1RmlkJTIyJTNBJTIyY2JhNzE1ZjNiNzcwOTk1MDVlNzRhOGNlMmUzYzE3MmMlMjIlMkMlMjJzY20lMjIlM0ElMjIyMDE0MDcxMy4xMzAxMDIzMzQuLiUyMiU3RCZhbXA7cmVxdWVzdF9pZD1jYmE3MTVmM2I3NzA5OTUwNWU3NGE4Y2UyZTNjMTcyYyZhbXA7Yml6X2lkPTAmYW1wO3V0bV9tZWRpdW09ZGlzdHJpYnV0ZS5wY19zZWFyY2hfcmVzdWx0Lm5vbmUtdGFzay1ibG9nLTJ+YWxsfnRvcF9wb3NpdGl2ZX5kZWZhdWx0LTEtMTI3MzEyNjMyLW51bGwtbnVsbC4xNDJedjEwMl5wY19zZWFyY2hfcmVzdWx0X2Jhc2UzJmFtcDt1dG1fdGVybT12LWZvciZhbXA7c3BtPTEwMTguMjIyNi4zMDAxLjQxODc=\">vue3【列表渲染】v-for 详细介绍（vue中的“循环”）_vue3 v-for-CSDN博客</span></li>\n<li><span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cucnVub29iLmNvbS92dWUzL3Z1ZTMtdi1mb3IuaHRtbA==\">Vue3 循环语句 | 菜鸟教程</span></li>\n</ul>\n<p>主要围绕如何使用v-for遍历数组、对象。v-for的几种基本用法要掌握。</p>\n<h1 id=\"安装Vue项目\"><a href=\"#安装Vue项目\" class=\"headerlink\" title=\"安装Vue项目\"></a>安装Vue项目</h1><p>参考资料：</p>\n<ul>\n<li><span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cucnVub29iLmNvbS92dWUzL3Z1ZTMtaW5zdGFsbC5odG1s\">Vue3 安装 | 菜鸟教程</span></li>\n<li><span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cucnVub29iLmNvbS92dWUzL3Z1ZTMtY3JlYXRlLXByb2plY3QuaHRtbA==\">Vue3 创建项目 | 菜鸟教程</span></li>\n</ul>\n<h1 id=\"Vue项目结构说明\"><a href=\"#Vue项目结构说明\" class=\"headerlink\" title=\"Vue项目结构说明\"></a>Vue项目结构说明</h1><p>参考资料：</p>\n<ul>\n<li><span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cucnVub29iLmNvbS92dWUzL3Z1ZTMtcHJvamVjdC1pbnRyby5odG1s\">Vue3 项目说明 | 菜鸟教程</span></li>\n</ul>\n",
            "tags": [
                "计算机"
            ]
        },
        {
            "id": "https://yunhdan.github.io/research/%E5%A4%9A%E6%A8%A1%E6%80%81%E8%AE%BA%E6%96%87%E7%B2%BE%E7%82%BC/",
            "url": "https://yunhdan.github.io/research/%E5%A4%9A%E6%A8%A1%E6%80%81%E8%AE%BA%E6%96%87%E7%B2%BE%E7%82%BC/",
            "title": "多模态论文精炼",
            "date_published": "2025-06-04T03:04:06.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"\\assets\\css\\APlayer.min.css\"><script src=\"\\assets\\js\\APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h1 id=\"CLIP工作\"><a href=\"#CLIP工作\" class=\"headerlink\" title=\"CLIP工作\"></a><code>CLIP</code>工作</h1><h2 id=\"2021-Learning-Transferable-Visual-Models-From-Natural-Language-Supervision-CLIP\"><a href=\"#2021-Learning-Transferable-Visual-Models-From-Natural-Language-Supervision-CLIP\" class=\"headerlink\" title=\"2021 Learning Transferable Visual Models From Natural Language Supervision(CLIP)\"></a><code>2021 Learning Transferable Visual Models From Natural Language Supervision(CLIP)</code></h2><p><img data-src=\"../../assets/clip.png\" alt=\"image\"></p>\n<blockquote>\n<p>学习自朱毅老师的<code>CLIP</code>逐段精读。</p>\n</blockquote>\n<p><strong>贡献</strong>：</p>\n<ul>\n<li>（1）通过文本和图像的对比学习，模型学习到文本-图像对的匹配关系。</li>\n<li>（2）能够实现通过给定一张图像，在多个文本标签中选择出与图像最相关的文本。也可以实现给定一个文本，选择最符合相关的图像。</li>\n</ul>\n<p><strong>创新</strong>：</p>\n<ul>\n<li>实现文本与图像的多模态学习。</li>\n<li>实现实现无标签限制的图像分类，也可以实现无图像限制的文本-图像配对。前者可以用于图像中的物体识别，后者可以用于文本检索图像。</li>\n</ul>\n<p><strong><code>CLIP</code>对比学习训练代码</strong>：</p>\n<pre><code class=\"lang-python\"># image_encoder - ResNet 或者 Vision Transformer\n# text_encoder - CBOW 或者 Text Transformer\n# I[n, h, w, c] - 图像形状\n# T[n, l] - 文本形状，l是序列长度\n# W_i[d_i, d_e] - 图像的线性投射矩阵\n# W_t[d_t, d_e] - 文本的线性投射矩阵\n# t - learned temperature parameter\n\n# 分别提取图像特征和文本特征\nI_f = image_encoder(I) #[n, d_i]\nT_f = text_encoder(T) #[n, d_t]\n\n# 对两个特征进行线性投射，得到相同维度的特征，并进行l2归一化\nI_e = l2_normalize(np.dot(I_f, W_i), axis=1)\nT_e = l2_normalize(np.dot(T_f, W_t), axis=1)\n\n# 计算缩放的余弦相似度：[n, n]\nlogits = np.dot(I_e, T_e.T) * np.exp(t)\n\n# 对称的对比学习损失：等价于N个类别的cross_entropy_loss\nlabels = np.arange(n) # 对角线元素的labels\nloss_i = cross_entropy_loss(logits, labels, axis=0)\nloss_t = cross_entropy_loss(logits, labels, axis=1)\nloss = (loss_i + loss_t)/2\n</code></pre>\n<h1 id=\"多模态在分割的应用\"><a href=\"#多模态在分割的应用\" class=\"headerlink\" title=\"多模态在分割的应用\"></a>多模态在分割的应用</h1><h2 id=\"2022-ICLR-Language-driven-semantic-segmentation-LSeg\"><a href=\"#2022-ICLR-Language-driven-semantic-segmentation-LSeg\" class=\"headerlink\" title=\"2022 ICLR Language-driven semantic segmentation(LSeg)\"></a><code>2022 ICLR Language-driven semantic segmentation(LSeg)</code></h2><p><img data-src=\"../../assets/lseg1.jpg\" alt=\"image\"></p>\n<blockquote>\n<p>学习自朱毅老师的逐段精读。</p>\n</blockquote>\n<p><strong>贡献</strong>：</p>\n<ul>\n<li>将<code>CLIP</code>的原始文本编码器作为需分割的物体标签的文本编码器，以充分提取文本特征。</li>\n<li>将文本特征与图像特征通过矩阵相乘融合得到多模态特征，上采样后与<code>Ground-truth</code>在像素级使用<code>cross entropy loss</code>进行训练。</li>\n<li>测试时可以实现，根据需要分割的对象的文本标签，分割特定图像的内容。</li>\n</ul>\n<p><strong>创新</strong>：</p>\n<ul>\n<li>一篇把<code>CLIP</code>模型运用到分割任务且有效果的工作。</li>\n<li>采用监督学习的方式训练，而不是对比学习去训练，也是为了更好地与特定分割任务适应。</li>\n</ul>\n<p><strong>不足</strong>：</p>\n<ul>\n<li>依然是有监督学习，目标函数不是对比学习的目标函数。</li>\n<li>文本特征只是用于融合多模态特征，并没有提供监督信号。</li>\n<li>依然依赖于手工标注<code>segmentation mask</code>。</li>\n</ul>\n<p>（可以做识别物体位置的实践）</p>\n<h2 id=\"2022-CVPR-GroupViT-Semantic-Segmentation-Emerges-from-Text-Supervision-GroupViT\"><a href=\"#2022-CVPR-GroupViT-Semantic-Segmentation-Emerges-from-Text-Supervision-GroupViT\" class=\"headerlink\" title=\"2022 CVPR GroupViT:Semantic Segmentation Emerges from Text Supervision(GroupViT)\"></a><code>2022 CVPR GroupViT:Semantic Segmentation Emerges from Text Supervision(GroupViT)</code></h2><p><img data-src=\"../../assets/groupvit1.jpg\" alt=\"image\"></p>\n<blockquote>\n<p>学习自朱毅老师的逐段精读。</p>\n<p>这篇是分割采用无监督学习的思路。主要使用的是分割中的<code>Grouping</code>思想。展开来讲，<code>Grouping</code>将图像分割做为一种聚类任务，首先在图像确定聚类中心点，然后在模型训练的过程中，不断学习聚类中心周围像素点与聚类中心的相互关系，将与聚类中心相关的像素点并入该聚类中心的<code>Group</code>中。</p>\n</blockquote>\n<p><strong>贡献</strong>：</p>\n<ul>\n<li>使用了文本作为监督信号训练分割任务，不再依赖人工标注的图像<code>Ground-Truth</code>。</li>\n<li>使用<code>Vision Transformer</code>作为图像编码器。在每个<code>Transformer</code>层的输入<code>tokens</code>中加入若干个<code>group tokens</code>，这些<code>group tokens</code>实际上就是预先设想的聚类中心数，也就是猜测的图像有哪些物体类别。经过多个<code>Transformer Layer</code>，<code>Image tokens</code>和这几个<code>group tokens</code>之间的关系被自注意力不断建模与学习。与特定聚类中心接近的<code>image tokens</code>，其特征也越接近该<code>group token</code>的特征。</li>\n<li>多个<code>Transformer</code>层后跟一个<code>Grouping Block</code>层。<code>Grouping Block</code>的本质是一个交叉注意力机制，将<code>Image tokens</code>并入所属的<code>Group tokens</code>。每个<code>Grouping Block</code>都将总<code>tokens</code>数降低，因此也减小了计算成本。</li>\n<li>使用对比学习的方式进行训练，带监督信号的文本被编码后的特征与最后的图像<code>tokens</code>特征两者交叉熵损失。</li>\n</ul>\n<p><strong>创新</strong>：</p>\n<ul>\n<li>首先使用了文本标注分割的<code>Ground-Truth</code>，不再依赖繁琐的手工标注。</li>\n</ul>\n<p><strong>不足</strong>：</p>\n<ul>\n<li>只能分割特定数量的类别，无法分割任意数量的物体。测试时，必须指定分割物体的数目，最后得到模型输出的<code>tokens</code>与文本标签进行余弦相似度的计算，确定分割物体的文本标签。</li>\n<li>训练中没有侧重语义信息，仅训练出了较好的分割能力。</li>\n</ul>\n<p><img data-src=\"../../assets/groupvit2.jpg\" alt=\"image\"></p>\n<p>（测试时，模型输出了两个<code>token</code>，我们指定分割物体的文本标签有<code>table、dog...potted plant</code>，于是可以使用余弦相似度计算得到一个相似度矩阵。对每行取最大的值，对应的文本标签即为该<code>token</code>的类别）</p>\n<h1 id=\"多模态在检测的应用\"><a href=\"#多模态在检测的应用\" class=\"headerlink\" title=\"多模态在检测的应用\"></a>多模态在检测的应用</h1><h2 id=\"2022-CVPR-Grounded-Language-Image-Pre-training-Glip\"><a href=\"#2022-CVPR-Grounded-Language-Image-Pre-training-Glip\" class=\"headerlink\" title=\"2022 CVPR Grounded Language-Image Pre-training(Glip)\"></a><code>2022 CVPR Grounded Language-Image Pre-training(Glip)</code></h2><p><img data-src=\"../../assets/glip1.jpg\" alt=\"image\"></p>\n<blockquote>\n<p>学习自朱毅老师的逐段精读。</p>\n<p>与常规目标检测任务相关的一个任务是<code>Vision Grounding</code>。具体是根据提供的文本，在图片中找到文本中出现的物体的位置。</p>\n</blockquote>\n<p><strong>贡献</strong>：</p>\n<ul>\n<li>参考<code>CLIP</code>范式，将图像的<code>Bounding box</code>的<code>region</code>输入图像编码器，将提供的文本输入文本编码器，最后得到每个<code>Bounding box</code>与单词的相似度矩阵。在相似度矩阵上与<code>Ground-Truth</code>的相似度矩阵求定位损失<code>Localization Loss</code>和分类损失<code>Alignment Loss</code>即可完成训练。</li>\n<li>为了更加充分地学习<code>Bounding box</code>和文本的<code>Joint Feature</code>，也就是多模态特征。在最后的特征相似度计算前，使用交叉注意力对图像特征和文本特征进行多层交互学习，即<code>Deep Fusion</code>。</li>\n</ul>\n<p><strong>创新</strong>：</p>\n<ul>\n<li>使用<code>Deep Fusion</code>技术以辅助学习多模态特征。</li>\n<li>将<code>Gounding</code>任务与目标检测任务很好地结合，并借鉴<code>CLIP</code>的思想做大规模数据的预训练，成功取得了很好的<code>Zero-shot</code>效果。</li>\n</ul>\n",
            "tags": [
                "学术"
            ]
        },
        {
            "id": "https://yunhdan.github.io/baoyan/Low-level-Vision-Group/",
            "url": "https://yunhdan.github.io/baoyan/Low-level-Vision-Group/",
            "title": "Low-level-Vision-Group",
            "date_published": "2025-06-03T03:08:17.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"\\assets\\css\\APlayer.min.css\"><script src=\"\\assets\\js\\APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>:::info </p>\n<p>做底层视觉的团队，供保研用。</p>\n<p>:::</p>\n<p>+++danger 注意</p>\n<p>请做好心理准备，这些导师都很强，申请做他们的学生，在面试考核中一定是会被拷打的。对方的学术水平，能力水平本身就在你之上，你的任何漏洞、问题、毛病都会被看得一清二楚。所以想要做到让对方完全满意是不太可能的，要做好这个心理建设。</p>\n<p>+++</p>\n<h1 id=\"中山大学-网络空间安全学院\"><a href=\"#中山大学-网络空间安全学院\" class=\"headerlink\" title=\"中山大学-网络空间安全学院\"></a>中山大学-网络空间安全学院</h1><ul>\n<li>任文琦：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9zaXRlcy5nb29nbGUuY29tL3ZpZXcvd2VucWlyZW4vaG9tZXBhZ2U=\">https://sites.google.com/view/wenqiren/homepage</span></li>\n</ul>\n<p>这个老师特别强，我发过email2次都是已阅没回，没看上我。</p>\n<h1 id=\"厦门大学-信息学院\"><a href=\"#厦门大学-信息学院\" class=\"headerlink\" title=\"厦门大学-信息学院\"></a>厦门大学-信息学院</h1><ul>\n<li>丁兴号：<span class=\"exturl\" data-url=\"aHR0cHM6Ly94bXUtc21hcnRkc3AuZ2l0aHViLmlvLw==\">https://xmu-smartdsp.github.io/</span></li>\n</ul>\n<p>没有联系过，没有实验室主页，情况未知。</p>\n<h1 id=\"南开大学-密码与网络空间安全学院\"><a href=\"#南开大学-密码与网络空间安全学院\" class=\"headerlink\" title=\"南开大学-密码与网络空间安全学院\"></a>南开大学-密码与网络空间安全学院</h1><ul>\n<li>程明明实验室李重仪，郭春乐：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9tbWNoZW5nLm5ldC9yZWNydWl0L2NvbW1lbnQtcGFnZS0yNS8=\">https://mmcheng.net/recruit/comment-page-25/</span></li>\n</ul>\n<p>底层视觉顶级组，考核贼强，六级要480+。考核差不多相当于用c++复现一篇传统论文，感觉非常困难故未考虑。</p>\n<h1 id=\"东南大学-计算机科学与工程学院\"><a href=\"#东南大学-计算机科学与工程学院\" class=\"headerlink\" title=\"东南大学-计算机科学与工程学院\"></a>东南大学-计算机科学与工程学院</h1><ul>\n<li>薛晖：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9wYWxtLnNldS5lZHUuY24vaHh1ZS8=\">https://palm.seu.edu.cn/hxue/</span></li>\n</ul>\n<p>这个是有名的palm实验室，不放实习，不建议去。</p>\n<h1 id=\"中山大学-计算机学院\"><a href=\"#中山大学-计算机学院\" class=\"headerlink\" title=\"中山大学-计算机学院\"></a>中山大学-计算机学院</h1><ul>\n<li>李冠彬：<span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cuc3lzdS1oY3AubmV0L2ZhY3VsdHkvbGlndWFuYmluLmh0bWw=\">https://www.sysu-hcp.net/faculty/liguanbin.html</span></li>\n<li>张冬雨：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9jc2Uuc3lzdS5lZHUuY24vdGVhY2hlci9aaGFuZ0Rvbmd5dQ==\">https://cse.sysu.edu.cn/teacher/ZhangDongyu</span></li>\n</ul>\n<p>联系过李老师2次，但是都没有看上我，没回信。</p>\n<h1 id=\"南京理工大学-计算机科学与工程学院\"><a href=\"#南京理工大学-计算机科学与工程学院\" class=\"headerlink\" title=\"南京理工大学-计算机科学与工程学院\"></a>南京理工大学-计算机科学与工程学院</h1><ul>\n<li>潘金山：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9qc3Bhbi5naXRodWIuaW8v\">https://jspan.github.io/</span></li>\n</ul>\n<p>这个老师做low level特别强。</p>\n<h1 id=\"北京大学-信息工程学院（深圳）\"><a href=\"#北京大学-信息工程学院（深圳）\" class=\"headerlink\" title=\"北京大学-信息工程学院（深圳）\"></a>北京大学-信息工程学院（深圳）</h1><ul>\n<li>张健：<span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cuZWNlLnBrdS5lZHUuY24vaW5mby8xMDQ2LzI1MDYuaHRt\">https://www.ece.pku.edu.cn/info/1046/2506.htm</span></li>\n</ul>\n<p>老师很强，听说对学生也很温和友好。我联系过2次，均未搭理，没回信。看了一下他实验室的学生的来向，基本全是9和2，双非和四非根本不可能。</p>\n<h1 id=\"哈尔滨工业大学-计算机学院\"><a href=\"#哈尔滨工业大学-计算机学院\" class=\"headerlink\" title=\"哈尔滨工业大学-计算机学院\"></a>哈尔滨工业大学-计算机学院</h1><ul>\n<li>左旺孟：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9ob21lcGFnZS5oaXQuZWR1LmNuL3dhbmdtZW5nenVv\">https://homepage.hit.edu.cn/wangmengzuo</span></li>\n</ul>\n<p>这个老师懂得都懂，low level泰斗。听说对学生也相当好，人品也不错。但因为在本部太远，未考虑。</p>\n<h1 id=\"南京大学-智能科学与技术学院（苏州）\"><a href=\"#南京大学-智能科学与技术学院（苏州）\" class=\"headerlink\" title=\"南京大学-智能科学与技术学院（苏州）\"></a>南京大学-智能科学与技术学院（苏州）</h1><ul>\n<li>张凯：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9jc3puLmdpdGh1Yi5pby8=\">https://cszn.github.io/</span></li>\n<li>邰颖：<span class=\"exturl\" data-url=\"aHR0cHM6Ly90eXNoaXdvLmdpdGh1Yi5pby9pbmRleC5odG1s\">https://tyshiwo.github.io/index.html</span></li>\n</ul>\n<p>联系过张凯老师，张凯老师人很好。第一次信没有回复，第二次在follow信发过去后很快就回信了，这个是第一个回信的老师，表示欢迎我来。虽然有点类似官回，但给我很大的鼓励。</p>\n<h1 id=\"北京师范大学-人工智能学院\"><a href=\"#北京师范大学-人工智能学院\" class=\"headerlink\" title=\"北京师范大学-人工智能学院\"></a>北京师范大学-人工智能学院</h1><ul>\n<li>黄华：<span class=\"exturl\" data-url=\"aHR0cHM6Ly92bWNsLmJudS5lZHUuY24vZ3JvdXAvdGVhY2hlci9kY2RhZWE3OWI1ZTU0Yjc1YjUzMjc5NTEwOWE4NWEzNC5odG0=\">https://vmcl.bnu.edu.cn/group/teacher/dcdaea79b5e54b75b532795109a85a34.htm</span></li>\n</ul>\n<p>有点偏low level中的底层，与相机有关，感觉干不来。</p>\n<h1 id=\"南京大学-计算机学院\"><a href=\"#南京大学-计算机学院\" class=\"headerlink\" title=\"南京大学-计算机学院\"></a>南京大学-计算机学院</h1><ul>\n<li>路通：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9jcy5uanUuZWR1LmNuL2x1dG9uZy9pbmRleC5odG0=\">https://cs.nju.edu.cn/lutong/index.htm</span></li>\n</ul>\n<p>联系过但没有回复。</p>\n<h1 id=\"大连理工大学-国际信息科学与工程学院\"><a href=\"#大连理工大学-国际信息科学与工程学院\" class=\"headerlink\" title=\"大连理工大学-国际信息科学与工程学院\"></a>大连理工大学-国际信息科学与工程学院</h1><ul>\n<li>刘日升：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9yc2xpdS50ZWNoLw==\">https://rsliu.tech/</span></li>\n</ul>\n<p>这个老师同时也做机器人，很强。因为位置偏远，没有考虑。</p>\n<h1 id=\"四川大学-计算机学院\"><a href=\"#四川大学-计算机学院\" class=\"headerlink\" title=\"四川大学-计算机学院\"></a>四川大学-计算机学院</h1><ul>\n<li>彭玺：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9wZW5neGkubWUv\">https://pengxi.me/</span></li>\n</ul>\n<h1 id=\"电子科技大学-计算机科学与工程学院\"><a href=\"#电子科技大学-计算机科学与工程学院\" class=\"headerlink\" title=\"电子科技大学-计算机科学与工程学院\"></a>电子科技大学-计算机科学与工程学院</h1><ul>\n<li>顾舒航：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9zaHVoYW5nZ3UuZ2l0aHViLmlvLw==\">https://shuhanggu.github.io/</span></li>\n</ul>\n<h1 id=\"天津大学-智能与计算学部\"><a href=\"#天津大学-智能与计算学部\" class=\"headerlink\" title=\"天津大学-智能与计算学部\"></a>天津大学-智能与计算学部</h1><ul>\n<li>郭晓杰：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9zaXRlcy5nb29nbGUuY29tL3ZpZXcveGpndW8=\">https://sites.google.com/view/xjguo</span></li>\n</ul>\n<p>很强，LIME论文的团队。听说对学生也很好，联系过一次，没有回信，再次未被看上。</p>\n<h1 id=\"电子科技大学-信息与通信工程学院\"><a href=\"#电子科技大学-信息与通信工程学院\" class=\"headerlink\" title=\"电子科技大学-信息与通信工程学院\"></a>电子科技大学-信息与通信工程学院</h1><ul>\n<li>刘帅成：<span class=\"exturl\" data-url=\"aHR0cDovL3d3dy5saXVzaHVhaWNoZW5nLm9yZy8=\">http://www.liushuaicheng.org/</span></li>\n</ul>\n<p>很强，GLARE论文的团队，依然是联系过后未被看上，没有回信。</p>\n<h1 id=\"中国科学技术大学\"><a href=\"#中国科学技术大学\" class=\"headerlink\" title=\"中国科学技术大学\"></a>中国科学技术大学</h1><ul>\n<li>李厚强：<span class=\"exturl\" data-url=\"aHR0cDovL3N0YWZmLnVzdGMuZWR1LmNuL35saWhxL2VuLw==\">http://staff.ustc.edu.cn/~lihq/en/</span></li>\n<li>熊志伟：<span class=\"exturl\" data-url=\"aHR0cDovL3N0YWZmLnVzdGMuZWR1LmNuL356d3hpb25nLw==\">http://staff.ustc.edu.cn/~zwxiong/</span></li>\n<li>刘东：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9mYWN1bHR5LnVzdGMuZWR1LmNuL2RvbmdlbGl1Lw==\">https://faculty.ustc.edu.cn/dongeliu/</span></li>\n<li>陈志波：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9mYWN1bHR5LnVzdGMuZWR1LmNuL2NoZW56aGliby8=\">https://faculty.ustc.edu.cn/chenzhibo/</span></li>\n</ul>\n<h1 id=\"武汉大学\"><a href=\"#武汉大学\" class=\"headerlink\" title=\"武汉大学\"></a>武汉大学</h1><ul>\n<li>马佳义：<span class=\"exturl\" data-url=\"aHR0cDovL212cC53aHUuZWR1LmNuL2ppYXlpbWEv\">http://mvp.whu.edu.cn/jiayima/</span></li>\n</ul>\n<h1 id=\"西安电子科技大学\"><a href=\"#西安电子科技大学\" class=\"headerlink\" title=\"西安电子科技大学\"></a>西安电子科技大学</h1><ul>\n<li>董伟生：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9zZWUueGlkaWFuLmVkdS5jbi9mYWN1bHR5L3dzZG9uZy8=\">https://see.xidian.edu.cn/faculty/wsdong/</span></li>\n</ul>\n<p>联系过董老师2次，但都是没有打开看我的信。</p>\n<h1 id=\"西安交通大学\"><a href=\"#西安交通大学\" class=\"headerlink\" title=\"西安交通大学\"></a>西安交通大学</h1><ul>\n<li>孟德宇：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9nci54anR1LmVkdS5jbi93ZWIvZHltZW5n\">https://gr.xjtu.edu.cn/web/dymeng</span></li>\n</ul>\n<p>西交夏令营要本科学校计算机a评估。</p>\n<h1 id=\"华东师范大学\"><a href=\"#华东师范大学\" class=\"headerlink\" title=\"华东师范大学\"></a>华东师范大学</h1><ul>\n<li>谢源：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9mYWN1bHR5LmVjbnUuZWR1LmNuL19zMTYveHkyXzExMzQyL21haW4ucHNw\">https://faculty.ecnu.edu.cn/_s16/xy2_11342/main.psp</span></li>\n</ul>\n<p>风评未知，也没有团队主页，暂不考虑。</p>\n<h1 id=\"中科院深先所\"><a href=\"#中科院深先所\" class=\"headerlink\" title=\"中科院深先所\"></a>中科院深先所</h1><ul>\n<li>MMLab：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9tbWxhYi5zaWF0LmFjLmNuLw==\">https://mmlab.siat.ac.cn/</span></li>\n<li>董超：<span class=\"exturl\" data-url=\"aHR0cDovL3hwaXhlbC5ncm91cC8=\">http://xpixel.group/</span></li>\n</ul>\n<p>联系过董超老师2次，依然没有打开信看。</p>\n<h1 id=\"同济大学-计算机科学与技术学院（软件学院）\"><a href=\"#同济大学-计算机科学与技术学院（软件学院）\" class=\"headerlink\" title=\"同济大学-计算机科学与技术学院（软件学院）\"></a>同济大学-计算机科学与技术学院（软件学院）</h1><ul>\n<li>张林：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9zc2UudG9uZ2ppLmVkdS5jbi9pbmZvLzEyMTIvNTA1Mi5odG0=\">https://sse.tongji.edu.cn/info/1212/5052.htm</span></li>\n</ul>\n<p>同济大学bar过高。</p>\n<h1 id=\"北京邮电大学-计算机学院\"><a href=\"#北京邮电大学-计算机学院\" class=\"headerlink\" title=\"北京邮电大学-计算机学院\"></a>北京邮电大学-计算机学院</h1><ul>\n<li>明安龙：<span class=\"exturl\" data-url=\"aHR0cHM6Ly90ZWFjaGVyLmJ1cHQuZWR1LmNuL21hbA==\">https://teacher.bupt.edu.cn/mal</span></li>\n</ul>\n<p>联系过明老师，明老师做计算摄影、美学评估方向为主，方向有点不太match。</p>\n<h1 id=\"北京邮电大学-人智学院\"><a href=\"#北京邮电大学-人智学院\" class=\"headerlink\" title=\"北京邮电大学-人智学院\"></a>北京邮电大学-人智学院</h1><ul>\n<li>鲁鹏：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9jdi14dWViYS5jbHViL3BhZ2VzL21lbWJlcnMvcGx1Lmh0bWw=\">https://cv-xueba.club/pages/members/plu.html</span></li>\n</ul>\n",
            "tags": [
                "保研"
            ]
        },
        {
            "id": "https://yunhdan.github.io/project/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%B0%8F%E5%AE%9E%E8%B7%B5%E2%80%94%E2%80%94%E6%9E%84%E5%BB%BAEnv%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%96%B9%E6%B3%95/",
            "url": "https://yunhdan.github.io/project/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%B0%8F%E5%AE%9E%E8%B7%B5%E2%80%94%E2%80%94%E6%9E%84%E5%BB%BAEnv%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%96%B9%E6%B3%95/",
            "title": "强化学习小实践——构建Env的基本方法",
            "date_published": "2025-05-22T10:50:06.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"\\assets\\css\\APlayer.min.css\"><script src=\"\\assets\\js\\APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>:::info</p>\n<p>这个小实践以一个示例说明构建Env的基本方法。同样能够涉及到Gymnasium的基本用法。</p>\n<p>:::</p>\n<h1 id=\"环境准备-rainbow\"><a href=\"#环境准备-rainbow\" class=\"headerlink\" title=\"[环境准备]{.rainbow}\"></a>[环境准备]{.rainbow}</h1><p>:::warning</p>\n<p>最好新建一个虚拟环境，在这个环境下进行环境配置。</p>\n<p>:::</p>\n<p>首先，需要在终端执行如下命令安装这个示例需要的包：</p>\n<pre><code class=\"lang-shell\">pip install copier\ncopier copy https://github.com/Farama-Foundation/gymnasium-env-template.git &quot;path/to/directory&quot;\n</code></pre>\n<p>其中，”path/to/directory”更改为你自定义的放项目的文件夹位置。执行完毕后，项目文件夹下会出现如下内容：</p>\n<pre><code class=\"lang-raw\">.\n├── gymnasium_env\n│   ├── envs\n│   │   ├── grid_world.py\n│   │   └── __init__.py\n│   ├── __init__.py\n│   └── wrappers\n│       ├── clip_reward.py\n│       ├── discrete_actions.py\n│       ├── __init__.py\n│       ├── reacher_weighted_reward.py\n│       └── relative_position.py\n├── LICENSE\n├── pyproject.toml\n└── README.md\n</code></pre>\n<p>然后确保你的电脑安装了Microsoft Visual C++ Build Tools。<br>安装方法：</p>\n<ul>\n<li>在浏览器打开<span class=\"exturl\" data-url=\"aHR0cHM6Ly92aXN1YWxzdHVkaW8ubWljcm9zb2Z0LmNvbS96aC1oYW5zL3Zpc3VhbC1jcHAtYnVpbGQtdG9vbHMv\">https://visualstudio.microsoft.com/zh-hans/visual-cpp-build-tools/</span></li>\n<li>点击“下载生成工具”，接着会下载vs_BuildTools.exe。</li>\n<li>下载完毕后执行vs_BuildTools.exe，在工作负载勾选第一个。</li>\n<li>在右侧勾选以下组件：MSVC v143 - VS 2022 C++ x64/x86 build tools、Windows 11 SDK。</li>\n<li>点击安装即可。</li>\n</ul>\n<p>最后，在终端执行：</p>\n<pre><code class=\"lang-shell\">cd &quot;path/to/directory&quot;\npip install swig\npip install &quot;gymnasium[box2d]&quot;\ncd gymnasium_env\npip install -e .\n</code></pre>\n<p>自此相关环境已经配置完毕。</p>\n<h1 id=\"创建环境实例-rainbow\"><a href=\"#创建环境实例-rainbow\" class=\"headerlink\" title=\"[创建环境实例]{.rainbow}\"></a>[创建环境实例]{.rainbow}</h1><p>在与gymnasim_env同级下，编写run.py文件：</p>\n<pre><code class=\"lang-python\">import gymnasium \nimport gymnasium_env\n\nenv = gymnasium.make(&#39;gymnasium_env/GridWorld-v0&#39;, render_mode=&#39;human&#39;)\nenv.reset()\n\nepisode_over = False\nwhile not episode_over:\n    action = env.action_space.sample()\n    observation, reward, terminated, truncated, info = env.step(action)\n\n    episode_over = terminated or truncated\n\nenv.close()\n</code></pre>\n<p>点击运行，就可以看到一个网格，Agent是蓝色的圆圈，Agent想要到达红色方块处，这就是Agent运行的环境Env。这个Agent因为是一个未训练的模型，所以并不能高效地完成这个任务，它经过了一段时间才“随机”地到达了红色方块处。本实践主要是展示如何构建一个环境实例。</p>\n<p><img data-src=\"../../assets/rl_env1.png\" alt=\"image\"></p>\n<h1 id=\"相关说明-rainbow\"><a href=\"#相关说明-rainbow\" class=\"headerlink\" title=\"[相关说明]{.rainbow}\"></a>[相关说明]{.rainbow}</h1><p>下面说明一些重要的方法以帮助进一步理解环境创建的过程。</p>\n<pre><code class=\"lang-python\">env = gymnasium.make(&#39;gymnasium_env/GridWorld-v0&#39;, render_mode=&#39;human&#39;)\n</code></pre>\n<p>这个语句，根据’gymnasium_env/GridWorld-v0’路径下自定义的环境类创建一个环境，render_mode是可视化的模式，‘human’表示用人性化的方式展现出来。</p>\n<p>很明显，你发现并没有这个路径’gymnasium_env/GridWorld-v0’，我们打开gymnasium_env文件夹下的__init__.py，可以看到如下代码：</p>\n<pre><code class=\"lang-python\">from gymnasium.envs.registration import register\n\nregister(\n    id=&quot;gymnasium_env/GridWorld-v0&quot;,\n    entry_point=&quot;gymnasium_env.envs:GridWorldEnv&quot;,\n)\n</code></pre>\n<p>因为是自定义的环境类，而非gymnasium库内置的环境类，所以通常需要用register类进行环境注册。entry_point指定了类的位置，id根据其创建一个路径。但如此做还不够，因为gymnasium不一定能够通过”gymnasium_env.envs:GridWorldEnv”找到自定义的GridWorldEnv。</p>\n<p>因为这条语句的意思是，向gymnasium_env.envs文件夹寻找GridWorldEnv这个类，但envs文件夹自己能不能知道自己有GridWorldEnv这个类？我们还要再做一步，在envs文件夹内的__init__.py文件导入GridWorldEnv，正如代码所示的那样：</p>\n<pre><code class=\"lang-python\">from gymnasium_env.envs.grid_world import GridWorldEnv\n</code></pre>\n<p>这样，”gymnasium_env.envs:GridWorldEnv”就能生效了，GridWorldEnv便可以被注册为”gymnasium_env/GridWorld-v0”这个路径。</p>\n<pre><code class=\"lang-python\">env.reset()\n</code></pre>\n<p>环境类通常有内置方法reset()，这个方法用于初始化环境。当环境类被实例化后，使用该方法生成第一个观察状态。</p>\n<pre><code class=\"lang-python\">action = env.action_space.sample()\n</code></pre>\n<p>当前实践的Agent的代码没有定义，所以暂时用环境类内置的action_space方法去生成Agent的动作。一般情况下，Agent的action是Agent观察环境后得出的，是Agent的方法。</p>\n<pre><code class=\"lang-python\">observation, reward, terminated, truncated, info = env.step(action)\n</code></pre>\n<p>环境类需要有step方法，根据Agent的action去生成激励reward，更新旧观察状态为新观察状态observation。terminated是检查是否已经结束游戏，truncated检查是否应该中途停止游戏，info是游戏有关的信息。</p>\n<pre><code class=\"lang-python\">env.close()\n</code></pre>\n<p>没什么说的，关闭环境，释放资源。</p>\n",
            "tags": [
                "项目与实践"
            ]
        },
        {
            "id": "https://yunhdan.github.io/baoyan/%E4%BF%9D%E7%A0%94%E5%8E%86%E7%A8%8B/",
            "url": "https://yunhdan.github.io/baoyan/%E4%BF%9D%E7%A0%94%E5%8E%86%E7%A8%8B/",
            "title": "保研历程",
            "date_published": "2025-05-16T13:31:49.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"\\assets\\css\\APlayer.min.css\"><script src=\"\\assets\\js\\APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h1 id=\"个人基本情况-rainbow\"><a href=\"#个人基本情况-rainbow\" class=\"headerlink\" title=\"[个人基本情况]{.rainbow}\"></a>[个人基本情况]{.rainbow}</h1><ul>\n<li>本科：江西四非，计算机科学与技术，2022级。</li>\n<li>排名：173人，前5%。</li>\n<li>竞赛：若干国奖，若干省奖。</li>\n<li>科研经历：2段，low-level vision相关，一篇会议在投，一篇竞赛产出的CVPR Workshop。</li>\n<li>英语：四级558，六级擦边428。无雅思。</li>\n</ul>\n<h1 id=\"定位与计划-rainbow\"><a href=\"#定位与计划-rainbow\" class=\"headerlink\" title=\"[定位与计划]{.rainbow}\"></a>[定位与计划]{.rainbow}</h1><ul>\n<li>院校倾向：在方向相关的基础上。华五优先，9优先。有一定的地域考虑，深圳优先。就业前景好优先。</li>\n<li>方向选择：做AI，low-level vision方向，可3d，可多模态。</li>\n<li>导师选择：人好肯带我最重要，个人倾向于年轻的导师，我感觉我不是那种给我资源自己找出路就能很好的人，还是希望有年轻的导师多带带我。导师人好，读研生活愉快些很重要！</li>\n<li>其他的一些考虑：title强一些更好、学硕最佳、暂时没有直博想法。</li>\n</ul>\n<h1 id=\"夏令营经历-rainbow\"><a href=\"#夏令营经历-rainbow\" class=\"headerlink\" title=\"[夏令营经历]{.rainbow}\"></a>[夏令营经历]{.rainbow}</h1><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>院校</th>\n<th>入营情况</th>\n<th style=\"text-align:left\">备注</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>南大计院</td>\n<td>寄</td>\n<td style=\"text-align:left\">自然是报着乐</td>\n</tr>\n<tr>\n<td>中大网安</td>\n<td>寄</td>\n<td style=\"text-align:left\">刚报完名一两天，夏令营就取消了</td>\n</tr>\n<tr>\n<td>北大信工</td>\n<td>寄</td>\n<td style=\"text-align:left\">bar挺高的</td>\n</tr>\n<tr>\n<td>上科大信院<code>VDI</code></td>\n<td>寄</td>\n<td style=\"text-align:left\">信院VDI很强，但需要联系到导师，门槛较高。自然，导师没回我信</td>\n</tr>\n<tr>\n<td>中科院深先院</td>\n<td>寄</td>\n<td style=\"text-align:left\">其实是弱com，联系导师没回复，自然寄</td>\n</tr>\n<tr>\n<td>南京航空航天计软</td>\n<td>寄</td>\n<td style=\"text-align:left\">今年夏令营bar很高，卡211，双非<code>rk1</code>也进不去</td>\n</tr>\n<tr>\n<td>深大计软</td>\n<td>寄</td>\n<td style=\"text-align:left\">很奇怪很奇怪，我的bg居然没入四非的营</td>\n</tr>\n<tr>\n<td>中科大</td>\n<td>寄</td>\n<td style=\"text-align:left\">不收双非四非今年居然要申请表上有意向导师签字，第一次见到这种</td>\n</tr>\n<tr>\n<td>北京师大人智</td>\n<td>寄</td>\n<td style=\"text-align:left\">今年居然要申请表上有意向导师签字，第一次见到这种</td>\n</tr>\n<tr>\n<td>南大智科</td>\n<td>已报</td>\n<td style=\"text-align:left\">老师要我，但学校一般不收双非四非</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>虽然不太敢相信，但还是不得不接受可能夏0营的事实。</p>\n<h1 id=\"预推免\"><a href=\"#预推免\" class=\"headerlink\" title=\"预推免\"></a>预推免</h1><p>已考虑：中大≈南大智科&gt;中科大≈人大&gt;电子科大≈南科大≈北邮≈中科院深先院&gt;华东师大&gt;北师大&gt;深大&gt;上科大信院&gt;南航</p>\n<h1 id=\"最后总结\"><a href=\"#最后总结\" class=\"headerlink\" title=\"最后总结\"></a>最后总结</h1><ul>\n<li>保研是导师和学生之间的双选过程，学生没必要抱着舔的心态去申请。牛导不会因为你的跪舔文案而看上你，对方看不上你，你也没办法，你只能选择水平相较之更低的导。你选择被你over qualified的导，即使你因为有更好的去处拒绝了这个导，只要你尽早告知，也没必要为自己的行为愧疚。毕竟还是那句话，双方是互选的过程，这个导也没有理由生你的气，你是出于升学考虑才同时联系多个导师。</li>\n<li>还是那句话，只要你积极不轻言放弃，该要你的一定会要你，不想要你的一定不会要，尽人事听天命。</li>\n</ul>\n",
            "tags": [
                "保研"
            ]
        },
        {
            "id": "https://yunhdan.github.io/ai/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/",
            "url": "https://yunhdan.github.io/ai/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/",
            "title": "深度学习理论",
            "date_published": "2025-05-09T15:49:32.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"\\assets\\css\\APlayer.min.css\"><script src=\"\\assets\\js\\APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>:::info</p>\n<p>复习深度学习必要的理论，可参考该复习线路。该文内容学自李沐动手学深度学习，更基础详尽的理论可以学习吴恩达深度学习。</p>\n<p>:::</p>\n<h1 id=\"线性神经网络-rainbow\"><a href=\"#线性神经网络-rainbow\" class=\"headerlink\" title=\"[线性神经网络]{.rainbow}\"></a>[线性神经网络]{.rainbow}</h1><h2 id=\"线性回归-dot\"><a href=\"#线性回归-dot\" class=\"headerlink\" title=\"++线性回归++{.dot}\"></a>++线性回归++{.dot}</h2><p>:::info Summary</p>\n<p>学习视频链接：<span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMVBYNHkxZzdLQy8/c3BtX2lkX2Zyb209MzMzLjEzODcuY29sbGVjdGlvbi52aWRlb19jYXJkLmNsaWNrJmFtcDt2ZF9zb3VyY2U9M2QxNDU2MGMyOGY5MGVmZGQxZjNlNmNhZjdiZjQyNzc=\">https://www.bilibili.com/video/BV1PX4y1g7KC/?spm_id_from=333.1387.collection.video_card.click&amp;vd_source=3d14560c28f90efdd1f3e6caf7bf4277</span></p>\n<p>:::</p>\n<ul>\n<li>线性回归是对n维输入的加权，外加偏差，通常用于预测，方程形式：<script type=\"math/tex; mode=display\">\ny = w_1x_1 + w_2x_2 + ... + b</script></li>\n<li><p>通常使用<code>MSE</code>损失去衡量预测的精确性，即预测值$\\hat{y}$和真实值y的均方差：</p>\n<script type=\"math/tex; mode=display\">\nL_{MSE} = \\frac{1}{2}||\\hat{y} - y||^2</script></li>\n<li><p>线性回归一般有显式解，显式解是损失导数为0的点。</p>\n</li>\n<li>线性回归可以看做是单层神经网络，$w_i$实际上是唯一的一层神经元的权重。</li>\n</ul>\n<p>pytorch实现线性回归很简单。线性回归可以被看成是一层神经网络，因此可以用全连接层实现：</p>\n<pre><code class=\"lang-python\">net = nn.Linear(2, 1)\n</code></pre>\n<p><code>Linear</code>第一个参数是输入数据形状的最后一个维度，比如输入数据features.shape是[4,2]，那么<code>Linear</code>第一个参数就是2。通常输入数据的最后一个维度是数据的特征，2代表输入数据有两个维度的特征，如买房数据有房价和占地面积两个维度的特征。第二个参数就是输出数据形状的最后一个维度。</p>\n<h2 id=\"基础优化算法概览-dot\"><a href=\"#基础优化算法概览-dot\" class=\"headerlink\" title=\"++基础优化算法概览++{.dot}\"></a>++基础优化算法概览++{.dot}</h2><p>:::info Summary</p>\n<p>学习视频链接：<span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMVBYNHkxZzdLQz9zcG1faWRfZnJvbT0zMzMuNzg4LnZpZGVvcG9kLmVwaXNvZGVzJmFtcDt2ZF9zb3VyY2U9M2QxNDU2MGMyOGY5MGVmZGQxZjNlNmNhZjdiZjQyNzcmYW1wO3A9Mg==\">https://www.bilibili.com/video/BV1PX4y1g7KC?spm_id_from=333.788.videopod.episodes&amp;vd_source=3d14560c28f90efdd1f3e6caf7bf4277&amp;p=2</span></p>\n<p>:::</p>\n<h3 id=\"梯度下降\"><a href=\"#梯度下降\" class=\"headerlink\" title=\"梯度下降\"></a>梯度下降</h3><p>基本思想是，对一组初始化的参数，反复迭代训练，按照下面的公式进行参数更新，使得最小化损失函数：</p>\n<script type=\"math/tex; mode=display\">\nw_t = w_{t-1} - \\alpha \\frac{\\partial Loss}{\\partial w_{t-1}}</script><p>$\\alpha$是学习率。学习率是一个很重要的超参，设置太大会导致模型无法收敛，设置太小会导致收敛过慢。</p>\n<h3 id=\"小批量梯度下降\"><a href=\"#小批量梯度下降\" class=\"headerlink\" title=\"小批量梯度下降\"></a>小批量梯度下降</h3><p>在整个训练集上进行求梯度、求导会很慢。我们可以随机采样b个样本，计算损失来近似整个训练集上的损失。这个b就是<code>batch_size</code>（批量大小），不能设置太大，太大导致内存占用过高，设置太小又无法充分发挥硬件潜力。</p>\n<h2 id=\"基本深度学习训练流程-dot\"><a href=\"#基本深度学习训练流程-dot\" class=\"headerlink\" title=\"++基本深度学习训练流程++{.dot}\"></a>++基本深度学习训练流程++{.dot}</h2><p>以线性回归为例，假设我们要建立一个这样的模型：</p>\n<script type=\"math/tex; mode=display\">\ny = 2x_1 -3.4x_2 + 4.2</script><p>事先导入需要用的包：</p>\n<pre><code class=\"lang-python\">import numpy as np\nimport torch\nfrom torch.utils import data\nfrom d2l import torch as d2l\n</code></pre>\n<p>人工生成数据：</p>\n<pre><code class=\"lang-python\">def synthetic_data(w, b, num_examples):\n    &quot;&quot;&quot;生成y=Xw+b+噪声&quot;&quot;&quot;\n    X = torch.normal(0, 1, (num_examples, len(w)))\n    y = torch.matmul(X, w) + b\n    y += torch.normal(0, 0.01, y.shape)\n    return X, y.reshape((-1, 1))\n\ntrue_w = torch.tensor([2, -3.4])\ntrue_b = 4.2\nfeatures, labels = synthetic_data(true_w, true_b, 1000)    # 生成1k个样本。\n</code></pre>\n<p>数据案例：</p>\n<pre><code class=\"lang-python\">print(&#39;features:&#39;, features[0],&#39;\\nlabel:&#39;, labels[0])\n# 返回\n# features: tensor([-0.3679, -1.8471]) \n# label: tensor([9.7361])\n</code></pre>\n<p><code>features</code>是样本的特征，本质是一个二维数组，长度为1000，而<code>label</code>是样本的预测真实值。这里每个样本有两个特征，对每个特征单独分析，都会发现其与<code>label</code>存在线性关系：</p>\n<p><img data-src=\"../../assets/d2l1.png\" alt=\"image\"></p>\n<p>读取数据集的函数，返回一个dataloader：</p>\n<pre><code class=\"lang-python\">def load_array(data_arrays, batch_size, is_train=True):\n    &quot;&quot;&quot;构造一个PyTorch数据迭代器&quot;&quot;&quot;\n    dataset = data.TensorDataset(*data_arrays)\n    return data.DataLoader(dataset, batch_size, shuffle=is_train)\n</code></pre>\n<p>数据情况示例：</p>\n<pre><code class=\"lang-python\">batch_size = 10\ndata_iter = load_array((features, labels), batch_size)\n\nnext(iter(data_iter))\n\n# 结果分别是features和labels：\n# [tensor([[ 0.1554, -0.2034],\n#          [-0.2140,  1.0352],\n#          [-0.4209,  0.0428],\n#          [ 0.1887,  0.6141],\n#          [ 0.4987, -0.2314],\n#          [ 0.0653,  1.6406],\n#          [-1.1881,  0.2900],\n#          [-0.2824,  0.5910],\n#          [ 0.9963, -0.1816],\n#          [-1.6830, -1.3963]]),\n#  tensor([[ 5.2116],\n#          [ 0.2479],\n#          [ 3.2188],\n#          [ 2.4845],\n#          [ 5.9884],\n#          [-1.2453],\n#          [ 0.8441],\n#          [ 1.6217],\n#          [ 6.8072],\n#         [ 5.5692]])]\n</code></pre>\n<p>我们的目的就是使用这1000个样本，训练出一个线性回归模型，也就是求出w和b，以最大化预测的精度，即给定一个样本特征，能够尽可能估计出其对应<code>label</code>的值。</p>\n<p>初始化线性回归模型的参数，然后在训练过程中，这些参数会被学习、调整。定义模型和损失函数，并初始化模型参数：</p>\n<pre><code class=\"lang-python\"># nn是神经网络的缩写\nfrom torch import nn\n\nnet = nn.Sequential(nn.Linear(2, 1))\nloss = nn.MSELoss()\n\nnet[0].weight.data.normal_(0, 0.01)\nnet[0].bias.data.fill_(0)\n</code></pre>\n<p>正如前面所说的，对整个数据集进行梯度求导会相当费时，所以通常采用小批量梯度下降——SGD。</p>\n<pre><code class=\"lang-python\">trainer = torch.optim.SGD(net.parameters(), lr=0.03)\n</code></pre>\n<p>这样就可以开始训练了：</p>\n<pre><code class=\"lang-python\">num_epochs = 3\nfor epoch in range(num_epochs):\n    for X, y in data_iter:\n        l = loss(net(X) ,y)\n        trainer.zero_grad()\n        l.backward()\n        trainer.step()\n    l = loss(net(features), labels)\n    print(f&#39;epoch &#123;epoch + 1&#125;, loss &#123;l:f&#125;&#39;)\n\n# 训练过程举例：\n# epoch 1, loss 0.043705\n# epoch 2, loss 0.000172\n# epoch 3, loss 0.000047\n</code></pre>\n<h2 id=\"回归、分类与独热编码-dot\"><a href=\"#回归、分类与独热编码-dot\" class=\"headerlink\" title=\"++回归、分类与独热编码++{.dot}\"></a>++回归、分类与独热编码++{.dot}</h2><p>:::info</p>\n<p>学习视频：<span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMUs2NHkxUTd3dT9zcG1faWRfZnJvbT0zMzMuNzg4LnZpZGVvcG9kLmVwaXNvZGVzJmFtcDt2ZF9zb3VyY2U9M2QxNDU2MGMyOGY5MGVmZGQxZjNlNmNhZjdiZjQyNzc=\">https://www.bilibili.com/video/BV1K64y1Q7wu?spm_id_from=333.788.videopod.episodes&amp;vd_source=3d14560c28f90efdd1f3e6caf7bf4277</span></p>\n<p>:::</p>\n<p>回归可以用于预测的问题，比如预测房屋被售出价格，或者棒球队可能获得的胜场数，又或者患者住院的天数，回归的输出是一个连续的数值。</p>\n<p><img data-src=\"../../assets/d2l2.png\" alt=\"image\"></p>\n<p>分类则更倾向于问“哪一个”。比如，某个电子邮件是否属于垃圾邮件，某张图像是驴、狗、猫还是鸡。分类问题通常是多个输出，输出i是模型预测输入为第i类的置信度。</p>\n<p><img data-src=\"../../assets/d2l3.png\" alt=\"image\"></p>\n<p>独热编码能够很好地应用到分类问题上，比如有三个类别：{狗，猫，鸡}。在计算机中，可以用(1,0,0)代表狗，用(0,1,0)代表猫，用(0,0,1)代表鸡。也就是说，用向量表示标签，分量和类别一样多，都是3。类别对应的分量设置为1，其他所有分量不是这个类别的设置为0，这就是独热编码。</p>\n<h2 id=\"Softmax运算与全连接层-dot\"><a href=\"#Softmax运算与全连接层-dot\" class=\"headerlink\" title=\"++Softmax运算与全连接层++{.dot}\"></a>++Softmax运算与全连接层++{.dot}</h2><p>:::info</p>\n<p>学习视频：<span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMUs2NHkxUTd3dT9zcG1faWRfZnJvbT0zMzMuNzg4LnZpZGVvcG9kLmVwaXNvZGVzJmFtcDt2ZF9zb3VyY2U9M2QxNDU2MGMyOGY5MGVmZGQxZjNlNmNhZjdiZjQyNzc=\">https://www.bilibili.com/video/BV1K64y1Q7wu?spm_id_from=333.788.videopod.episodes&amp;vd_source=3d14560c28f90efdd1f3e6caf7bf4277</span></p>\n<p>:::</p>\n<p>softmax运算将数据转换为[0,1]区间的数值，可以理解为一种标准化，数值可以认为是概率。比如，一个长度为3的向量经过softmax操作后，3个数值都会被转换为0到1的区间值，并且相加和为1。</p>\n<p>softmax公式如下：</p>\n<script type=\"math/tex; mode=display\">\nsoftmax(x) = \\frac{exp(x_i)}{\\sum_{k}^{len(x)}exp(x_k)}</script><p>全连接层无处不在，前面提到全连接层可以很方便地通过nn.Linear实现。但是全连接层也不是没有缺点，参数量冗余是问题。对于任何具有d个输入和q个输出的全连接层（对应在最后一个维度上，输入和输出的特征数分别为d和q），参数量开销为O(dq)。</p>\n<p>后续会提到用Dropout方法处理这个问题。</p>\n<h2 id=\"经典损失函数-dot\"><a href=\"#经典损失函数-dot\" class=\"headerlink\" title=\"++经典损失函数++{.dot}\"></a>++经典损失函数++{.dot}</h2><h3 id=\"L1损失\"><a href=\"#L1损失\" class=\"headerlink\" title=\"L1损失\"></a>L1损失</h3><h3 id=\"L2损失\"><a href=\"#L2损失\" class=\"headerlink\" title=\"L2损失\"></a>L2损失</h3><h3 id=\"Huber鲁棒损失\"><a href=\"#Huber鲁棒损失\" class=\"headerlink\" title=\"Huber鲁棒损失\"></a>Huber鲁棒损失</h3><h3 id=\"交叉熵损失\"><a href=\"#交叉熵损失\" class=\"headerlink\" title=\"交叉熵损失\"></a>交叉熵损失</h3><h2 id=\"信息论基础-dot\"><a href=\"#信息论基础-dot\" class=\"headerlink\" title=\"++信息论基础++{.dot}\"></a>++信息论基础++{.dot}</h2><h1 id=\"多层感知机-rainbow\"><a href=\"#多层感知机-rainbow\" class=\"headerlink\" title=\"[多层感知机]{.rainbow}\"></a>[多层感知机]{.rainbow}</h1><h3 id=\"多层感知机理论-dot\"><a href=\"#多层感知机理论-dot\" class=\"headerlink\" title=\"++多层感知机理论++{.dot}\"></a>++多层感知机理论++{.dot}</h3><p>前面提到的线性回归是一种线性神经网络，这样的网络存在一种假设：输入和输出是线性相关的。这种假设下，任何输入的特征增大都会导致模型的输出增大或减小。但很多时候，输入和输出并非是线性相关的。比如一张图像，增加某个位置的像素的强度值能否总是增大其分类为狗的概率？    </p>\n<p>我们可以在网络中加入一个或多个隐藏层来突破线性模型的限制，使其能处理更普遍的函数关系类型。这种架构称为多层感知机（<code>multilayer perceptron, MLP</code>），这是堆叠许多全连接层的神经网络。</p>\n<p><img data-src=\"../../assets/d2l4.png\" alt=\"image\"></p>\n<p>每两个层都是全连接的，每个输入都会影响隐藏层中的每个神经元，而隐藏层中的每个神经元又会影响输出层中的每个神经元。</p>\n<p>如果输入$X \\in \\mathbb{R}^{n \\times d}$，n是小样本数，d是输入特征。对于隐藏层有权重$W_1 \\in \\mathbb{R}^{d \\times h}$、偏置$b_1 \\in \\mathbb{R}^{1 \\times h}$，输出层也有权重$W_2 \\in \\mathbb{R}^{h \\times q}$和偏置$b_2 \\in \\mathbb{R}^{1 \\times q}$。其中，h通常是这个隐藏层的隐藏单元数，q是输出的输出特征，如果要分类为10类，q就是10。因此多层感知机（单个隐藏层）的数学表达式可以表示为，O是输出，H称为隐藏表征（<code>hidden representation</code>）：</p>\n<script type=\"math/tex; mode=display\">\nH = XW_1 + b_1    \\\\\nO = HW_2 + b_2</script><h3 id=\"激活函数-dot\"><a href=\"#激活函数-dot\" class=\"headerlink\" title=\"++激活函数++{.dot}\"></a>++激活函数++{.dot}</h3><p>没有激活函数的多层感知机相当于线性神经网络。观察上面的表达式，隐藏单元由输入的仿射变换给出，而输出也只是隐藏单元的仿射函数。仿射函数的仿射函数还是仿射函数，可以如下证明上面的多层感知机等价于单层模型：</p>\n<script type=\"math/tex; mode=display\">\nO = (XW_1 + b_1)W_2 + b_2 = XW_1W_2 + b_1W_2 + b_2 = XW + b</script><p>这是因为，之前说到的线性回归模型已经可以表示任何仿射函数。通过合并，多层感知机退化为单层的线性回归模型。为了发挥多层架构的潜力，可以在仿射变换后应用非线性的激活函数（<code>activation function</code>），即：</p>\n<script type=\"math/tex; mode=display\">\nH = \\sigma(XW_1 + b_1)    \\\\\nO = \\sigma(HW_2 + b_2)</script><p>这样，多层感知机避免了线性计算退化为单层的线性模型的风险。通过隐藏层中的神经元，多层感知机可以捕获输入之间复杂的相互作用，这些神经元依赖每个输入的值。如果给定足够的神经元和正确的权重，我们就可以对任意函数进行建模，尽管实际应用中学习该函数是很困难的。</p>\n<h4 id=\"ReLU函数\"><a href=\"#ReLU函数\" class=\"headerlink\" title=\"ReLU函数\"></a><code>ReLU</code>函数</h4><p>最受欢迎的激活函数：修正线性单元（<code>rectified linear unit, ReLU</code>）。数学表达式为：</p>\n<script type=\"math/tex; mode=display\">\nReLU(x) = max(x, 0)</script><p><code>ReLU</code>函数通过将相应的激活值设为0，仅保留正元素并丢弃所有负元素。当输入值精确为0试，<code>ReLU</code>函数不可导。<code>ReLU</code>函数求导很方便，优化表现好，并一定程度上缓解了以往神经网络的梯度消失问题。代码实现和函数曲线图如下：</p>\n<pre><code class=\"lang-python\">y = torch.relu(x)\n</code></pre>\n<p><img data-src=\"../../assets/d2l5.png\" alt=\"image\"></p>\n<h4 id=\"sigmoid函数\"><a href=\"#sigmoid函数\" class=\"headerlink\" title=\"sigmoid函数\"></a>sigmoid函数</h4><p>对于一个定义在$\\mathbb{R}$的输入，<code>sigmoid</code>激活函数将输入变换到(0,1)区间。数学表达式为：</p>\n<script type=\"math/tex; mode=display\">\nsigmoid(x) = \\frac{1}{1+exp(-x)}</script><p>这是一个平滑的、可微的阈值单元的近似函数。sigmoid常被用做输出层的激活函数，这个时候，它输出二元分类的概率，因此sigmoid可以看作是softmax的一个特例。但是，隐藏层中的激活函数还是不选择sigmoid，因为<code>ReLU</code>更合适。当输入接近0时，sigmoid函数接近线性变换。代码实现和函数曲线图如下：</p>\n<pre><code class=\"lang-python\">y = torch.sigmoid(x)\n</code></pre>\n<p><img data-src=\"../../assets/d2l6.png\" alt=\"image\"></p>\n<h4 id=\"Tanh函数\"><a href=\"#Tanh函数\" class=\"headerlink\" title=\"Tanh函数\"></a><code>Tanh</code>函数</h4><p><code>Tanh</code>（双曲正切）函数也是将输入压缩转换到区间(-1,1)上。函数公式如下：</p>\n<script type=\"math/tex; mode=display\">\ntanh(x) = \\frac{1 - exp(-2x)}{1+exp(-2x)}</script><p>输入在0附近时，它和sigmoid函数一样，接近线性变换。代码实现和函数曲线图如下：</p>\n<pre><code class=\"lang-python\">y = torch.tanh(x)\n</code></pre>\n<p><img data-src=\"../../assets/d2l7.png\" alt=\"image\"></p>\n",
            "tags": [
                "人工智能"
            ]
        },
        {
            "id": "https://yunhdan.github.io/other/%E5%8D%9A%E5%AE%A2%E6%96%87%E6%A1%A3%E7%BE%8E%E5%8C%96%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E/",
            "url": "https://yunhdan.github.io/other/%E5%8D%9A%E5%AE%A2%E6%96%87%E6%A1%A3%E7%BE%8E%E5%8C%96%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E/",
            "title": "博客文档美化使用说明",
            "date_published": "2025-03-06T13:04:00.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"\\assets\\css\\APlayer.min.css\"><script src=\"\\assets\\js\\APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>:::info</p>\n<p>摘自<code>Hexo-Shoka</code>主题拥有者的使用说明：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9zaG9rYS5sb3N0eXUubWUvY29tcHV0ZXItc2NpZW5jZS9ub3RlL3RoZW1lLXNob2thLWRvYy9zcGVjaWFsLw==\">Step.4 主题特殊功能 - Theme Shoka Documentation - 二进制杂谈 - 计算机科学 | Yume Shoka = 有夢書架 = 吾乃天，壶中之天 (lostyu.me)</span></p>\n<p>:::</p>\n<h1 id=\"文字特效\"><a href=\"#文字特效\" class=\"headerlink\" title=\"文字特效\"></a>文字特效</h1><pre><code class=\"lang-raw\">++下划线++\n++波浪线++&#123;.wavy&#125;\n++着重点++&#123;.dot&#125;\n++紫色下划线++&#123;.primary&#125;\n++绿色波浪线++&#123;.wavy .success&#125;\n++黄色着重点++&#123;.dot .warning&#125;\n~~删除线～～\n~~红色删除线～～&#123;.danger&#125;\n==荧光高亮==\n[赤橙黄绿青蓝紫]&#123;.rainbow&#125;\n[红色]&#123;.red&#125;\n[粉色]&#123;.pink&#125;\n[橙色]&#123;.orange&#125;\n[黄色]&#123;.yellow&#125;\n[绿色]&#123;.green&#125;\n[靛青]&#123;.aqua&#125;\n[蓝色]&#123;.blue&#125;\n[紫色]&#123;.purple&#125;\n[灰色]&#123;.grey&#125;\n快捷键 [Ctrl]&#123;.kbd&#125; + [C]&#123;.kbd .red&#125;\nH~2~0\n29^th^\n</code></pre>\n<p>++下划线++<br>++波浪线++{.wavy}<br>++着重点++{.dot}<br>++紫色下划线++{.primary}<br>++绿色波浪线++{.wavy .success}<br>++黄色着重点++{.dot .warning}<br>~~删除线～～<br>~~红色删除线～～{.danger}<br>==荧光高亮==<br>[赤橙黄绿青蓝紫]{.rainbow}<br>[红色]{.red}<br>[粉色]{.pink}<br>[橙色]{.orange}<br>[黄色]{.yellow}<br>[绿色]{.green}<br>[靛青]{.aqua}<br>[蓝色]{.blue}<br>[紫色]{.purple}<br>[灰色]{.grey}<br>快捷键 [Ctrl]{.kbd} + [C]{.kbd .red}<br>H~2~0<br>29^th^</p>\n<h1 id=\"隐藏文字\"><a href=\"#隐藏文字\" class=\"headerlink\" title=\"隐藏文字\"></a>隐藏文字</h1><pre><code class=\"lang-raw\">!! 黑幕黑幕黑幕黑幕黑幕黑幕 !!： 鼠标滑过显示内容\n!! 模糊模糊模糊模糊模糊模糊 !!&#123;.bulr&#125; ： 选中文字显示内容\n</code></pre>\n<p>!! 黑幕黑幕黑幕黑幕黑幕黑幕 !!： 鼠标滑过显示内容<br>!! 模糊模糊模糊模糊模糊模糊 !!{.bulr} ： 选中文字显示内容</p>\n<h1 id=\"标签块\"><a href=\"#标签块\" class=\"headerlink\" title=\"标签块\"></a>标签块</h1><pre><code class=\"lang-raw\">[default]&#123;.label&#125;\n[primary]&#123;.label .primary&#125;\n[info]&#123;.label .info&#125;\n[:heavy_check_mark:success]&#123;.label .success&#125;\n[warning]&#123;.label .warning&#125;\n[:broken_heart:danger]&#123;.label .danger&#125;\n</code></pre>\n<p>[default]{.label}<br>[primary]{.label .primary}<br>[info]{.label .info}<br>[:heavy_check_mark:success]{.label .success}<br>[warning]{.label .warning}<br>[:broken_heart:danger]{.label .danger}</p>\n<h1 id=\"提醒块\"><a href=\"#提醒块\" class=\"headerlink\" title=\"提醒块\"></a>提醒块</h1><pre><code class=\"lang-raw\">:::default\n默认默认\n:::\n\n:::primary\n基本基本\n:::\n\n:::info\n提示提示\n:::\n\n:::success\n成功成功\n:::\n\n:::warning\n警告警告\n:::\n\n:::danger\n危险危险\n:::\n</code></pre>\n<p>:::default</p>\n<p>默认默认</p>\n<p>:::</p>\n<p>:::primary</p>\n<p>基本基本</p>\n<p>:::</p>\n<p>:::info</p>\n<p>提示提示</p>\n<p>:::</p>\n<p>:::success</p>\n<p>成功成功</p>\n<p>:::</p>\n<p>:::warning</p>\n<p>警告警告</p>\n<p>:::</p>\n<p>:::danger</p>\n<p>危险危险</p>\n<p>:::</p>\n<h1 id=\"折叠块\"><a href=\"#折叠块\" class=\"headerlink\" title=\"折叠块\"></a>折叠块</h1><pre><code class=\"lang-raw\">+++ 默认默认 这里是一段文字\n++ 下划线 ++\n+++\n\n\n+++primary 紫色\n:::info\n参考信息\n:::\n\n- 第一行\n- 第二行\n+++\n\n\n+++info  蓝色\n;;;id3 卡片 1\n这里是卡片 1 的内容\n;;;\n\n;;;id3 卡片 2\n这里是卡片 2 的内容\n;;;\n+++\n\n+++success 绿色\n&#123;% links %&#125;\n- site: 優萌初華\n  url: https://shoka.lostyu.me\n  color: \"#e9546b\"\n&#123;% endlinks %&#125;\n+++\n\n+++warning 黄色\n!! 警告警告警告警告警告！！&#123;.bulr&#125;\n[label]&#123;.label .success&#125;\n+++\n\n+++danger 红色\n[danger]&#123;.label .danger&#125;\n+++\n</code></pre>\n<p>+++ 默认默认 这里是一段文字<br>++ 下划线 ++<br>+++</p>\n<p>+++primary 紫色</p>\n<p>:::info</p>\n<p>参考信息</p>\n<p>:::</p>\n<ul>\n<li>第一行</li>\n<li>第二行<br>+++</li>\n</ul>\n<p>+++info  蓝色<br>;;;id3 卡片 1<br>这里是卡片 1 的内容<br>;;;</p>\n<p>;;;id3 卡片 2<br>这里是卡片 2 的内容<br>;;;<br>+++</p>\n<p>+++success 绿色<br><div class=\"links\"><div class=\"item\" title=\"優萌初華\" style=\"--block-color:#e9546b;\"><span class=\"exturl image\" data-url=\"aHR0cHM6Ly9zaG9rYS5sb3N0eXUubWU=\" data-background-image=\"/images/404.png\"></span>\n          <div class=\"info\">\n          <span class=\"exturl title\" data-url=\"aHR0cHM6Ly9zaG9rYS5sb3N0eXUubWU=\">優萌初華</span>\n          <p class=\"desc\">https://shoka.lostyu.me</p>\n          </div></div></div><br>+++</p>\n<p>+++warning 黄色<br>!! 警告警告警告警告警告！！{.bulr}<br>[label]{.label .success}<br>+++</p>\n<p>+++danger 红色<br>[danger]{.label .danger}<br>+++</p>\n",
            "tags": [
                "琐碎"
            ]
        },
        {
            "id": "https://yunhdan.github.io/ai/Deep-Learning-Experiment-Tricks/",
            "url": "https://yunhdan.github.io/ai/Deep-Learning-Experiment-Tricks/",
            "title": "Deep Learning Experiment Tricks",
            "date_published": "2025-03-02T15:58:57.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"\\assets\\css\\APlayer.min.css\"><script src=\"\\assets\\js\\APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>:::info</p>\n<p>一般在一个新的<code>trick</code>和<code>experience</code>开坑时，都会先暂时粗略地搬运一些其他地方的内容，或者简略描述。偶尔精进与专门研究时，会特别地丰富和细致化该内容。</p>\n<p>:::</p>\n<h1 id=\"pytorch-mssim-ssim的使用\"><a href=\"#pytorch-mssim-ssim的使用\" class=\"headerlink\" title=\"pytorch_mssim.ssim的使用\"></a><code>pytorch_mssim.ssim</code>的使用</h1><p>以下面计算<code>ssim</code>的代码为例：</p>\n<pre><code class=\"lang-python\">ssim_value = ssim(final, gt_batch, data_range=2.0, size_average=True)\n</code></pre>\n<p><code>data_range</code>表示图像像素值的动态范围（最大值与最小值的差）。如果输入图像经过归一化处理（如 <code>transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])</code>），则像素值范围会被映射到<code>[-1, 1]</code>。此时 <code>data_range</code> 应设为 <code>2.0</code>（因为 <code>1 - (-1) = 2</code>），而不是 <code>1.0</code>。</p>\n<p><code>SSIM</code>默认假设输入范围是<code>[0, 1]</code>（当 <code>data_range=1</code>）或 <code>[0, 255]</code>（当 <code>data_range=255</code>）。</p>\n<p><code>size_average=True</code> 会将 <code>SSIM</code> 值在所有图像和通道上取平均。<code>pytorch_msssim</code>的新版本使用reduction取代这个参数，重写为：<code>reduction=&#39;mean&#39;</code>。</p>\n<p>有时候，应该确保输入给<code>ssim</code>做计算时的数据范围在<code>[-1, 1]</code>之间，不然，则要裁剪处理：</p>\n<pre><code class=\"lang-python\">final_clamped = torch.clamp(final, 0.0, 1.0)\nssim_value = ssim(final_clamped, gt_batch, data_range=1.0, size_average=True)\n</code></pre>\n<h1 id=\"损失函数下降、震荡、上升的原因\"><a href=\"#损失函数下降、震荡、上升的原因\" class=\"headerlink\" title=\"损失函数下降、震荡、上升的原因\"></a>损失函数下降、震荡、上升的原因</h1><blockquote>\n<p>在训练包含多个损失函数的模型时，各子损失函数的变化趋势能够反映模型的学习动态和优化方向。以下是不同趋势的详细分析及应对策略：</p>\n<hr>\n<h4 id=\"一、损失函数整体持续下降\"><a href=\"#一、损失函数整体持续下降\" class=\"headerlink\" title=\"一、损失函数整体持续下降\"></a><strong>一、损失函数整体持续下降</strong></h4><h4 id=\"含义解析\"><a href=\"#含义解析\" class=\"headerlink\" title=\"含义解析\"></a><strong>含义解析</strong></h4><ul>\n<li><strong>良性学习信号</strong>：模型正在有效优化该任务目标，权重分配合理，数据质量良好。</li>\n<li><strong>潜在风险</strong>：<ul>\n<li><strong>过拟合倾向</strong>：若验证集对应指标未同步下降，可能过拟合训练数据。</li>\n<li><strong>任务主导性</strong>：其他损失未充分优化，模型可能偏向该任务。</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"典型案例\"><a href=\"#典型案例\" class=\"headerlink\" title=\"典型案例\"></a><strong>典型案例</strong></h4><ul>\n<li>重建损失（如L1/L2）持续下降，但对抗损失震荡 → 模型过度拟合像素级精度，忽视生成真实性。</li>\n</ul>\n<h4 id=\"应对策略\"><a href=\"#应对策略\" class=\"headerlink\" title=\"应对策略\"></a><strong>应对策略</strong></h4><ol>\n<li><strong>验证泛化性</strong>：检查验证集对应指标是否同步改善</li>\n<li><strong>调整权重</strong>：若其他损失停滞，适当降低该损失权重（如从1.0→0.7）</li>\n<li><strong>早停机制</strong>：当验证损失不再下降时停止训练</li>\n</ol>\n<hr>\n<h4 id=\"二、损失函数震荡波动\"><a href=\"#二、损失函数震荡波动\" class=\"headerlink\" title=\"二、损失函数震荡波动\"></a><strong>二、损失函数震荡波动</strong></h4><h4 id=\"含义解析-1\"><a href=\"#含义解析-1\" class=\"headerlink\" title=\"含义解析\"></a><strong>含义解析</strong></h4><ul>\n<li><strong>优化不稳定</strong>：学习率过高、批次过小或损失间存在冲突。</li>\n<li><strong>数据问题</strong>：噪声数据或类别不均衡导致梯度方向不一致。</li>\n<li><strong>对抗性博弈</strong>：典型于GAN的判别器与生成器损失交替上升。</li>\n</ul>\n<h4 id=\"数值特征\"><a href=\"#数值特征\" class=\"headerlink\" title=\"数值特征\"></a><strong>数值特征</strong></h4><ul>\n<li><strong>高频震荡</strong>（如±5%）：常由学习率过大引起</li>\n<li><strong>低频震荡</strong>（如每5个epoch变化）：多任务目标冲突</li>\n</ul>\n<h4 id=\"典型案例-1\"><a href=\"#典型案例-1\" class=\"headerlink\" title=\"典型案例\"></a><strong>典型案例</strong></h4><ul>\n<li>分类损失下降但正则化损失震荡 → L2正则化强度过高导致参数更新不稳定</li>\n</ul>\n<h4 id=\"应对策略-1\"><a href=\"#应对策略-1\" class=\"headerlink\" title=\"应对策略\"></a><strong>应对策略</strong></h4><ol>\n<li><strong>降低学习率</strong>：将初始学习率减少3-5倍（如2e-4→5e-5）</li>\n<li><strong>增大批次大小</strong>：从32提升至128，稳定梯度估计</li>\n<li><strong>梯度裁剪</strong>：设置<code>max_grad_norm=1.0</code></li>\n<li><strong>冲突分析</strong>：计算损失梯度余弦相似度，对负相关损失解耦训练</li>\n</ol>\n<hr>\n<h4 id=\"三、损失函数持续上升\"><a href=\"#三、损失函数持续上升\" class=\"headerlink\" title=\"三、损失函数持续上升\"></a><strong>三、损失函数持续上升</strong></h4><h4 id=\"含义解析-2\"><a href=\"#含义解析-2\" class=\"headerlink\" title=\"含义解析\"></a><strong>含义解析</strong></h4><ul>\n<li><strong>严重警告信号</strong>：模型在该任务上性能退化，优化方向错误。</li>\n<li><strong>常见诱因</strong>：<ul>\n<li><strong>损失权重倒置</strong>：如误将权重设为负数</li>\n<li><strong>任务本质冲突</strong>：如超分辨率任务中，L1损失下降但感知损失上升</li>\n<li><strong>数值不稳定</strong>：梯度爆炸导致损失进入病态区域</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"典型案例-2\"><a href=\"#典型案例-2\" class=\"headerlink\" title=\"典型案例\"></a><strong>典型案例</strong></h4><ul>\n<li>对抗损失上升而重建损失下降 → 判别器过强导致生成器无法有效学习</li>\n</ul>\n<h4 id=\"应对策略-2\"><a href=\"#应对策略-2\" class=\"headerlink\" title=\"应对策略\"></a><strong>应对策略</strong></h4><ol>\n<li><strong>立即暂停训练</strong>：检查损失计算代码和权重符号</li>\n<li><strong>损失权重热力图</strong>：可视化各损失对总损失的贡献比例</li>\n<li><strong>渐进式训练</strong>：分阶段引入上升的损失项（如先用L1预训练，第50epoch加入对抗损失）</li>\n<li><strong>架构改进</strong>：对于根本性冲突，修改网络结构（如增加多尺度特征融合模块）</li>\n</ol>\n<hr>\n<h4 id=\"四、综合优化建议\"><a href=\"#四、综合优化建议\" class=\"headerlink\" title=\"四、综合优化建议\"></a><strong>四、综合优化建议</strong></h4><ol>\n<li><strong>动态权重调整</strong>：采用不确定性加权法（如《Multi-Task Learning Using Uncertainty to Weigh Losses》）<pre><code class=\"lang-python\"># 各损失自动加权示例\nlog_var = torch.nn.Parameter(torch.zeros(3)) # 3个损失\nloss = 0.5*(loss1/torch.exp(log_var[0]) + loss2/torch.exp(log_var[1]) + log_var.sum())\n</code></pre>\n</li>\n<li><strong>损失相关性监控</strong>：计算各损失间的Pearson相关系数矩阵，识别冲突组合</li>\n<li><strong>课程学习策略</strong>：早期侧重易优化损失（如L1），后期加强高阶损失（如SSIM、VGG感知损失）</li>\n<li><strong>可视化工具</strong>：使用TensorBoard的并行坐标视图对比超参数与损失关系</li>\n</ol>\n<hr>\n<h4 id=\"五、调试检查清单\"><a href=\"#五、调试检查清单\" class=\"headerlink\" title=\"五、调试检查清单\"></a><strong>五、调试检查清单</strong></h4><p>当出现异常损失趋势时，按以下顺序排查：</p>\n<ol>\n<li><strong>数值检查</strong>：<ul>\n<li>确认损失计算未出现NaN/Inf</li>\n<li>检查梯度幅值（<code>torch.nn.utils.clip_grad_norm_</code>）</li>\n</ul>\n</li>\n<li><strong>数据流验证</strong>：<pre><code class=\"lang-python\"># 数据检查代码片段\nfor batch in val_loader:\n    print(batch[&#39;image&#39;].min(), batch[&#39;image&#39;].max()) # 应为[0,1]或[-1,1]\n    visualize(batch[&#39;image&#39;][0]) # 肉眼验证图像质量\n</code></pre>\n</li>\n<li><strong>权重合理性</strong>：确保各损失量级匹配（如L1≈0.1，对抗损失≈2.0时，需调整权重平衡）</li>\n<li><strong>模型容量测试</strong>：在小数据集（如100样本）上过拟合，验证能否达到预期损失</li>\n</ol>\n<p>通过系统分析损失动态，可精准定位模型优化瓶颈，实现多目标协同优化。</p>\n</blockquote>\n<h1 id=\"transforms-Resize\"><a href=\"#transforms-Resize\" class=\"headerlink\" title=\"transforms.Resize()\"></a><code>transforms.Resize()</code></h1><p>这个与<code>RandomCrop()</code>还不太一样，<code>Resize()</code>是等比例的缩放原图。所以存在一定的信息损失，一般不使用这种操作。</p>\n<h1 id=\"不确定性损失加权法——多任务损失均衡\"><a href=\"#不确定性损失加权法——多任务损失均衡\" class=\"headerlink\" title=\"不确定性损失加权法——多任务损失均衡\"></a>不确定性损失加权法——多任务损失均衡</h1><blockquote>\n<p>以下是使用不确定性加权法改造后的损失函数实现：</p>\n<pre><code class=\"lang-python\">import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom pytorch_msssim import ssim\n\nclass UncertaintyWeightedLoss(nn.Module):\n    def __init__(self, trans, num_tasks=5):\n        &quot;&quot;&quot;\n        trans: HVI转换器实例\n        num_tasks: 需要加权的损失项数量（这里包含L1, SSIM, Res, Cons, HVI）\n        &quot;&quot;&quot;\n        super().__init__()\n        self.trans = trans\n        # 初始化可学习的不确定性参数（log方差）\n        self.log_vars = nn.Parameter(torch.zeros(num_tasks))\n        # 初始化参数（可选）\n        nn.init.uniform_(self.log_vars, -3, -1)  # 初始方差在0.05~0.37之间\n\n    def compute_losses(self, final, gt, output, S1, P1, S2, P2):\n        &quot;&quot;&quot;分解计算各个基础损失项&quot;&quot;&quot;\n        # RGB空间损失\n        l1_loss = F.l1_loss(final, gt)\n        ssim_loss = 1 - ssim(final, gt, data_range=1.0, size_average=True)\n\n        # 残差一致性损失\n        loss_res1 = F.mse_loss(S1, P1 + S2) / (S1.detach().var() + 1e-6)\n        loss_res2 = F.mse_loss(S2, P2 + S1) / (S2.detach().var() + 1e-6)\n        res_loss = loss_res1 + loss_res2\n\n        # 下采样一致性损失\n        g1, g2 = pair_downsampler(output)\n        cons_loss = F.l1_loss(S1, P1 + g1) + F.l1_loss(S2, P2 + g2)\n\n        # HVI空间损失\n        final_hvi = self.trans.HVIT(final)\n        gt_hvi = self.trans.HVIT(gt)\n        hvi_l1 = F.l1_loss(final_hvi, gt_hvi)\n        hvi_edge = edge_loss(final_hvi, gt_hvi)\n\n        return [l1_loss, ssim_loss, res_loss, cons_loss, hvi_l1, hvi_edge]\n\n    def forward(self, final, gt, output, S1, P1, S2, P2):\n        # 获取所有基础损失项\n        losses = self.compute_losses(final, gt, output, S1, P1, S2, P2)\n\n        # 应用不确定性加权\n        total_loss = 0.0\n        for i, loss in enumerate(losses):\n            precision = torch.exp(-self.log_vars[i])\n            total_loss += precision * loss + self.log_vars[i]\n\n        # 返回总损失和详细损失项（用于监控）\n        loss_details = &#123;\n            &#39;total&#39;: total_loss,\n            &#39;l1&#39;: losses[0],\n            &#39;ssim&#39;: losses[1],\n            &#39;res&#39;: losses[2],\n            &#39;cons&#39;: losses[3],\n            &#39;hvi_l1&#39;: losses[4],\n            &#39;hvi_edge&#39;: losses[5],\n            &#39;log_vars&#39;: self.log_vars\n        &#125;\n        return total_loss, loss_details\n</code></pre>\n<p>主要改进点说明：</p>\n<ol>\n<li><strong>模块化设计</strong>：<br>```python<h1 id=\"初始化方式变化\"><a href=\"#初始化方式变化\" class=\"headerlink\" title=\"初始化方式变化\"></a>初始化方式变化</h1>trans = RGB_HVI().to(device)<br>criterion = UncertaintyWeightedLoss(trans).to(device)</li>\n</ol>\n<h1 id=\"前向计算变化\"><a href=\"#前向计算变化\" class=\"headerlink\" title=\"前向计算变化\"></a>前向计算变化</h1><p>total_loss, loss_details = criterion(final, gt, output, S1, P1, S2, P2)</p>\n<pre><code>\n2. **动态权重机制**：\n- 每个损失项自动获得权重：weight = exp(-log_var)\n- 包含正则项：log_var 防止方差无限增大\n- 初始权重范围：exp(-3)=0.05 ~ exp(-1)=0.37\n\n3. **训练监控增强**：\n```python\n# 在训练循环中添加监控\nwriter.add_scalars(&#39;Loss/Train&#39;, &#123;\n    &#39;total&#39;: loss_details[&#39;total&#39;].item(),\n    &#39;l1&#39;: loss_details[&#39;l1&#39;].item(),\n    &#39;ssim&#39;: loss_details[&#39;ssim&#39;].item(),\n    &#39;res&#39;: loss_details[&#39;res&#39;].item(),\n    &#39;cons&#39;: loss_details[&#39;cons&#39;].item(),\n    &#39;hvi_l1&#39;: loss_details[&#39;hvi_l1&#39;].item(),\n    &#39;hvi_edge&#39;: loss_details[&#39;hvi_edge&#39;].item()\n&#125;, total_iter)\n\n# 监控不确定性参数\nfor i, log_var in enumerate(loss_details[&#39;log_vars&#39;]):\n    writer.add_scalar(f&#39;Uncertainty/var_&#123;i&#125;&#39;, torch.exp(log_var).item(), epoch)\n</code></pre><ol>\n<li><p><strong>优化器调整</strong>：</p>\n<pre><code class=\"lang-python\"># 需要将损失参数加入优化器\noptimizer = optim.Adam(\n list(model.parameters()) + list(criterion.parameters()),\n lr=args.lr, \n betas=(0.9, 0.999)\n)\n</code></pre>\n</li>\n<li><p><strong>梯度稳定性处理</strong>：</p>\n<pre><code class=\"lang-python\"># 在训练步骤中添加梯度裁剪\ntorch.nn.utils.clip_grad_norm_(\n list(model.parameters()) + list(criterion.parameters()),\n max_norm=1.0\n)\n</code></pre>\n</li>\n</ol>\n<p>该实现通过以下方式解决原代码问题：</p>\n<ol>\n<li><strong>自动平衡机制</strong>：</li>\n</ol>\n<ul>\n<li>难任务（高方差项）自动获得低权重</li>\n<li>简单任务（低方差项）获得高权重</li>\n<li>通过反向传播自动调整权重</li>\n</ul>\n<ol>\n<li><strong>数值稳定性改进</strong>：</li>\n</ol>\n<ul>\n<li>使用log方差代替直接学习方差，避免除零错误</li>\n<li>初始值限制在合理范围</li>\n<li>梯度裁剪防止参数爆炸</li>\n</ul>\n<ol>\n<li><strong>可解释性增强</strong>：</li>\n</ol>\n<ul>\n<li>通过TensorBoard可直接观察每个任务的：  <ul>\n<li>损失值变化曲线</li>\n<li>自适应权重变化（exp(-log_var)）</li>\n<li>方差参数演化</li>\n</ul>\n</li>\n</ul>\n<p>实际使用时需要注意：</p>\n<ol>\n<li><p><strong>参数初始化</strong>：</p>\n<pre><code class=\"lang-python\"># 如果某些任务需要强调，可以调整初始值\nnn.init.constant_(self.log_vars[4], -2.0)  # 强调HVI_L1损失\n</code></pre>\n</li>\n<li><p><strong>学习率设置</strong>：</p>\n<pre><code class=\"lang-python\"># 为损失参数设置更小的学习率\noptimizer = optim.Adam([\n    &#123;&#39;params&#39;: model.parameters(), &#39;lr&#39;: 1e-4&#125;,\n    &#123;&#39;params&#39;: criterion.parameters(), &#39;lr&#39;: 1e-5&#125;\n])\n</code></pre>\n</li>\n<li><p><strong>多阶段训练</strong>：</p>\n<pre><code class=\"lang-python\"># 初始阶段固定部分损失权重\nif epoch &lt; warmup_epochs:\n    criterion.log_vars.requires_grad_(False)\nelse:\n    criterion.log_vars.requires_grad_(True)\n</code></pre>\n</li>\n</ol>\n<p>这种实现方式比手动调整lambda参数更科学，尤其在处理类似HVI这类新增损失时，能自动平衡其与原有损失项的关系。</p>\n</blockquote>\n<h1 id=\"余弦退火学习率调度器\"><a href=\"#余弦退火学习率调度器\" class=\"headerlink\" title=\"余弦退火学习率调度器\"></a>余弦退火学习率调度器</h1><p>一代经典的学习率调度器。</p>\n<p>模板代码参考如：</p>\n<pre><code class=\"lang-python\"># ... 其他导入 ...\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\n\ndef main():\n    # 参数解析\n    parser = argparse.ArgumentParser(&quot;MAI_Denoised_Train&quot;)\n    # ... 原有参数 ...\n    parser.add_argument(&#39;--min_lr&#39;, type=float, default=1e-6, help=&#39;minimum learning rate for cosine annealing&#39;)\n    args = parser.parse_args()\n\n    # ... 模型初始化 ...\n\n    # 初始化优化器和调度器\n    optimizer = optim.Adam(model.parameters(), lr=args.lr, betas=(0.9, 0.999), weight_decay=1e-6)\n    scheduler = CosineAnnealingLR(optimizer, T_max=args.epochs, eta_min=args.min_lr)\n\n    # 训练循环\n    for epoch in range(args.epochs):\n        # 训练过程...\n\n        # 验证过程...\n\n        # 更新学习率\n        scheduler.step()\n\n        # 记录学习率\n        current_lr = scheduler.get_last_lr()[0]\n        writer.add_scalar(&#39;Learning Rate&#39;, current_lr, epoch)\n        logging.info(f&#39;Epoch [&#123;epoch+1&#125;/&#123;args.epochs&#125;] Learning Rate: &#123;current_lr:.7f&#125;&#39;)\n\n    # ... 后续代码 ...\n</code></pre>\n<h1 id=\"Optuna自动化调参\"><a href=\"#Optuna自动化调参\" class=\"headerlink\" title=\"Optuna自动化调参\"></a><code>Optuna</code>自动化调参</h1><blockquote>\n<p>为了使用 Optuna 进行超参数调优，我们需要对代码进行以下主要修改。这里展示关键修改步骤（完整代码见最后）：</p>\n<pre><code class=\"lang-python\">import optuna\nfrom optuna.trial import Trial\n\ndef objective(trial):\n    # 定义可调参数范围\n    args = argparse.Namespace(\n        batch_size=trial.suggest_categorical(&#39;batch_size&#39;, [32, 64, 128]),\n        lr=trial.suggest_float(&#39;lr&#39;, 1e-6, 1e-3, log=True),\n        lambda_hvi1=trial.suggest_float(&#39;lambda_hvi1&#39;, 0.001, 0.1),\n        lambda_hvi2=trial.suggest_float(&#39;lambda_hvi2&#39;, 0.001, 0.1),\n        lambda_rgb1=trial.suggest_float(&#39;lambda_rgb1&#39;, 0.1, 2),\n        lambda_rgb2=trial.suggest_float(&#39;lambda_rgb2&#39;, 0.1, 2),\n        # 保留其他固定参数...\n        cuda=True,\n        gpu=&#39;cuda:0&#39;,\n        epochs=100,  # 调试时可减少epoch\n        save=f&#39;./EXP/&#123;trial.number&#125;&#39;  # 为每个trial创建独立目录\n    )\n\n    # 运行训练并返回验证指标\n    final_psnr = train_model(args, trial)\n    return final_psnr\n\ndef train_model(args, trial=None):\n    # [原main()函数内容在这里重构]\n    # 在验证循环中报告中间结果\n    if trial:\n        trial.report(val_psnr, epoch)\n        if trial.should_prune():\n            raise optuna.exceptions.TrialPruned()\n\n    return best_val_psnr  # 返回需要优化的指标\n\nif __name__ == &quot;__main__&quot;:\n    # 创建Optuna study\n    study = optuna.create_study(\n        direction=&#39;maximize&#39;,\n        sampler=optuna.samplers.TPESampler(),\n        pruner=optuna.pruners.MedianPruner()\n    )\n\n    # 运行优化\n    study.optimize(objective, n_trials=50, timeout=3600*24)\n\n    # 输出结果\n    print(&quot;Best trial:&quot;)\n    trial = study.best_trial\n    print(f&quot;  Value: &#123;trial.value&#125;&quot;)\n    print(&quot;  Params: &quot;)\n    for key, value in trial.params.items():\n        print(f&quot;    &#123;key&#125;: &#123;value&#125;&quot;)\n</code></pre>\n<p>主要修改点说明：</p>\n<ol>\n<li><p><strong>参数建议</strong>：使用 trial.suggest_* 方法替代原argparse参数：</p>\n<pre><code class=\"lang-python\">trial.suggest_categorical(&#39;batch_size&#39;, [32, 64, 128])\ntrial.suggest_float(&#39;lr&#39;, 1e-6, 1e-3, log=True)\n</code></pre>\n</li>\n<li><p><strong>目标函数</strong>：将训练过程封装到目标函数中，返回验证PSNR作为优化指标</p>\n</li>\n<li><p><strong>中间报告</strong>：在训练过程中定期报告验证指标，支持提前终止：</p>\n<pre><code class=\"lang-python\">trial.report(val_psnr, epoch)\nif trial.should_prune():\n    raise optuna.exceptions.TrialPruned()\n</code></pre>\n</li>\n<li><p><strong>独立目录</strong>：为每个trial创建独立的保存目录，避免文件冲突：</p>\n<pre><code class=\"lang-python\">args.save = f&#39;./EXP/&#123;trial.number&#125;&#39;\n</code></pre>\n</li>\n<li><p><strong>Study配置</strong>：创建优化study时指定优化方向（最大化PSNR）和采样策略：</p>\n<pre><code class=\"lang-python\">study = optuna.create_study(direction=&#39;maximize&#39;)\n</code></pre>\n</li>\n</ol>\n<p>完整整合后的代码示例：</p>\n<pre><code class=\"lang-python\">import optuna\nfrom optuna.trial import Trial\nimport argparse\nimport torch\n\ndef main():\n    # 原始训练代码...\n\ndef objective(trial):\n    # 定义超参数搜索空间\n    params = &#123;\n        &#39;batch_size&#39;: trial.suggest_categorical(&#39;batch_size&#39;, [32, 64, 128]),\n        &#39;lr&#39;: trial.suggest_float(&#39;lr&#39;, 1e-6, 1e-3, log=True),\n        &#39;lambda_hvi1&#39;: trial.suggest_float(&#39;lambda_hvi1&#39;, 0.001, 0.1),\n        &#39;lambda_hvi2&#39;: trial.suggest_float(&#39;lambda_hvi2&#39;, 0.001, 0.1),\n        &#39;lambda_rgb1&#39;: trial.suggest_float(&#39;lambda_rgb1&#39;, 0.5, 2.0),\n        &#39;lambda_rgb2&#39;: trial.suggest_float(&#39;lambda_rgb2&#39;, 0.5, 2.0),\n        &#39;lambda_res&#39;: trial.suggest_float(&#39;lambda_res&#39;, 0.5, 2.0),\n        &#39;lambda_cons&#39;: trial.suggest_float(&#39;lambda_cons&#39;, 0.5, 2.0),\n    &#125;\n\n    # 固定参数\n    fixed_params = &#123;\n        &#39;cuda&#39;: True,\n        &#39;gpu&#39;: &#39;cuda:0&#39;,\n        &#39;epochs&#39;: 100,  # 调优时epoch可以适当减少\n        &#39;data_dir&#39;: &#39;/path/to/data&#39;,\n        &#39;save&#39;: f&#39;./EXP/trial_&#123;trial.number&#125;&#39;,\n    &#125;\n\n    # 合并参数\n    args = argparse.Namespace(**&#123;**params, **fixed_params&#125;)\n\n    # 运行训练\n    best_psnr = train_with_args(args, trial)\n    return best_psnr\n\ndef train_with_args(args, trial=None):\n    # [原main()函数内容重构到这里]\n    # 初始化模型、数据加载等...\n\n    best_psnr = 0\n    for epoch in range(args.epochs):\n        # 训练循环...\n\n        # 验证循环\n        with torch.no_grad():\n            val_psnr = evaluate(model, val_loader)\n\n            # 向Optuna报告中间结果\n            if trial:\n                trial.report(val_psnr, epoch)\n\n                # 提前终止\n                if trial.should_prune():\n                    raise optuna.exceptions.TrialPruned()\n\n        if val_psnr &gt; best_psnr:\n            best_psnr = val_psnr\n            torch.save(model.state_dict(), f&quot;&#123;args.save&#125;/best_model.pth&quot;)\n\n    return best_psnr\n\nif __name__ == &quot;__main__&quot;:\n    # 创建Optuna study\n    study = optuna.create_study(\n        direction=&#39;maximize&#39;,\n        sampler=optuna.samplers.TPESampler(),\n        pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=10)\n    )\n\n    # 运行优化\n    study.optimize(objective, n_trials=50, timeout=3600*24)\n\n    # 输出最佳结果\n    print(&quot;Best trial:&quot;)\n    trial = study.best_trial\n    print(f&quot;  PSNR: &#123;trial.value&#125;&quot;)\n    print(&quot;  Params: &quot;)\n    for key, value in trial.params.items():\n        print(f&quot;    &#123;key&#125;: &#123;value&#125;&quot;)\n</code></pre>\n<p>关键优化技巧：</p>\n<ol>\n<li><p><strong>参数范围设置</strong>：根据参数性质选择适当的范围：</p>\n<pre><code class=\"lang-python\">trial.suggest_float(&#39;lr&#39;, 1e-6, 1e-3, log=True)  # 对数尺度更适合学习率\ntrial.suggest_categorical(&#39;batch_size&#39;, [32, 64, 128])\n</code></pre>\n</li>\n<li><p><strong>提前终止</strong>：使用MedianPruner避免资源浪费：</p>\n<pre><code class=\"lang-python\">pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=10)\n</code></pre>\n</li>\n<li><p><strong>并行优化</strong>：通过指定n_jobs并行运行：</p>\n<pre><code class=\"lang-python\">study.optimize(objective, n_trials=100, n_jobs=4)\n</code></pre>\n</li>\n<li><p><strong>持久化存储</strong>：使用数据库保存进度：</p>\n<pre><code class=\"lang-python\">study = optuna.create_study(\n    storage=&#39;sqlite:///optuna.db&#39;,\n    study_name=&#39;denoising_study&#39;,\n    load_if_exists=True\n)\n</code></pre>\n</li>\n</ol>\n<p>注意事项：</p>\n<ol>\n<li><p><strong>资源管理</strong>：调优时适当减少epoch数量（如50-100），最终训练时再用完整epoch</p>\n</li>\n<li><p><strong>参数空间</strong>：初始搜索使用较宽范围，后期可基于初步结果缩小范围</p>\n</li>\n<li><p><strong>指标选择</strong>：建议使用验证集PSNR作为优化目标，而非训练损失</p>\n</li>\n<li><p><strong>随机种子</strong>：为保持可比性，可在每个trial中固定随机种子：</p>\n<pre><code class=\"lang-python\">torch.manual_seed(trial.suggest_int(&#39;seed&#39;, 0, 1000))\n</code></pre>\n</li>\n<li><p><strong>GPU内存</strong>：注意batch_size与GPU显存的匹配，建议在suggest_categorical中包含可行值</p>\n</li>\n</ol>\n<p>这种集成方式可以在不破坏原有训练逻辑的基础上，系统性地探索超参数空间。最终可以通过study.best_trial.params获取最佳参数组合，用于最终模型的训练。</p>\n</blockquote>\n<h1 id=\"混合精度训练\"><a href=\"#混合精度训练\" class=\"headerlink\" title=\"混合精度训练\"></a>混合精度训练</h1><h1 id=\"梯度累积\"><a href=\"#梯度累积\" class=\"headerlink\" title=\"梯度累积\"></a>梯度累积</h1><p>通过多次小批量迭代累积梯度，模拟大 <code>Batch Size</code> 的效果，模板代码参考可见下方：</p>\n<pre><code class=\"lang-python\">accumulation_steps = 4  # 累积4个batch的梯度\nfor i, (inputs, labels) in enumerate(dataloader):\n    outputs = model(inputs)\n    loss = criterion(outputs, labels)\n    loss = loss / accumulation_steps  # 损失按累积步数缩放\n    loss.backward()\n\n    if (i + 1) % accumulation_steps == 0:\n        optimizer.step()\n        optimizer.zero_grad()\n</code></pre>\n<h1 id=\"torchinfo统计模型的显存占用\"><a href=\"#torchinfo统计模型的显存占用\" class=\"headerlink\" title=\"torchinfo统计模型的显存占用\"></a><code>torchinfo</code>统计模型的显存占用</h1><p>参考如下代码：</p>\n<pre><code class=\"lang-python\">from torchinfo import summary\nmodel = MyModel().cuda()\nsummary(model, input_size=(batch_size, 3, 256, 256))\n</code></pre>\n<h1 id=\"显存分析器memory-profiler\"><a href=\"#显存分析器memory-profiler\" class=\"headerlink\" title=\"显存分析器memory_profiler\"></a>显存分析器<code>memory_profiler</code></h1><p>这个工具可以可以统计每行代码的显存变化</p>\n<pre><code class=\"lang-python\">from pytorch_memlab import LineProfiler\n\n@profile\ndef train_batch(inputs, labels):\n    outputs = model(inputs)\n    loss = criterion(outputs, labels)\n    loss.backward()\n    optimizer.step()\n\n# 运行后会打印每行代码的显存变化\ntrain_batch(inputs, labels)\n</code></pre>\n<h1 id=\"Dataloader的num-workers设置\"><a href=\"#Dataloader的num-workers设置\" class=\"headerlink\" title=\"Dataloader的num_workers设置\"></a><code>Dataloader</code>的<code>num_workers</code>设置</h1><p><code>num_workers</code>通常设置为0，<code>CPU</code>线程数的<code>75%</code>，<code>CPU</code>线程数，<code>CPU</code>线程数的两倍。</p>\n<p><code>CPU</code>的线程数计算公式为：线程数 = 逻辑核心数 = 物理核心数 * 单核线程数。</p>\n<p><code>num_workers</code>很大程度上影响<code>GPU</code>的占用率。保持长时间的高<code>GPU</code>占用率是高效率训练深度学习的基础。</p>\n<h1 id=\"损失为Nan的分析\"><a href=\"#损失为Nan的分析\" class=\"headerlink\" title=\"损失为Nan的分析\"></a>损失为<code>Nan</code>的分析</h1><blockquote>\n<p>损失值出现NaN（Not a Number）通常由数值不稳定引起，以下是可能原因及解决方案：</p>\n<h4 id=\"1-输入数据问题\"><a href=\"#1-输入数据问题\" class=\"headerlink\" title=\"1. 输入数据问题\"></a>1. <strong>输入数据问题</strong></h4><ul>\n<li><p><strong>检查数据中的NaN或异常值</strong>：确保输入数据无缺失或无效值。</p>\n<pre><code class=\"lang-python\">import numpy as np\nprint(&quot;NaN in data:&quot;, np.isnan(data).any())\nprint(&quot;数据范围:&quot;, data.min(), data.max())\n</code></pre>\n</li>\n<li><p><strong>数据标准化/归一化</strong>：过大或过小的输入值可能导致梯度爆炸。</p>\n<pre><code class=\"lang-python\">data = (data - data.mean()) / data.std()  # 标准化\n</code></pre>\n</li>\n</ul>\n<h4 id=\"2-学习率过高\"><a href=\"#2-学习率过高\" class=\"headerlink\" title=\"2. 学习率过高\"></a>2. <strong>学习率过高</strong></h4><ul>\n<li><strong>降低学习率</strong>：过大的学习率会导致参数更新不稳定。<pre><code class=\"lang-python\">optimizer = torch.optim.SGD(model.parameters(), lr=0.01)  # 初始学习率设为0.01或更小\n</code></pre>\n</li>\n</ul>\n<h4 id=\"3-损失函数实现问题\"><a href=\"#3-损失函数实现问题\" class=\"headerlink\" title=\"3. 损失函数实现问题\"></a>3. <strong>损失函数实现问题</strong></h4><ul>\n<li><p><strong>避免对零取对数</strong>：在交叉熵损失中增加极小值ε（如1e-8）。</p>\n<pre><code class=\"lang-python\">loss = -tf.reduce_sum(y_true * tf.math.log(y_pred + 1e-8))\n</code></pre>\n</li>\n<li><strong>使用框架内置函数</strong>：如TensorFlow的<code>CategoricalCrossentropy(from_logits=True)</code>，避免手动实现中的错误。</li>\n</ul>\n<h4 id=\"4-梯度爆炸（前提是你的其他代码得写对）\"><a href=\"#4-梯度爆炸（前提是你的其他代码得写对）\" class=\"headerlink\" title=\"4. 梯度爆炸（前提是你的其他代码得写对）\"></a>4. <strong>梯度爆炸（前提是你的其他代码得写对）</strong></h4><ul>\n<li><p><strong>梯度裁剪</strong>：限制梯度最大范数。</p>\n<pre><code class=\"lang-python\"># PyTorch示例\ntorch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n</code></pre>\n<pre><code class=\"lang-python\"># TensorFlow示例\ngradients = tape.gradient(loss, model.trainable_variables)\ngradients, _ = tf.clip_by_global_norm(gradients, 1.0)\noptimizer.apply_gradients(zip(gradients, model.trainable_variables))\n</code></pre>\n</li>\n</ul>\n<h4 id=\"5-模型结构问题\"><a href=\"#5-模型结构问题\" class=\"headerlink\" title=\"5. 模型结构问题\"></a>5. <strong>模型结构问题</strong></h4><ul>\n<li><strong>激活函数与输出层匹配</strong>：分类任务最后一层需用Softmax（或配合<code>from_logits=True</code>）。</li>\n<li><strong>权重初始化</strong>：使用He/Xavier初始化避免初始值过大。<pre><code class=\"lang-python\"># PyTorch示例\ntorch.nn.init.kaiming_normal_(layer.weight)\n</code></pre>\n</li>\n</ul>\n<h4 id=\"6-数值稳定性技巧\"><a href=\"#6-数值稳定性技巧\" class=\"headerlink\" title=\"6. 数值稳定性技巧\"></a>6. <strong>数值稳定性技巧</strong></h4><ul>\n<li><strong>添加Batch Normalization</strong>：稳定层间输出分布。<pre><code class=\"lang-python\">model.add(tf.keras.layers.BatchNormalization())\n</code></pre>\n</li>\n<li><strong>混合精度训练</strong>：使用FP16时，开启梯度缩放。<pre><code class=\"lang-python\">optimizer = tf.keras.mixed_precision.LossScaleOptimizer(optimizer)\n</code></pre>\n</li>\n</ul>\n<h4 id=\"7-调试步骤\"><a href=\"#7-调试步骤\" class=\"headerlink\" title=\"7. 调试步骤\"></a>7. <strong>调试步骤</strong></h4><ul>\n<li><strong>小数据集测试</strong>：用少量样本过拟合，快速复现问题。</li>\n<li><strong>打印中间结果</strong>：检查前向传播输出和梯度。<pre><code class=\"lang-python\"># 检查输出层\nprint(&quot;模型输出:&quot;, outputs)\n# 检查梯度\nfor name, param in model.named_parameters():\n    if param.grad is not None:\n        print(f&quot;梯度 &#123;name&#125;: &#123;param.grad.norm()&#125;&quot;)\n</code></pre>\n</li>\n</ul>\n<h4 id=\"8-其他可能原因\"><a href=\"#8-其他可能原因\" class=\"headerlink\" title=\"8. 其他可能原因\"></a>8. <strong>其他可能原因</strong></h4><ul>\n<li><strong>正则化过强</strong>：降低L2正则化系数。</li>\n<li><strong>数据预处理错误</strong>：检查标准化时是否除以零（如方差为零的特征）。</li>\n</ul>\n<h4 id=\"总结流程\"><a href=\"#总结流程\" class=\"headerlink\" title=\"总结流程\"></a>总结流程</h4><ol>\n<li><strong>检查输入数据</strong>：确保无NaN且已标准化。</li>\n<li><strong>降低学习率</strong>：尝试0.001或更低。</li>\n<li><strong>验证损失函数</strong>：使用内置函数或添加ε。</li>\n<li><strong>梯度裁剪</strong>：限制梯度大小。</li>\n<li><strong>检查模型结构</strong>：激活函数、初始化、添加BatchNorm。</li>\n<li><strong>逐步调试</strong>：缩小数据范围，打印中间变量。</li>\n</ol>\n<p>通过以上步骤逐步排查，通常可以定位并解决NaN损失问题。</p>\n</blockquote>\n<h1 id=\"torchvision-utils-save-image\"><a href=\"#torchvision-utils-save-image\" class=\"headerlink\" title=\"torchvision.utils.save_image\"></a><code>torchvision.utils.save_image</code></h1><p>有个参数叫做<code>Normalize</code>，这个将数值映射到<code>[0,255]</code>的区间。相关使用说明如下：</p>\n<pre><code class=\"lang-python\">当设置normalize=True时：\n- 会自动将张量的数值范围从[min, max]线性映射到[0, 255]\n- 例如：输入张量范围是[-1, 1]，会被映射到0-255\n- 例如：输入张量范围是[0, 1]，会被映射到0-255（相当于直接乘以255）\n</code></pre>\n<p><code>torchvision.utils.save_image</code>保存图像要求图像的数值范围必须是指定范围，即在<code>[0,1]</code>或<code>[0,255]</code>。如果数据范围在其他区间，则需要保证数据范围符合<code>torchvision.utils.save_image</code>的要求，可通过设置<code>normalize</code>为<code>True</code>解决这个问题。</p>\n<h1 id=\"确保Python优先加载本地项目的代码而不是Anaconda环境中的库\"><a href=\"#确保Python优先加载本地项目的代码而不是Anaconda环境中的库\" class=\"headerlink\" title=\"确保Python优先加载本地项目的代码而不是Anaconda环境中的库\"></a>确保<code>Python</code>优先加载本地项目的代码而不是<code>Anaconda</code>环境中的库</h1><p>情景：<code>TinyNeuralNetwork</code>库代码在项目文件夹<code>Retinexformer</code>下面，<code>Anaconda</code>也有一个<code>TinyNeuralNetwork</code>库。现在我们在本地更新了<code>TinyNeuralNetwork</code>库代码，想要运行更新后的库代码中的<code>convert.py</code>代码。这个时候Python有可能会在执行新库代码<code>convert.py</code>的时候，调用<code>Anaconda</code>环境的旧库代码。</p>\n<p>一种方法是指定优先级，强制优先加载项目中的本地库：</p>\n<pre><code class=\"lang-python\">import sys\nimport os\n\n# 获取当前脚本所在目录（TinyNeuralNetwork文件夹的路径）\nTINYNN_DIR = os.path.dirname(os.path.abspath(__file__))\n# 获取项目根目录（假设 TinyNeuralNetwork 是 Retinexformer 的子目录）\nPROJECT_ROOT = os.path.dirname(TINYNN_DIR)\n\n# 将本地库路径插入到 sys.path 的最前面\nsys.path.insert(0, TINYNN_DIR)\nsys.path.insert(0, PROJECT_ROOT)\n\n# 打印验证路径是否正确添加（可选）\nprint(&quot;当前 Python 路径:&quot;)\nfor p in sys.path:\n    print(p)\n</code></pre>\n<p>另一种方式就是在终端执行<code>convert.py</code>而不是在<code>IDE</code>中运行：</p>\n<pre><code class=\"lang-python\">&gt; cd Retinexformer\n&gt; export PYTHONPATH=&quot;$PWD:$PYTHONPATH&quot;\n&gt; python convert.py\n</code></pre>\n",
            "tags": [
                "人工智能"
            ]
        }
    ]
}